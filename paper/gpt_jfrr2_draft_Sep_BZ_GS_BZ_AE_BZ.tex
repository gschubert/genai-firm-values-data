\documentclass[12pt]{article}
 

\usepackage{setspace,graphicx,epstopdf,amsmath,amsfonts,amssymb,amsthm, versionPO, texintro}
\usepackage{marginnote,datetime,enumitem,rotating,fancyvrb}
%\usepackage{hyperref,float}
%\usepackage[longnamesfirst]{natbib}
\usepackage{booktabs}
\usepackage{placeins}
\usepackage{bbm}
\usepackage{natbib}
\usepackage{listings}
\usepackage{array}
\usepackage[utf8]{inputenc}
\usepackage[colorlinks=true,urlcolor=blue,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{xurl}
\usepackage{verbatim}

\usepackage{adjustbox}


\usepackage[title,titletoc]{appendix}
\usepackage{chapterbib}

% \urlstyle{same}
% \usdate

% These next lines allow including or excluding different versions of text
% using versionPO.sty

%\excludeversion{notes}		% Include notes?
%\includeversion{links}          % Turn hyperlinks on?

% Turn off hyperlinking if links is excluded
%\iflinks{}{\hypersetup{draft=true}}

% Notes options
%\ifnotes{%
	%\usepackage[margin=1in,paperwidth=10in,right=2.5in]{geometry}%
	%\usepackage[textwidth=1.4in,shadow,colorinlistoftodos]{todonotes}%
	%}{%
	\usepackage[margin=1in]{geometry}%
	
	\usepackage{lscape}
	%\usepackage[disable]{todonotes}%
	%}

% Allow todonotes inside footnotes without blowing up LaTeX
% Next command works but now notes can overlap. Instead, we'll define 
% a special footnote note command that performs this redefinition.
%\renewcommand{\marginpar}{\marginnote}%

% Save original definition of \marginpar
\let\oldmarginpar\marginpar

% Workaround for todonotes problem with natbib (To Do list title comes out wrong)
\makeatletter\let\chapter\@undefined\makeatother % Undefine \chapter for todonotes

% Define note commands
\newcommand{\smalltodo}[2][] {\todo[caption={#2}, size=\scriptsize, fancyline, #1] {\begin{spacing}{.5}#2\end{spacing}}}
\newcommand{\rhs}[2][]{\smalltodo[color=green!30,#1]{{\bf RS:} #2}}
\newcommand{\rhsnolist}[2][]{\smalltodo[nolist,color=green!30,#1]{{\bf RS:} #2}}
\newcommand{\rhsfn}[2][]{%  To be used in footnotes (and in floats)
	\renewcommand{\marginpar}{\marginnote}%
	\smalltodo[color=green!30,#1]{{\bf RS:} #2}%
	\renewcommand{\marginpar}{\oldmarginpar}}
%\newcommand{\textnote}[1]{\ifnotes{{\noindent\color{red}#1}}{}}
\newcommand{\textnote}[1]{\ifnotes{{\colorbox{yellow}{{\color{red}#1}}}}{}}

% Command to start a new page, starting on odd-numbered page if twoside option 
% is selected above
\newcommand{\clearRHS}{\clearpage\thispagestyle{empty}\cleardoublepage\thispagestyle{plain}}

% Number paragraphs and subparagraphs and include them in TOC
\setcounter{tocdepth}{2}

% JF-specific includes:

\usepackage{indentfirst} % Indent first sentence of a new section.
\usepackage{endnotes}    % Use endnotes instead of footnotes
\usepackage{jf}          % JF-specific formatting of sections, etc.

\usepackage[labelfont=bf,labelsep=period]{caption}   % Format figure captions
\captionsetup[table]{labelsep=none}
% \captionsetup{width=\textwidth}
% \captionsetup[table]{labelsep=colon}
% \captionsetup[figure]{labelsep=colon}

% Define theorem-like commands and a few random function names.
\newtheorem{condition}{CONDITION}
\newtheorem{corollary}{COROLLARY}
\newtheorem{proposition}{PROPOSITION}
\newtheorem{obs}{OBSERVATION}
\newcommand{\argmax}{\mathop{\rm arg\,max}}
\newcommand{\sign}{\mathop{\rm sign}}
\newcommand{\defeq}{\stackrel{\rm def}{=}}

% Figure
\usepackage{subcaption}
\renewcommand{\thesubfigure}{\Alph{subfigure}}


%%% TIKZ
\usepackage{tikz}
\usepackage{xcolor}
\usetikzlibrary{patterns}
\usetikzlibrary{decorations.pathreplacing}


% Colors %%%
\definecolor{dgreen}{RGB}{20, 160, 0}
\definecolor{gold}{RGB}{255, 205, 0}
\definecolor{brick}{RGB}{178,34,34}
\definecolor{ochre}{RGB}{204, 119, 34}
\definecolor{lightlightgray}{gray}{0.95}


% Table
\usepackage{booktabs, caption}
\usepackage{threeparttable}
\captionsetup{labelsep = period}

%%%%%%%%%%%%%%%WARNING
%%%%AE commented to compile%%%%%%%%%%%
%%%%%Fix issue with \input in new TEX version
\makeatletter
%%%primitive input in tabular
\AddToHook{env/tabular/begin}{\let\input\@@input}
\makeatother

%line spacing
%\linespread{2.5}

\graphicspath{{"/Users/gschubert/Gregor_Dropbox Dropbox/Gregor Schubert/Research/GPT and Firms/figures"}}


\author{	Gregor Schubert, UCLA Anderson School of Management\thanks{\scriptsize Email: \href{mailto:gregor.schubert@anderson.ucla.edu}{gregor.schubert@anderson.ucla.edu.}}
}
	\title{\textbf{}} 

\begin{document}


\title{\textbf{\scalebox{0.9}{Generative AI and Firm Values}}\footnote{We thank David Autor, Tania Babina, Thomas Chaney, Charlie Clarke,  Olivier Dessaint, Anastassia Fedyk, Alex He, Chad Jones, Sophia Kazinnik, Mete Kilic, Elena Simintzi, Selale Tuzel, Stijn Van Nieuwerburgh, Junbo Wang, Paul Whelan, Emmanuel Yimfor, Paolo Zaffaroni, and participants in the UCLA Anderson Finance Brown Bag, the UCSD Finance Seminar, NYU Stern Finance Seminar, KDD Finance Day,  Q Group 2023 Meeting,  Duke/UNC Asset Pricing Conference, IMF-WIFPR Conference, the 2023 ``Artificial Intelligence and the Economy'' conference, Carey Finance Conference, TCU Finance Conference,  the Chicago Booth Empirical Finance Conference, the OECD, the ITAM Finance Workshop, Macro-Finance Society Workshop, University of Kentucky Finance Conference, UW Summer Finance Conference, the IESE AI in Finance Workshop, the CEPR International Conference on Generative AI, the Purdue FinTech Conference, the Wharton AI and the Future of
Work Conference, the NBER Big Data and Securities Markets 2023 Meeting, the Federal Reserve Board, the MIT Initiative on the Digital Economy, the Bank for International Settlements Seminar, and the Stanford Digital Economy Lab for helpful feedback. We also thank Colton Etheridge and Yi Li for their research assistance. All remaining errors are our own.  } \\ \small \textcolor{white}{ }}

\author{Andrea L. Eisfeldt\thanks{
UCLA Anderson School of Management and NBER, Email: \href{mailto:andrea.eisfeldt@anderson.ucla.edu}%
{andrea.eisfeldt@anderson.ucla.edu} }  \hspace{-.3cm} \and Gregor Schubert\thanks{%
UCLA Anderson School of Management, Email: \href{mailto:gregor.schubert@anderson.ucla.edu}{gregor.schubert@anderson.ucla.edu.}}  
  \hspace{-.3cm}  \and   Bledi Taska\thanks{%
SkyHive, Email: \href{mailto:bt540@nyu.edu}{bt540@nyu.edu.}}
 \hspace{-.3cm}  \and Miao Ben Zhang\thanks{USC Marshall School of Business, Email: \href{mailto:Miao.Zhang@marshall.usc.edu}{%
Miao.Zhang@marshall.usc.edu}} }




\date{\bigskip \bigskip September 2025}

\maketitle
\thispagestyle{empty}
\begin{singlespacing}

\begin{abstract}
\normalsize
\onehalfspacing
%\noindent How do recent advances in Generative AI affect firm value? We construct the first measure of \textit{firms' workforce exposures} to Generative AI and show that an ``Artificial-Minus-Human'' (AMH) portfolio that is long high-exposure firms and short low-exposure firms earned daily returns of 0.44\% in the two weeks following the release of ChatGPT. The labor-exposure effect is more pronounced for firms with greater data assets and is distinct from the effect of firms' product exposures to Generative AI. Highly-exposed workforces can be either substituted for or complemented by Generative AI technologies.  We measure to what degree task level exposure is likely to lead to job level substitution by distinguishing whether the exposed tasks are core or supplemental to an occupation. Changes in firms' labor demand and profitability following the release of ChatGPT provide evidence for a labor-technology substitution channel driving the increases in exposed firms' values, which increases in magnitude if the exposure is concentrated in core tasks.

%100 WORD VERSION 
\noindent  How do recent advances in Generative AI affect firm value? We construct the first measure of \textit{firms' workforce exposures} to Generative AI and show that an ``Artificial-Minus-Human'' (AMH) portfolio earned 5\% in the two weeks following the release of ChatGPT. The labor-exposure effect is more pronounced for firms with greater data assets and is distinct from the effect of firms' product exposures to AI. We assess whether exposed workforces are substituted or complemented by Generative AI based on whether their exposed tasks are core or supplemental. Examining firmsâ€™ labor demand and profitability following the release of ChatGPT supports a labor-technology substitution channel. 
 
\bigskip 
\bigskip 
\bigskip 




%\noindent {\small {\it JEL Classification:} D92; E24; G32; J41; L25}
\end{abstract}
% \newline



\noindent {\small {\it Keywords:} Artificial Intelligence, Large Language Models, Generative AI, ChatGPT, Corporate Valuations, Equity Returns, Technological Change,  Labor Market Effects of Technology}

\end{singlespacing}
\bigskip 

\newpage 
\thispagestyle{empty}
\begin{center}
\textbf{Disclosure Statement}
\end{center}
\bigskip 
\bigskip 

\noindent \textbf{Andrea L. Eisfeldt }

\noindent I have an affiliation agreement with Cornerstone Research from which annual income is greater than \$10,000.  I am the owner of the NXTI Intangible index, which is licensed to the Simplify NXTI ETF.
\bigskip 
\bigskip


\noindent \textbf{Gregor Schubert}
 

\noindent I have nothing to disclose.
\bigskip 
\bigskip

\noindent \textbf{Bledi Taska}
 

\noindent I was employed by Lightcast from March 2015 till August 2023, and Lightcast is one 
of the sources of data used in this article. Lightcast's policy positions, goals, or 
financial interests are not related in any other way to the article and its results. 
\bigskip 
\bigskip

\noindent \textbf{Miao Ben Zhang}
 

\noindent I have nothing to disclose.
\bigskip 
\bigskip

 

 
 
\newpage
\setcounter{page}{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%      INTRODUCTION     %%%%%%%%%  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\tableofcontents

\onehalfspacing
%\section{Introduction}

\noindent Recent advances in Generative Artificial Intelligence are widely seen as a major technological breakthrough.  We construct the first \textit{firm-level} measure of the exposure of U.S. publicly traded firms' workforces to Generative AI. Using this measure, we show that the release of ChatGPT resulted in a significant and substantial change in the relative valuation of US firms.  Firms whose workforces are highly exposed to Generative AI increased in market value by almost 5\% relative to firms with a low exposure in the two weeks following the release of ChatGPT on November 30th, 2022.   The divergence in value reflects the varied potential for Generative AI to execute the tasks currently accomplished by firms' workforces, and the resulting effects on firms' expected future free cash flows.   It is not driven by firms' product-market exposure to Generative AI.
 

The release of ChatGPT can improve the expected future cash flows of firms with a high share of exposed workforces due to productivity improvements either from substituting labor with technology to save costs, or from complementing labor with Generative AI tools.  We show that the labor substitution channel drives our results, and develop a new method for assessing an occupation's potential for Generative AI substitution versus complementarity.  In particular, we show that the substitution effects measured by lower wages and job postings after the release of ChatGPT are concentrated in occupations that are most exposed to Generative AI through their \textit{core} tasks.  Examples include proofreaders and web developers.  Occupations most exposed through \textit{supplemental} tasks, such as financial managers and pharmacy aids, experience much smaller substitution effects. Our use of core versus supplemental task exposure to study substitution versus complementarity effects of technology on occupations can help to understand which occupations may ultimately benefit from Generative AI enhancements. However, our results for Generative AI's impact on firm value and future profitability illustrate that the main driver of the increase in value is the substitution channel.  The observed increase in firm value for firms whose workforces are more exposed to Generative AI is driven by occupations whose core tasks are more easily executed by Generative AI technologies.

Generative AI is a general-purpose technology and is changing (and expected to change) the way work is conducted across a broad array of industries.  Relative to earlier artificial intelligence models, Generative AI models can digest more complex inputs, and can produce human-like output, making Generative AI models (of which ChatGPT is an important example) more versatile and scalable than prior innovations in AI and machine learning.  In the past, technology shocks diffused over long periods of time, but the large change in the accessibility of AI tools and the massive amount of analysis and attention generated by the release of ChatGPT allow us to study its impact almost in real-time.\footnote{A large body of literature examined the historical diffusion of technologies and showed that the diffusion process is remarkably slow, particularly in the initial periods after the technologies are available, constituting an S-curve for technology diffusion (see many examples in \cite{greenwood_third_1999} and \cite{manuelli_frictionless_2014}).  ChatGPT reached 1 million users in only 5 days after its release, according to OpenAI's CEO Sam Altman's \href{https://twitter.com/sama/status/1599668808285028353}{Tweet} on December 4, 2022. It reached 100 million users in only two months after its release, a milestone that took the World Wide Web 7 years, WhatsApp 3.5 years, Instagram 2.5 years, and Twitter 5 years to reach (see this \href{https://economictimes.indiatimes.com/news/new-updates/chatgpt-witnesses-massive-rise-chatbot-gains-100-million-users-in-two-months/articleshow/98428443.cms?from=mdr}{link}).}  Our study, which includes effects on the full cross-section of firm values, wages, job postings, and firm profits, thus sheds light on the quantitative effects of an important technology shock on key corporate and economic outcomes.  

Recent work has documented variation in occupational exposure to Generative AI (see \cite{eloundou2023}).  However, without a connection to firm value, it is unclear whether higher exposure is value-increasing or value-decreasing for incumbent firms.  If Generative AI does increase efficiency for existing firms, how much value do firms versus workers accrue?  By documenting the increase in the value of firms with higher workforce exposure to Generative AI, while wages and job postings decline for exposed workers, we show that firm owners benefited relatively more than labor from the technology shock.  This is an important finding regarding the economic impact, especially in the context of the recent literature on the decline in the share of value added accruing to labor.  Our study is the first to document firms' workforce exposure to Generative AI, and to document the effect of these exposures on key labor market outcomes, including wages and job postings.  Moreover, we link these labor outcomes to firm profits, providing additional support for a labor-substitution effect driving changes in firm value.  By refining the measurement of task-level exposures using the distinction between core and supplementary task exposures, we are able to uncover both substitution and complementary effects of Generative AI on labor.

We build our measure of firms' exposure to Generative AI starting at the level of the tasks that workers in U.S. firms perform.  From the O*Net database, we obtain information on the 19,265 tasks that constitute the activities performed in 923 SOC 8-digit occupations in the U.S. We use a large language model to classify each task's exposure into categories based on whether it can be done more effectively using ChatGPT based on descriptions of the tasks and known capabilities of Generative AI models. Aggregating to the SOC 6-digit level, our final sample includes 678 occupations with, on average, 23\% of their tasks exposed to Generative AI, and 85\% of the occupations having at least one task exposed to Generative AI. We aggregate this task-level exposure to construct average occupational exposures.  We construct firm-level exposure estimates for publicly traded firms using data from Revelio Labs, which provides firms' occupational shares based on millions of individual public profiles. Our firm-level measure captures the potential for the tasks currently performed by labor at those firms to be done more efficiently using Generative AI. 

Our approach yields intuitive exposures that reflect the distinctive features of Generative AI compared to prior technologies. Unlike computerization that mainly disrupted routine-task jobs (e.g., \cite{autor2003} and \cite{acemoglu2011}) and robots that mainly disrupted manual-task jobs (\cite{acemoglu2020robots}), occupations exposed to Generative AI are cognitive-task jobs, such as legal, financial, mathematical, and administrative professions.\footnote{Our finding is consistent with \cite{webb2019impact}, who studies broadly-defined AI on the labor market using patent texts and shows that AI tends to disrupt non-routine cognitive-analytical jobs.} Consistent with Generative AI being able to assist with high-level cognitive tasks, we show that occupations with higher wages also have higher exposure to Generative AI.\footnote{Our result is consistent with recent findings by  \cite{kogan2019technology}, who find that technological advances impact workers at the higher end of the wage distribution.  On the other hand, other studies (\cite{krusell2000capital} and \cite{eisfeldt2023human}) document substitutability between low-skilled labor and capital but complementarity between high-skilled labor and capital.}   Overall, the Generative AI exposure of the tasks in all white-collar occupations is 40\% versus  9\% for blue-collar and service occupations. Our firm-level measure also shows that Generative AI is indeed a general-purpose technology, which varies both across and within a broad array of industries, with 3-digit NAICS industry effects explaining less than a third of the variation in the firm-level exposure. 

We derive our first main results from an event study that documents variation in the returns to firms with different labor-force exposures to Generative AI following the release of ChatGPT on November 30th, 2022.
Since we study firms' relative returns following a major event, our study can be thought of as looking at the effect of the release of ChatGPT on difference-in-differences in the levels of firms' valuations.
Sorting firms into five value-weighted portfolios based on their Generative AI exposures, we show that firms in the highest-exposure quintile, labeled the ``Artificial'' portfolio, earned 44 basis points higher daily returns than firms in the lowest-exposure quintile, labeled the ``Human'' portfolio, during the two weeks following the release of ChatGPT.\footnote{Our choice of the two-week event window is guided by the intensity of public attention to the release of ChatGPT on Twitter.} This finding is robust to controlling for firms' exposure to the market factor and the Fama-French 5 factors, and also to controlling for firm characteristics that have been shown to predict returns. Figure \ref{fig:ts_mkt} plots the cumulative abnormal returns during the time before and after the event for the zero-investment portfolio that goes long the artificial stocks and short the human stocks, which we denote as the ``Artificial Minus Human'' portfolio (AMH).   The AMH portfolio returns do not show an obvious pre-trend before the event window, and also no reversal after the event window, supporting the validity of our treatment effect estimation.\footnote{See Appendix Figure \ref{fig:apx_ts_mkt} for a version of the figure with a longer pre-period.}  



\begin{figure}[!ht]
\centering 
\includegraphics[width=0.95\linewidth]{../figures/ts_w2d180_mkt_short}  

\caption[.]{\textbf{Cumulative Abnormal Returns by Generative AI Exposure.} \small The figure plots the cumulative abnormal returns (CARs) of value-weighted quintile portfolios sorted by firms' labor-based Generative AI exposure. The graph shows the CARs of the lowest-exposure quintile portfolio, ``Human'' (H), the highest-exposure quintile portfolio, ``Artificial'' (A), and the zero investment portfolio that longs A and shorts H, ``Artificial-minus-Human'' (AMH). Market-adjusted daily abnormal returns are cumulated from November 29, 2022, the day before the release of ChatGPT, and are based on factor exposures computed over the 6-month period preceding the period shown in the graph.  Daily stock returns are from Yahoo Finance. The dashed vertical lines indicate the ``ChatGPT event period'' from November 30, 2022, to December 14, 2022. See details of the definition of firms' Generative AI exposure in Section \ref{sec:data} and the construction of the portfolios, the calculation of portfolios' CARs, and the determination of the ChatGPT event period in Section \ref{sec:returns}. GPT-4 was released on March 14, 2023.}
\label{fig:ts_mkt} 
\end{figure}


While the release of ChatGPT is also expected to affect firm values through effects on products and services,\footnote{For example, the stock value of chip maker NVIDIA more than doubled in early 2023 as the firm is a key chip supplier for training Generative AI models.} we conduct three separate tests to show that our findings based on firms' labor exposure to Generative AI are distinct from any product-exposure channel. First, we show that the AMH returns during the event window hold when sorting portfolios within industries.  We show this using both the NAICS 3-digit industry classification and the 10K text-based FIC 50 industry classification by \cite{hoberg2016}.  Noting that only 31\% of the firm-level variation in labor exposure to Generative AI is explained by 3-digit industry effects, our results are, not surprisingly, robust to these within-industry sorts.  Second, the AMH returns remain the same if we exclude the tech sector, in which firms' products are most likely to be directly related to the Generative AI technology.\footnote{Following \cite{acemoglu2022}, we identify the tech sector as the NAICS 51 ``Information'' and NAICS 54 ``Professional, Scientific, and Technical Services'' and exclude firms from these two sectors.}  Third, we use four proxies for firms' product exposure to Generative AI: a classification of AI-related business models based on firm annual reports;  the count of AI-related keywords based on texts of firms' annual reports; a Goldman Sachs classification of AI beneficiaries; and a measure based on firms' share of AI-skilled workers adopted from \cite{babina2024artificial}. We then run a standard event study test by regressing stock-level cumulative abnormal returns (CARs) on our labor-based Generative AI exposure measure while controlling for the proxies for product exposures. While firms' product exposures separately predict CARs, the effect of our labor-based Generative AI exposure remains significant, confirming the distinction between the labor and product-exposure channels. 

We show that data is an important complement to Generative AI.  This may help to understand the benefits of AI improvements for incumbent firms with existing data corpora. Examples highlighting the importance of data for using Generative AI can be seen in applications such as training customer service chatbots, automating workflows, improving predictions and analytics, and many others (\cite{caserta2023}).  Realizing the value associated with this technology at scale, therefore, may require a baseline level of data management capabilities and access to relevant input data.  We thus expect the return effect of Generative AI exposure to be particularly pronounced among firms with readily available data. We find strong confirmation for this proposition. In particular, we construct two measures of firms' data assets following the prior literature (\cite{begenau2018big}, \cite{farboodi2019big}, \cite{eeckhout2022data}, \cite{farboodi2023}, and \cite{abis2023}), and we show that Generative AI exposure boosts firm value significantly more if the firm has greater data assets. This finding also explains why firms' potential benefits from Generative AI are not expected to be entirely competed away by new entrants, as data assets can be highly specific to, or proprietary property of, incumbent firms. 

Our second set of main results documents the mechanism by which the labor channel generates our results for the impact of Generative AI on firm value. Importantly, we ask whether the effect of higher exposure to Generative AI reflects a greater substitution of,  or complementarity to,  firms' labor inputs.  Ex ante, both channels could increase firms' future cash flows and boost their current market value. That is, firms whose labor force can be substituted with cheaper Generative AI-based capital could save costs and generate higher future cash flows. On the other hand, if the technology complements the firm's workers and increases their productivity, the firm may also experience an increase in future profitability. 

To distinguish between these two channels, we refine our measure of occupational exposure.
Specifically, we redefine exposure depending on whether the occupational tasks that are exposed to Generative AI are \textit{core} or \textit{supplemental} according to O*Net's classification. Many occupations have exposure to Generative AI through both core and supplemental tasks, with 77\% of the exposure from core tasks and 23\% of the exposure deriving from supplemental tasks on average. Our key hypothesis is that an occupation is more likely to be substituted by Generative AI if its \textit{core} tasks are more exposed to the productivity improvements enabled by the technology, while if an occupation's \textit{supplemental} tasks are more exposed, there is more opportunity for complementarity. Intuitively, core tasks represent the most fundamental duties an employee in that occupation is expected to perform. If Generative AI can more efficiently complete the core tasks at a much lower cost, then it is more likely that the technology can displace the occupation as a whole. In contrast, supplemental tasks are additional tasks or duties associated with the core tasks but which are not themselves considered critical or central to the occupation. If Generative AI can help workers more efficiently complete their supplemental tasks, this can free up time and effort for the worker to focus more on the core tasks,  potentially increasing the worker's productivity without making them replaceable. To the best of our knowledge, this is the first study that distinguishes between core and supplemental task exposures within occupations. 

 We conduct two sets of tests to investigate the mechanism for the labor-channel impact on firm value. Our first set of tests investigates the impact on occupation-level labor demand and wage rates as a result of higher overall Generative AI exposure.  Next, we show that, holding total exposure constant, it is the occupations that derive their Generative AI exposure from core tasks that experience a decline in labor demand. We construct the number of job postings for each occupation-month from January 2022 to August 2023 from  granular Lightcast job posting data. We also obtain individual-level hourly wage rates from January 2022 to October 2023 from the Census Current Population Survey data. 

Our study contributes three key new findings regarding the labor market outcomes for different \textit{occupations} before and after the release of ChatGPT. First, occupations with higher Generative AI exposure unconditionally experienced reduced labor demand and a lower relative wage rate after the release of ChatGPT: A one-standard-deviation increase in Generative AI exposure is associated with an 8\% decline in job postings and a 0.6\% decline in the hourly wage rate. Second, the magnitudes of the effects of Generative AI exposure on job posting and hourly wage rates are \textit{66\% and 97\% greater}, respectively, if the occupations are more substitutable by Generative AI according to our approach, i.e. if occupational exposure is derived entirely from core tasks.  Likewise, consistent with the greater potential for complementarities when supplemental tasks generate an occupation's Generative AI exposure, the share of an occupation's exposure stemming from supplemental tasks, as opposed to core tasks, significantly weakens the above associations.  Third, the above findings remain when we examine \textit{within-firm}  occupational demand using granular job posting data, reinforcing our interpretation that the occupation-level results are driven by firms reorganizing their operations after the technology shock instead of, for instance,  variation in industry dynamics. In summary, these findings show that firms adjust their labor demand in response to the release of ChatGPT in a way that, on average,  suggests a substitution effect in the initial months, but with significant heterogeneity depending on the kinds of tasks within an occupation that are affected.

Our second sets of tests examine the technology-labor substitution channel for explaining the cross-section of the labor demand of \textit{firms} with high and low Generative AI exposure. This channel suggests that firms with a more exposed workforce may have a greater capacity to reduce reliance on exposed occupations, thereby decreasing costs, improving future profitability, and boosting firm value. To test this channel, we measure the shares of firms' Generative AI exposures that arise from their workers' supplemental tasks. We show that firms with higher Generative AI exposure unconditionally reduce job postings more for the occupations that are highly exposed to Generative AI.  These firms see an increase in analyst forecasts of short-run and long-run earnings per share and also experience greater increases in actual profitability in quarterly earnings after the release of ChatGPT. Our estimates show that when firms' Generative AI exposure is derived entirely from the core tasks of their workforce, the effects of Generative AI exposure on labor demand and profitability are more than twice as large as the unconditional average effects.  The impact of core-task Generative AI exposure on cumulative abnormal returns is also 75\% greater than the impact of overall exposure.  Our results for firms' labor demand, profitability, and market value strongly support that a labor-substitution channel is driving Generative AI's impact on firm value. 
 
Our study contributes to the literature on disruptive technologies' impact on firm hiring and firm valuation.\footnote{See \cite{greenwood1997long} for an early contribution on the long-run impacts of investment-specific technological change.} \cite{papanikolaou2011investment} and \cite{kogan2014growth} study the effects of investment-specific technological changes on asset prices. \cite{zhang2019labor} studies firms' exposure to routine-biased automation.  \cite{babina2024artificial} and \cite{babina2022firm} are key early contributions studying the effects of AI on firm growth, compensation, and workforce composition.\footnote{These studies using job-posting data up to 2018 shed light on the contribution of AI to firm outcomes even before the advances offered by more recent Generative AI models.}  See also \cite{webb2019impact} for the impact of AI on the workforce,  and \cite{acemoglu2022} for evidence of the effects of firm exposure to AI on hiring and skill demand over the 2010-2018 period. More recently,  \cite{brynjolfsson2025} study the effects of generative AI on U.S. labor markets and find that employment in exposed occupations has declined in relative terms since the release of ChatGPT, especially among younger workers (see also in \cite{lichtinger_generative_2025}). However, \cite{humlum2025} focus on effects within exposed occupations in Denmark and find no effects of generative AI adoption on hours worked or wages in that setting.  \cite{kelly2021measuring} study firms' exposure to disruptive technological shocks using patent textual data, and \cite{kogan2019technology} assess worker displacement from technological change over a very long sample. These two studies offer important insights into investors' and firms' responses to technological shocks using a long panel containing several innovation waves.   

We measure firms' exposure to Generative AI and assess investors' reaction to the technology shock upon its arrival.  We show that the release of ChatGPT in November 2022 is an observable and significant technology shock that created a substantive impact on firm valuation. As the stock market is forward-looking, the information contained in market prices can potentially inform firms and employees about where the technology is likely to be most disruptive.  Indeed, in the same month we first released our study, IBM, the company ranked \#1 in our exposure to Generative AI measure among the largest U.S. firms, announced it would halt hiring of 7,800 jobs.\footnote{We released our first draft to the SSRN on May 9, 2023, while Bloomberg reported the IBM announcement on May 1, 2023. See \url{https://www.bloomberg.com/news/articles/2023-05-01/ibm-to-pause-hiring-for-back-office-jobs-that-ai-could-kill}}  Timely assessment of the market's expectations of Generative AI's impact on firms can also help policymakers to effectively evaluate regulatory policies in response to the arrival of the new technology.  

This paper contributes to a large body of literature examining the heterogeneous effects of technological shocks on workers with different skills or tasks (see, for examples, \cite{krusell2000capital}, \cite{autor2003}, \cite{acemoglu2011}, \cite{acemoglu2018}, \cite{eisfeldt2013}, \cite{tuzel_economic_2021}, \cite{eisfeldt2022human}, \cite{kogan2023technology}, among others). A common empirical approach to measuring how substitutable capital is for labor after a technology shock is to assess whether the technology can more efficiently complete the tasks in that occupation at a lower cost.  We adopt this approach in our study and offer a novel extension.\footnote{Since the initial release of our study, other researchers have found that financial markets rapidly respond to generative AI news: for example, \cite{andrews2025} find that long-run bond yields fall around model release dates, and \cite{bertomeu2025} show that a ChatGPT ban in Italy led to a rapid drop in stock prices for AI-exposed firms.}  

We decompose our measure of task-level exposures to Generative AI into exposures of core versus supplemental tasks.  We argue that occupations with higher exposure stemming from core tasks offer more opportunities for capital to replace labor.  On the other hand, workers in occupations with exposure derived from supplemental tasks may exhibit more complementarity with Generative AI capital.  Our empirical results analyzing job postings and wage rates show that recognizing the core versus supplemental task distinction offers an improvement to the traditional approach to measuring task-level exposures and substitution effects.   Our core-task-based Generative AI exposure shows significantly stronger results than the overall task-based Generative AI exposure.  By decomposing occupations into core and supplemental tasks, we refine the distinction between task and occupation substitutability.   By aggregating up to the firm level, we distinguish between occupational and workforce substitutability.  We see both of these distinctions as key contributions of our work.

The paper proceeds as follows:  Section \ref{sec:data} describes our data and measures of firms' exposures to Generative AI.  Section \ref{sec:returns} presents the impact of the release of ChatGPT on the market value of firms with different Generative AI exposures. Section \ref{sec:mech} supports a labor-technology substitution channel by proposing and testing a novel methodology to identify workers' substitutability by Generative AI. Section \ref{sec:concl} concludes.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Data and Measure
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data, Measurement, and Stylized Facts} \label{sec:data}
We measure a firm's labor exposure to Generative AI in three steps, starting with task-level exposures, and then aggregating to the occupation- and firm-level exposures, respectively.   The Occupational Information Network (O*Net) database describes 19,265 tasks that make up the 923 occupations of U.S. workers.  Each occupation executes a subset of these tasks.  The task and occupational exposure measurement follow \cite{eloundou2023}.
To aggregate the exposures from the occupation level to the firm level, we use the Revelio Labs database to measure firm-level occupational employment shares. A summary of our three-step procedure, which we detail further below, is:
\begin{enumerate}
\item \textit{Task-level exposure:} We use Open AI's GPT 3.5 Turbo model to assign each of the 19,265 tasks in the O*Net an exposure to Generative AI by evaluating whether each task can be more efficiently completed by having access to the capabilities of LLM-based tools like ChatGPT. 
\item \textit{Occupation-level exposure:}  Aggregate from tasks to occupation exposures by averaging the task-level exposures within each of the 923 occupations.\footnote{We begin by equally weighting tasks within an occupation. In Section \ref{subsec:occsubcomp}, we exploit the weights and distinguish between core and supplemental tasks to shed light on the substitution and complementarity of occupation to the Generative AI technology.   } 
\item \textit{Firm-level exposure:}  Compute the firm-level exposures by weighted averaging the occupation-level exposures using each firm's occupational employment share from the Revelio Labs database as the weight.  
\end{enumerate}
    
\subsection{Measuring task exposure to Generative AI}\label{subsec:taskexposure}
 
\paragraph{Occupational task data} We consider an occupation to be a portfolio of tasks to be done. From the O*Net V27.2 database, we obtain the task statement for each task in an occupation, documented by practitioners or occupational experts.\footnote{This data can be accessed via the O*Net website at \url{https://www.onetonline.org}.}  A task statement is usually one sentence, and an occupation consists of 22 tasks on average. We code each of the 19,265 tasks as being exposed to Generative AI technologies or not using the task statement. 
 
\paragraph{Task scoring} We use OpenAI's GPT 3.5 Turbo model and the following algorithm to score each task $T$'s exposure $X^T$ to Generative AI, following the approach suggested and validated by \cite{eloundou2023}. This approach categorizes each task into one of the following three categories $X^T\in\{1, 0.5, 0\}$ in terms of its Generative AI exposure:

\begin{itemize}\item  \textit{Direct Exposure ($X^T=1$)} if using ChatGPT reduces the time required to complete the task by at least half.
\item \textit{Indirect Exposure ($X^T=0.5$)} if using ChatGPT would not reduce the time required to complete the task by at least half, but
additional software could be developed on top of the existing capabilities of ChatGPT or related LLMs that could reduce the time it takes to complete the task with equal quality by at least half.
\item \textit{No Exposure ($X^T=0$)} if using ChatGPT does not reduce the time required to complete the task by half while maintaining equivalent quality, or  using ChatGPT reduces the quality of the task's output.
\end{itemize}

Our classification uses the ``few-shot prompting'' technique and takes three steps. First, we create a system prompt that explains the classification exercise and describes each category. Second, we create two examples of user-assist prompts that showcase the expected output, where the user prompt asks ChatGPT to classify an example task and to explain its reasoning, while the assist prompt provides the example answers. Third, for each of the 19,265 tasks, $T$, we feed the GPT model with the system prompt, the two examples of user-assist prompts, and a new user prompt that includes the text of task $T$'s statement and occupation title. The model produces answers similar to the assist prompt in the examples, including the classification and a short explanation, allowing us to audit whether the LLM actually understands the prompt as intended and interprets the task correctly.  The Appendix \ref{sec:rubric} details our prompts and the classification procedure. 

Note that this classification method should \textit{not} be interpreted as requiring ChatGPT to have any kind of correct ``knowledge of its own capabilities.'' Instead, the categories for what kinds of capabilities state-of-the-art LLMs have are given by us to the model, as they were pre-defined by researchers in collaboration with OpenAI in \cite{eloundou2023}. That is, the right way to think about the role of ChatGPT here is as a research assistant mapping task statements into existing categories, which relies on its ability to interpret language, understand occupational contexts, and reason about which known LLM capabilities would be relevant for the task at hand. There is thus no need for ChatGPT to have oracular powers of prediction for ``which tasks \textit{it} could automate.'' Instead, the LLM is scaling an approach that could, in theory, be implemented using only human research assistants with sufficient occupational context for each task. 

However, the approach using GPT instead of human labeling has several important advantages. First, the GPT model is less subject to individual idiosyncrasies compared to human labeling because it leverages a vast amount of prior information that may be difficult for individual humans to master (\cite{gilardi2023}).\footnote{We further check the model consistency and show in Appendix Section \ref{sec:consistent}  that GPT reliably provides classifications that are highly consistent across different runs. We also check the confidence of the classification by requiring GPT to return a confidence score for its prediction, which shows ``high confidence'' in most cases. The GPT model has been increasingly used to classify content in recent academic studies, e.g., \cite{hansen2023} and \cite{lopez-lira_can_2023}. Appendix Section \ref{sec:validation} also validates the LLM-based scoring by comparing it to scores assigned by research assistants for a sub-sample, and showing that there is high alignment between human labels and LLM labels, with higher consistency between LLM runs than between human labelers.} Second, the GPT approach permits rapid scaling of the method to categorize the complete set of 19,265 task statements, which would likely be very time-consuming for human labeling (\cite{frey2017future}). Third, the approach also provides explanations for labeling, allowing for an auditing capability often unavailable in instances of human labeling. 

Of the 19,265 tasks, 14\% were categorized as directly exposed to ChatGPT, $X^T=1$. Table \ref{table:gpt_output} provides examples of tasks in this category and explanations. For instance, ``adjust sales scripts'' for telemarketers and ``write supporting codes for web applications'' for web developers.   We give these tasks an exposure score $X^T=1$ as they are directly exposed to Generative AI. Another 22\% were categorized as indirectly exposed to ChatGPT if appropriate software or applications based on the technology were developed, with $X^T=0.5$. For instance, ``review financial transactions'' for food service managers and ``identify (trading) opportunities'' for financial services sales agents.  Following \cite{eloundou2023}, we give a one-half exposure score for these tasks since their exposure to Generative AI is not as direct and requires further development of software and applications.\footnote{The results are similar if we use alternative discounts for the exposure score of tasks in the E2 category.} The rest of the tasks are categorized as not exposed, $X^T=0$. For instance, ``connect heating or AC equipment'' for installers and ``mentor new faculty'' for postsecondary business teachers. 

\begin{center}
--- Insert Table \ref{table:gpt_output} about here --- 
\end{center}


% March 29, 2023.
% E3: 121
% E2: 4210
% E1: 2619
% E0: 12315



 



 
\subsection{Measuring occupation exposure to Generative AI}\label{subsec:occexposure}

\paragraph{Scoring occupations' exposure to Generative AI} We next aggregate tasks' exposures to Generative AI to the occupation level. For each 8-digit Standard Occupational Classification (SOC) occupation from the O*Net, we calculate the share of the total number of tasks for each occupation that have either a direct or indirect exposure to Generative AI. Our measure of occupation-level exposure $X^O$ is the sum of task-level exposures $X^T$ for $T \in[0:19,265]$ within each occupation $O \in [1:923]$ divided by the total number of tasks in occupation $O$. That is,

\begin{equation}\label{eq:exp}
X^O=\frac{\sum_{T \in O} X^T }{\sum_{T \in O} \mathbbm{1}}. 
\end{equation}
We then aggregate the 8-digit O*Net occupation codes to 6-digit SOC codes using equal-weighted averages of each 6-digit code's 8-digit sub-codes to match the occupation-level exposure measure to firms' occupational employment data. Generally speaking, this measure captures the percentage of an occupation's tasks that can be more efficiently completed using ChatGPT and similar tools.\footnote{After aggregating from O*Net occupations, we have exposure scores for 778 SOC 2010 occupations, of which 709 can also be found in the LinkedIn data and are used in our analysis. The summary statistics below refer to this set.} 


\subsection{Occupation-level stylized facts}
In this section, we present summary statistics describing occupational exposures.  We note that 15\% of occupations in our data have zero exposure.  The average exposure for white-collar occupations is 40\%, while it is 9\% for blue-collar and service occupations.\footnote{This calculation is based on the commonly used classification of major SOC occupation groups 11-29 (Management, Business, Science, and Arts Occupations) and 41-43 (Sales and Office Occupations) as ``white collar'', and all other major occupation groups as blue-collar or service occupations. The reported percentages are 2022 employment-weighted averages of 6-digit SOC exposures within each group. For details on this aggregation, see \url{https://www.bls.gov/soc/soc_2010_class_and_coding_structure.pdf}.} We also show that Generative AI exposures are higher for occupational skill sets that are more cognitive, and that more exposed occupations tend to be at the higher end of the occupational wage distribution.  The latter facts show how the Generative AI substitution effect is likely to operate on a very different part of the labor force relative to prior automation waves.  

Panel A of Table \ref{tab:summary} shows that the mean and median Generative AI exposure of occupations, $X^O$, are 23\% and 18\%, respectively,  with a standard deviation of 21\%. The 10$^{th}$ and 90$^{th}$ percentiles of occupational exposure are 0\% and 53\%. The Appendix Table \ref{tab:highlowocc} lists the 20 occupations with the highest and lowest Generative AI exposure scores.\footnote{Note that the lowest score category only shows an alphabetically sorted subset of a larger set of occupations with zero Generative AI exposure. Overall, 15\% of occupations have zero exposure.} Occupations such as ``telemarketers'',  ``proofreaders and copy markers'',  and ``computer programmers'' have the highest Generative AI exposure scores.  This is intuitive as recent technological advances in Generative AI feature natural language-based conversations, translating texts between languages and styles, and generating functioning code based on high-level descriptions of a programming task.  On the other hand, occupations requiring more physical manual tasks, such as ``shampooers'', "installers and repairs'', and ``stonemasons'' seem not to be exposed to Generative AI. 

\begin{center}
--- Insert Table \ref{tab:summary} about here --- 
\end{center}

A large body of literature has explored how prior technologies such as computers, automation, and robots have affected different occupations over the past decades (e.g., \cite{autor2003}, \cite{acemoglu2011}, \cite{acemoglu2020robots}, among many others). Computerization  has been shown to replace primarily routine-task jobs, which are jobs that perform repetitive and codifiable tasks, such as production line assemblers and record keepers (\cite{autor2003} and \cite{acemoglu2011}). Robots have been shown to replace primarily programmable manual-task jobs such as machinists, material handlers, and welders (\cite{acemoglu2020robots}) and \cite{webb2019impact}). 

To examine whether occupations exposed to Generative AI are distinct from routine and manual jobs, we follow \cite{acemoglu2011} and construct scores for the level of non-routine-analytical, non-routine-interpersonal, routine-cognitive, routine-manual, non-routine-interpersonal, and non-routine-manual skills required for each occupation. For any given occupation, the skill-measure scores essentially measure how important each of the six skills is for executing its tasks.  Unlike our measure of exposure to Generative AI, which is truly task-based, \cite{acemoglu2011} use O*Net's importance metrics for several pre-defined skills within occupations to construct the scores for these six skill measures for each occupation.    See the Appendix  \ref{sec:skill_apx} for the detailed construction of the scores for these six skill measures.\footnote{For each occupation, the O*Net database not only provides the textual statements of each task the occupation performs, which is the data that we used to construct our Generative AI exposure measure, the database also provides a numerical ``importance'' score for a large number of pre-defined skills for each occupation. \cite{acemoglu2011} select certain pre-defined skills and aggregate them to measure an occupation's skill requirement in each of the six skill dimensions mentioned above. For instance, the measure of non-routine-analytical skill for an occupation is constructed as the average of the standardized importance score of three detailed O*Net skills, \textit{analyzing data/information, thinking creatively,} and \textit{interpreting information from others.}} 

Next, we study whether occupations' exposures to Generative AI are distinct from previously documented occupational exposures to computerization and robots.   Specifically, we regress an occupation's Generative AI exposure measure on its six occupational skill scores ($\text{Skill}^O_S$) in the following cross-sectional regression: 
\begin{equation} \label{eq:regskill}
X^O = \alpha + \sum _{S} \beta_{\text{S}} * \text{Skill}^O_{S} + \varepsilon^O.
\end{equation}
Figure \ref{fig:autor} shows the results.  We show that occupations with higher Generative AI exposure are more likely to involve non-routine cognitive analytical skills and routine cognitive skills,  and less likely to involve other non-cognitive skills. Hence, distinct from computerization which disrupts routine jobs, and robots which disrupt manual jobs, Generative AI tends to primarily affect cognitive jobs,  in particular those requiring non-routine analytical skills.\footnote{Using a similar regression setting, \cite{webb2019impact} shows that broadly-defined AI technologies before the recent advances in Generative AI also tended to disrupt cognitive non-routine analytical jobs, but not routine cognitive jobs.} Hence, one would expect that firms with more cognitive jobs in their occupational portfolio will be more disrupted by Generative AI.

We show in Figure \ref{fig:wage_exp_occ} that major occupation groups with higher exposures to Generative AI also tend to have higher wages.   This is in contrast to the recent automation wave that impacted low-wage occupations more.  Consistent with our finding, important recent work by \cite{kogan2023technology} studies the longer-term impact of breakthrough patents on workers' wages, and high-wage workers are impacted more negatively.

\begin{center}
--- Insert Figure \ref{fig:autor} about here --- 
\end{center} 


\begin{center}
--- Insert Figure \ref{fig:wage_exp_occ} about here --- 
\end{center} 

\subsection{Measuring firms' exposures to Generative AI} \label{subsec:firmgenai}
To measure a firm's exposure to Generative AI, we obtain data on firms' occupational employment from Revelio Labs, which collects information on job titles and employers from LinkedIn and other resume profiles and constructs occupation-by-firm employment counts.\footnote{See, for example, \cite{li2022employee} and \cite{chen2023talent} for more descriptions of the Revelio Labs data.} For each Compustat firm, we use its employment counts at the 6-digit SOC occupation level as of March 2022, the latest month in our Revelio data. A firm's Generative AI exposure is the weighted average of its occupations' Generative AI exposure, $X^O$.  That is, for each firm $f$, labor force exposure to Generative AI is computed as:
\begin{equation} \label{eq:firm_exp}
X^f= \sum_{O \in f} EmpShare_{f,O} \times X^O,
\end{equation}
where $EmpShare_{f,O}=\frac{emp_{f,O}}{emp_f}$ is the employment share of occupation $O$ in firm $f$. This procedure generates the Generative AI exposures 
 for 2,518 publicly traded firms in 2022. Intuitively, our exposure measure captures the fraction of labor tasks in the firm that can be more efficiently completed using Generative AI.
 
\subsection{Firm-level stylized facts}\label{sec:facts}
 
Panel B of Table \ref{tab:summary} reports the summary statistics.  The mean and median of firms' Generative AI exposures are both 35\%,  with a standard deviation of 8\%. The 10$^{th}$ and 90$^{th}$ percentiles of firm-level exposures to Generative AI are 27\% and 44\%, respectively, implying that labor exposure to Generative AI is a broad phenomenon.

Table \ref{tab:firm_gpt} lists the 15 firms among the top 100 largest U.S. firms by market capitalization with the highest and lowest exposure to Generative AI, respectively.\footnote{See Appendix Table \ref{apptab:firm_gpt} for the full list of the exposures for the 100 largest  firms in 2022, and Table \ref{tab:highlowind} for the exposures aggregated to the NAICS 3-digit industry level.} Although many IT firms, such as IBM and Intuit, not surprisingly have a large fraction of employees exposed to Generative AI,  we also find manufacturing firms, such as 3M, and administrative conglomerates, such as S\&P Global, in the high-exposure list The large U.S. firms ranked at the bottom of the exposure distribution include restaurants, such as Starbucks and McDonald's, retail firms, such as Target and Walmart, transportation firms, such as UPS, and manufacturing firms, such as Tesla, suggesting that these firms' activities require more manual or interpersonal tasks and have a smaller fraction of employees exposed to Generative AI. 

\begin{center}
--- Insert Table \ref{tab:firm_gpt} about here --- 
\end{center}
 
We next formally investigate the industry component of firms' Generative AI exposures. Figure \ref{fig:gpt_naics2} shows that the variation in firm-level Generative AI exposure has a substantial within-industry component where the industry is classified at the NAICS 3-digit level. While firms in industries such as ``data processing, hosting, and related services'' and ``professional, scientific, and technical services'' have high average exposures to Generative AI and firms in industries such as ``clothing and clothing accessories stores'' and ``food service and drinking places'' have low average exposures, there is considerable variation of firms' exposures within each industry. A variance decomposition shows that NAICS 3-digit industry differences explain only 31\% of the firm-level variation in exposure to Generative AI.  The rich within-industry variation in firms' exposures to Generative AI suggests that our labor-based measure captures firms' exposures to Generative AI that can be distinct from their products' exposures to Generative AI.  We explore labor versus product exposure effects in-depth in the next section. 

In the Appendix Table \ref{tab:firmgpt_char}, we also show that our measure of firms' exposures to Generative AI is not explained by other firm characteristics that have been shown to predict stock returns in the cross-section, such as size,  Tobin's Q,  ROA,  Labor Intensity,  and Asset Tangibility. Cross-sectional regressions of firms' Generative AI exposures on each of these variables yield adjusted R$^2$s between 0.6\% and 10.7\%.

%Finally, we also investigate how firms' exposures to Generative AI relate to other firm characteristics? Panel A of Table \ref{tab:firmgpt_char} shows that firms with higher exposure to Generative AI tend to be smaller, have greater Tobin's Q, and are less profitable. These findings are consistent with the notion that such small and high-growth firms tend to focus their workforce on cognitive tasks. Moreover, we also observe that firms with higher labor intensity, higher organizational capital ratio \cite{eisfeldt2013} and less tangible capital are more exposed to Generative AI.  We will thus control for these firm characteristics in our later analyses.   Panel B of Table \ref{tab:firmgpt_char} shows that the above associations between firms' Generative AI exposure and firm characteristics are not just a cross-industry feature but also exist within-industry,  albeit to a smaller degree. Hence, other firm characteristics may be a less confounding concern for our within-industry analyses later. 


\begin{center}
--- Insert Figure \ref{fig:gpt_naics2} about here --- 
\end{center} 
 
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Main Stock Market Impact of GAI
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
 
\section{Generative AI Exposures and Firm Value}\label{sec:returns}

\subsection{Empirical design}
We examine the impact of Generative AI on firm value by analyzing the relative returns, or changes in market value, of firms with high versus low exposure to Generative AI immediately following the release of ChatGPT.  We sort portfolios into quintiles based on stocks' labor exposures to Generative AI and compare the returns of the top ``Artificial" quintile to those of the bottom ``Human'' quintile.  We show that an AMH portfolio that is long the highest exposure firms and short the lowest exposure firms earns 0.45\% daily in the two weeks following the release of ChatGPT (0.44\% if we control for market exposures).   We argue, and provide supporting evidence, that these changes in value are consistent with changes in the expected future cash flows of firms based on labor cost savings.

By exploring changes in firms' market value, i.e., stock returns, our empirical design uses a first-difference method to control for time-invariant firm-level heterogeneity. By studying the alphas of the portfolios from asset pricing factor models, our setting controls for firms' exposures to time-varying priced risk factors. Finally, because we study relative returns, our study highlights the differences in differences of firm value following the release of ChatGPT across firms whose labor forces are more versus less exposed to Generative AI.  To rule out alternative channels, we corroborate our portfolio sorting results with standard event study regressions of stocks' cumulative abnormal returns (CAR) on firms' Generative AI exposures while controlling for other firm characteristics.  
 
We start by defining our event window.  We choose the two weeks from November 30, 2022, to December 14, 2022 (the release date and subsequent ten trading days) as our event window, and we label these two weeks as the ``\textbf{ChatGPT event period}.''  In choosing the event window, we make a tradeoff.  On the one hand, we want to have a window that is long enough for investors to digest the full cross-section of labor implications on firm value.   On the other hand, we want the window to be short enough to prevent our estimated stock returns from being contaminated by other related events.   The two-week window ensures enough power to ascertain the market's absorbtion of the complex effects of ChatGPT on firm values through their labor force exposures, however we provide results for a one-week window in the Appendix Table \ref{tab:5d_quintiles}.\footnote{In the Appendix Figure \ref{fig:prduct_vs_labor} we also show that the impact of the release of ChatGPT on IT producers occurred in one day, consistent with the industry effect being simpler than, and distinct to, the labor effects.}

Our test examines a joint hypothesis that the large language model can assess various tasks' exposure to ChatGPT (see Section \ref{subsec:taskexposure}) and that the financial market can respond to the assessment. Whether the joint hypothesis holds is an empirical question, however several facts indicate that the hypothesis is plausible for testing. First, the machine-generated task labels, validated in \cite{eloundou2023} and by ourselves, show high agreement with human labels (see Appendix Section \ref{sec:validation}). Second, the exposed tasks and occupations as listed in Table \ref{table:gpt_output}  and Appendix Table \ref{tab:highlowocc} appear intuitive; for example, proofreaders are expected to be highly affected by the release of ChatGPT.  Third, the release of ChatGPT has immediately garnered massive public attention. Figure \ref{fig:vol} plots the daily mentions of ``ChatGPT'' or ``GPT'' on Twitter around the ChatGPT public release date on November 30, 2023.  The figure shows that the daily mentions reached over 100K in just a few days after the release of ChatGPT and remained at 50K two weeks after the release. This pattern is consistent with both immediate public attention and continued discussion and information processing over time.\footnote{ChatGPT amassed 100 million users in just two months after its release, a milestone which took the World Wide Web 7 years, WhatsApp 3.5 years, Instagram 2.5 years, and Twitter 5 years to reach. See \url{https://economictimes.indiatimes.com/news/new-updates/chatgpt-witnesses-massive-rise-chatbot-gains-100-million-users-in-two-months/articleshow/98428443.cms?from=mdr}.} Finally, in the Appendix, we show that our results are robust to using a shorter (one-week) event window, or a longer (three-week) event window.\footnote{See Appendix Tables \ref{tab:5d_quintiles} and \ref{tab:15d_quintiles}.} 


\begin{center}
--- Insert Figure \ref{fig:vol} about here --- 
\end{center}

%To further distinguish our findings during the ChatGPT event period from trends in the stock returns of different firms, such as the momentum effect, we further provide a robustness check of the portfolio returns around the ChatGPT event period. Specifically, we define the days from December 15, 2022, to March 31, 2023, but outside the ChatGPT event period as the ``ChatGPT non-shock period.''. A non-result during the non-shock period would reinforce our confidence that the findings during the ChatGPT event period are driven by the impact of the release of ChatGPT.  

\subsection{Realized returns and Generative AI exposures} \label{subsec:mainreturn}
\paragraph{Portfolio sorts}   To measure the effect of firms' workforce exposures to Generative AI on changes in value during the ChatGPT event period, we form five portfolios based on our firm-level Generative AI exposure measure. Specifically, at the beginning of our sample period on November 29, 2022, we sort stocks traded on the NYSE exchange into five quintiles based on their Generative AI exposures. We use these NYSE breakpoints to assign non-NYSE stocks into the quintile bins. We compute the value-weighted daily returns of each portfolio as the average daily returns of stocks in the portfolio weighted by their previous day's market capitalization.\footnote{See Appendix Section \ref{sec:constructpf} for more details on the portfolio construction.}  We refer to the high-minus-low portfolio as the ``Artificial Minus Human'' (\textit{AMH}) portfolio, which represents the zero-net-investment portfolio that goes long high-exposure ($A$) stocks and shorts the low-exposure ($H$) stocks. 

Panel A of Table \ref{tab:robust_quintiles} shows the realized excess returns, i.e., the raw daily returns minus the daily risk-free rate, of the quintile portfolios sorted by firms' Generative AI exposures and also the long-short AMH portfolio during the ChatGPT event period.  The \textit{AMH} portfolio yields positive daily returns of 0.45\% ($t$-statistic $=3.53$) on average during the two weeks after ChatGPT's release. 
 
One concern might be that our results are driven by firms' differential exposures to risk factors.  We show that this is not the case.  In Panel B of Table \ref{tab:robust_quintiles},  we report the alpha of each portfolio after controlling for the market factor (i.e., the CAPM model). The market-adjusted alpha of the AMH portfolio shows very similar results with a point estimate of 0.44\% per day ($t$-statistic $=4.70$), suggesting that our main finding is not driven by firms' heterogeneous exposures to the market. In Panel C, we further control for the Fama-French 5-factor model (\cite{fama2015}) and again find similar results. The 5-factor adjusted alpha of the AMH portfolio is 0.35\% per day ($t$-statistic  $=3.85$).  

A related issue arises if the differential stock returns between the high and low Generative AI exposure portfolios are driven by different trends in the stock returns of the two portfolios ex-ante.  We show that this is also not the case.  In the Appendix Tables  \ref{tab:robust_quintiles_nonews} and \ref{tab:terciles_withinindustry_nonews}, we conduct a placebo test and examine the excess returns and alphas during periods immediately before and after our ChatGPT event period.  We do not find significant differences between the high and low Generative AI exposure portfolios. This absence of statistically significant differences in returns outside the ChatGPT event period supports our main findings during the ChatGPT event period being due to the impact of the release of ChatGPT.  


\begin{center}
--- Insert Table  \ref{tab:robust_quintiles} about here --- 
\end{center}

\paragraph{Time series of cumulative abnormal returns} We further visualize the differential impact of the release of ChatGPT  on high and low-Generative AI exposure portfolios by plotting the difference in cumulative abnormal returns (CAR) between portfolios in Figure \ref{fig:ts_mkt}. To do so, we first compute the cumulative abnormal returns of the top and bottom quintile portfolios in Table \ref{tab:robust_quintiles} using November 29, 2022 as the reference date.\footnote{Following the literature, we compute each portfolio's daily abnormal return as the portfolio's daily return minus the product of each portfolio's market beta (computed over the 6 months before the time window shown in the figure) and the daily market return, and we compute the CAR for each portfolio by accumulating its daily abnormal returns from November 29, 2022.} This figure represents the holding period returns of the long-short AMH portfolio at any given date in the two weeks before and three months after the ChatGPT event period. It is reassuring that we do not find a strong trend in the AMH portfolio either immediately before or after the ChatGPT event period, suggesting that the market actively reassessed the impact of Generative AI on firm value via our labor channel during the two weeks after the release of ChatGPT, when the Twitter mentions of ChatGPT were exceptionally high.\footnote{The  effects on valuations from the release of ChatGPT among tech firms seem to be mostly realized on the announcement day (Appendix Figure \ref{fig:prduct_vs_labor}), while the labor-exposure-based ``Artificial-minus-Human'' portfolio returns continue to  increase throughout the 10 trading day release period (Figure  \ref{fig:ts_mkt}), in line with the more complex information about labor effects taking longer to be incorporated into prices than product effects.} In Appendix Figure \ref{fig:apx_ts_mkt}, we extend the pre-period out to 3 months before the release and also observe no systematic pre-trend in the AMH returns. 

Prior to the announcement date, the correlation between the A and H portfolio abnormal returns is -0.54, while after the announcement, it is -0.31.  The negative correlation prior to the announcement may be due to different ex-ante exposures to technology shocks, as in \cite{kogan2014growth} and \cite{kogan2023technology}.  The change in the correlation between the two portfolios may also be due to a compositional effect of overall systematic risk as generative AI becomes a more important determinant of market-level cash flows (see \cite{babina2023}).  Our cash flow analysis in Section \ref{sec:cashflow_mechanism} using profits and analyst forecasts to show the magnitudes of the changes in realized and expected future cash flows suggests that the main effect on valuations is due to cash flows rather than discount rates, but we cannot rule out that both cash flow and discount rate effects may be present.  Indeed, the discount rate channel is an interesting avenue for future research.


The cumulative abnormal returns of the AMH portfolio remain high and do not reverse after the event period, suggesting that the revaluation is not short-lived. In fact, the AMH portfolio seems to have experienced another period of outsized returns in early March leading up to the release of GPT 4, in line with the anticipation of the release and functionality of this more capable model representing an additional increase in the expected productivity impact of Generative AI on exposed firms.\footnote{While the time series of returns suggests that the revaluation impact for the AMH portfolio may have been similar in the run-up to the GPT 4 release, we cannot repeat our event study analysis in that case, as the existence of the model was widely known in advance, and only the uncertainty about the exact capabilities and precise release date for the more advanced model was resolved during the run-up.}

% We observe that while the firms with low exposure to Generative AI had \textit{negative} market factor-adjusted returns of $\sim2.5$\% during the ChatGPT event period, firms with high exposure to Generative AI experienced a positive return of more than 2\%.  In summary, the AMH long-short portfolio generates a positive cumulative return of about 5\% during the ChatGPT event period.  
% We note that the overall market actually declined substantially during this two-week window, consistent with the performance of the ``Human'' leg of our AMH portfolio.\footnote{The S\&P 500 index dropped by 4.4\% from December 1, 2022 to December 15, 2022. See \url{https://www.google.com/finance/quote/.INX:INDEXSP?sa=X\&sqi=2\&ved=2ahUKEwiruL6e0fuAAxXGh-4BHW5MCd8Q3ecFegQILRAf\&window=1} .  Note that the overall market includes the middle three AMH quintiles, so A and H do not aggregate to the market, even when returns are not market-factor adjusted.} We extend the cumulative returns to the end of our sample and observe that the positive cumulative return of the AMH portfolio is sustained following the ChatGPT event period and reaches about 8\% on March 31, 2023.    The time series return plot shows that the Generative AI exposure returns are closely associated with the timing of the release of ChatGPT.\footnote{Note that GPT 4 was released on March 14, 2023.  The impact of this release, unlike that of the original ChatGPT, was widely anticipated. Investors, although unsure of the exact timing, appear to have priced its effects in in advance of the actual release date.  Thus, although the AMH returns around the release of GPT 4 are also visually striking, they do not lend themselves to a clean event study analysis.} Moreover, Figure \ref{fig:ts_mkt} clearly shows that there is no discernible pre-trend in the AMH returns before the start of our analysis sample:  the cumulative returns from September 1, 2022 to the ChatGPT release on Nov.   30th, 2022,  are -0.025\%.  This provides support for the assumption implicit in our event study that the low and high-exposure portfolios are comparable before the ChatGPT technology shock is realized.


\paragraph{Event study regressions controlling for firm characteristics}
We show that our finding of increased value for firms with greater labor exposures to Generative AI during the ChatGPT event period is robust to controlling for firm characteristics commonly used to explain the cross-section of returns.  Specifically, we run an event study regression of firms' cumulative abnormal returns in excess of market returns during the ChatGPT event period on their labor-based Generative AI exposure, and also firm characteristics, in the following specification:
\begin{equation} \label{eq:characteristics}
\text{CAR}_{i}  = \beta\times\text{GenAI Exp}_i + \gamma\times\text{Char}_{i}  +\varepsilon_{i}, 
\end{equation}
where $\textit{CAR}_{i}$ is firm $i$'s cumulative abnormal return during the ChatGPT event period (from November 30, 2022 to December 14, 2022), $\textit{GenAI Exp}_i$  is the firm's labor-based Generative AI exposure, and $\textit{Char}_{i}$ is firm characteristics, including size,  Tobin's Q,  ROA,  Labor Intensity,  and Asset Tangibility. We are interested in $\beta$, which measures the impact of the release of ChatGPT  on the value of firms with a higher labor-based Generative AI exposure relative to other firms while allowing a differential impact on firms with particular characteristics.  We utilize weighted least squares, weighting each stock by its market capitalization as of November 29, 2022, to be consistent with the value-weighted portfolio sorts.  

Table \ref{tab:het_panel} shows the results.  Column (1) provides the benchmark result without controlling for firm characteristics, which shows that firms with higher Generative AI exposures experienced a greater boost in firm value during the ChatGPT event period, consistent with our portfolio-sorting results.  The magnitude of the estimate suggests that a one-standard-deviation increase in the firm-level Generative AI exposure is associated with 1.7 pp higher cumulative abnormal returns over the event period,  which is comparable to the effect size estimated using the portfolio sorts.\footnote{The returns for a one-standard-deviation change are computed as $0.078\times 21.6 = 1.7$.  Note that the market cap weighted exposure scores of the firms in the highest and lowest quintile portfolios are 44.5\% and 26.1\%, respectively,  so the firm-level CAR[-1,10] event study estimate in Table \ref{tab:het_panel}  would predict a daily return difference of $(.445 - .261) \times 21.6 / 11 = 0.36$ pp for the portfolios, which is not far from the 0.45 pp  long-short returns estimated in Panel A of Table \ref{tab:robust_quintiles}. }  Columns (2)-(8) show that the effect of our Generative AI exposure remains highly robust with coefficients similar to the benchmark estimate after controlling for the effects of each firm characteristic separately or the effects of all firm characteristics jointly.\footnote{The Appendix Table \ref{tab:car_apx} shows that the results are also robust to controlling for NAICS 3-digit industry fixed effects and using alternative models for computing abnormal returns.} 

\begin{center}
--- Insert Table  \ref{tab:het_panel} about here --- 
\end{center}

\subsection{Product exposure versus  labor exposure to Generative AI}\label{subsec:withinindustry}
A key concern is that labor market effects may be correlated with firms' product market exposures to Generative AI.
The stock-market value of chip-maker NVIDIA more than doubled from the beginning of 2023 to September 19, 2023, which has been widely attributed to the company being a key supplier of chips used in data centers and for training Generative AI models.  We perform several tests to show that our labor-exposure results are robust to controlling for firms' product-market exposures to Generative AI.   To be clear, we do not claim that the release of ChatGPT  does not impact firms' products and services.  Instead, we provide strong support for the idea that the differential returns we document for firms with different labor force exposures to Generative AI are not driven by the product exposure channel.  %Labor and product market channels are not mutually exclusive. 
%While both channels are interesting, distinguishing the two helps understand the mechanism driving the AMH portfolio's high returns during the ChatGPT event period.  

\subsubsection{Importance of within-industry heterogeneity} \label{subsubsec:ind}
Our first robustness check, which controls for the product exposure channel, examines the within-industry variation in firms' Generative AI exposure in our portfolio sorting test.  This test takes the industry classification as a categorization of the product market. Hence, to the degree that product markets align with detailed industry definitions, a significant industry-neutral AMH portfolio return would suggest that our main findings in Section \ref{subsec:mainreturn} are not driven by firms' product exposures to Generative AI.

We have shown earlier in Figure \ref{fig:gpt_naics2} that firms' exposures to Generative AI vary substantially within industry.  Indeed, only 31\% of firm-level variation in labor force exposure to Generative AI can be explained by 3-digit industry fixed effects.  Here, we sort firms into portfolios based on their Generative AI exposures within industries. We consider two industry classifications.  The first one is the NAICS 3-digit industry classification,  which includes 46 categories with at least ten firms in our data. \cite{hoberg2016} show that the rich texts of firms' product descriptions in their 10K filings can more precisely separate product markets. We thus also adopt their 10K-based FIC50 industry classification as an alternative measure of industries. Given the more limited number of stocks within industries, we form tercile portfolios (instead of quintile portfolios) within each industry and then value-weight stock returns in the industry-neutral tercile portfolios.  

Table \ref{tab:terciles_withinindustry} shows the results.  Panels A1-A3 show the market-adjusted alphas for the tercile portfolios sorted by Generative AI exposures across all firms unconditionally, within NAICS 3-digit industries, and within FIC50 industries, respectively.  Using Panel A1 as the unconditional benchmark for the tercile portfolios, Panels A2 and A3 show that the within-industry AMH portfolios using both industry definitions also have large and statistically significant market-adjusted alphas during the ChatGPT event period.  The magnitudes of the within-industry alphas are also very similar to the alpha of the unconditionally sorted AMH portfolio in Panel A1. Panels B1-B3 show similar results when we examine the FF5-factor-adjusted alphas instead of the market-adjusted alphas. 

In summary, if industry classifications capture the segmentation of firms' products and services, then the within-industry findings suggest that the impact of Generative AI on firm value, as we described in our main findings in Section \ref{subsec:mainreturn} is not driven by firms' products' differential exposures to Generative AI. 

\begin{center}
--- Insert Table \ref{tab:terciles_withinindustry} about here --- 
\end{center}

\subsubsection{Results excluding the tech sector} 
Our results are also robust to excluding the tech sector altogether.  We follow \cite{acemoglu2022} and identify firms as potential tech firms if they are in the following two sectors: information sector (NAICS 51) and professional, scientific, and technical services sector (NAICS 54).\footnote{The 2023 U.S. Census Business Trends and Outlook Survey shows that these two sectors have the highest use of AI in their products. See \url{https://www.census.gov/library/stories/2023/11/businesses-use-ai.html}.} In Panel D of Table \ref{tab:robust_quintiles}, we report our baseline quintile sorting results excluding firms from these two sectors. We document a strikingly similar result to our main results when we exclude the tech sectors. In particular, the FF 5-factor-adjusted alpha for the AMH portfolio using non-tech firms is 0.38\% per day during the ChatGPT event period as compared to 0.35\% per day using all firms.  These results, along with our within-industry results, confirm that the labor impact of Generative AI is broad, and that Generative AI is a general-purpose technology. 

\subsubsection{Horseraces between labor versus  product exposures} \label{sec:product}
Next, we run horse race tests between our labor exposure to Generative AI and direct measures of product market exposures. By constructing these measures, we aim to directly identify firms that can benefit from an AI boom either because they are selling related products (e.g., cloud computing hardware and graphics processing units) or because they are using existing versions of AI-related technologies as direct inputs into their products and services.  Our product exposure measures may be of independent interest since we show they are related to firm returns; however, importantly, our labor exposure effects remain even when we control for these product market effects.

Our first measure of firms' product exposure to Generative AI follows \cite{hoberg2016} and many other prior studies and infers information about a firm's products from the business description section of a firm's most recent 10-K annual report. We then use GPT 3.5 Turbo to assess whether firms' business products involve enabling or scaling new Generative AI technologies or benefit from a direct incorporation of the new Generative AI capabilities as a functionality of their products.\footnote{Conceptually, this product-exposure channel differs from our labor-exposure channel as the former channel does not directly imply an impact of Generative AI on the firm's operation and production process.} We provide details in the Internet Appendices \ref{sec:productmeasures} and \ref{sec:productprompt}. This procedure generates a dummy variable that equals 1 if the answer is yes--the firm's annual report suggests product market exposure to Generative AI, and 0 otherwise. We label this measure \textit{GPT10K Product Exposure}. 

Our second measure counts the number of occurrences of AI-related keywords in the firm's business section in its 10-K report.  This keyword-count approach is consistent with the approach used in prior studies (e.g., \cite{webb2019impact} and \cite{babina2024artificial}), and it generates a continuous measure instead of the binary value obtained in our first product exposure measure. We label this AI keyword-based measure \textit{Count10K Product Exposure}. 

Our third measure adopts the list of firms recently classified as ``near-term beneficiaries of AI'' by the investment bank Goldman Sachs.\footnote{See Goldman Sachs US Equity Views, August 21, 2023,   ``\textit{The (AI) trade after the trade: Identifying potential long-term EPS beneficiaries of AI adoption}'' available from \url{https://research.gs.com/}.    For a publicly accessible write-up of the results of the study,  see, for instance,  \url{https://markets.businessinsider.com/news/stocks/goldman-sachs-reveals-long-term-ai-portfolio-here-are-the-50-stocks-to-monitor-1032573922}. } This measure identifies stocks with business models that are directly exposed to the development of AI and which, as a result,  are expected to experience an immediate increase in earnings. The list includes makers of semiconductors and related equipment,  and large technology companies with extensive cloud computing infrastructure or business models that are likely to benefit from incorporating AI capabilities into their products.  This measure is explicitly focused on \textit{ex post} identifying stocks with high recent returns due to their earnings potential increasing as a result of the AI boom, and it may thus account for firms' product exposure to AI beyond firms' discussion in past annual reports. We label this measure from Goldman Sachs \textit{GS Product Exposure}.  

Finally, our fourth measure uses the share of workers at a firm who have AI skills on their resumes constructed by \cite{babina2024artificial}, who show that this measure effectively predicts AI-related product innovations and R\&D spending during the pre-ChatGPT wave of AI advancements. We use a firm's most recently available AI skill share in the data from \cite{babina2024artificial} to proxy for its prior investment in using AI-related tools pre-ChatGPT and its susceptibility to adopt new AI tools in their products post-ChatGPT.\footnote{We thank \cite{babina2024artificial} for making the data publicly available. The last year of available skill share data is 2021 for most firms in the sample. While their measure also derives from firms' labor heterogeneity, their approach uses keywords to account for firms' employees' AI skills, and their measure aims to capture firms' AI investment. In contrast, our labor-based Generative AI exposure accounts for firms' employees whose tasks can be more efficiently completed by using Generative AI, and thus the firms' \textit{labor exposure} to Generative AI.} We label this measure from \cite{babina2024artificial} \textit{BFHH Product Exposure}.  

How well do these four proxies for firms' product exposure to Generative AI capture the potential for firms to adopt recent AI in their products and services after the release of ChatGPT?  To answer this question, we use data from the U.S. Census Business Trends and Outlook Survey, which reports data on the share of firms using ``Artificial Intelligence (AI) in producing goods and services'' for a number of industries after August 2023.\footnote{See details about the survey and data at \url{https://www.census.gov/hfp/btos/about}.} We thus aggregate our four proxies of product exposure to Generative AI to the industry level and compare our proxies with the intensity of industries' actual use of AI in their products after the release of ChatGPT. Appendix Table \ref{fig:btos} shows that all four proxies correlate strongly with the Census survey results at the industry level. Hence, we argue that these four proxies capture firms' product exposure to Generative AI reasonably well. Moreover, they capture different dimensions of product exposure, as evidenced by the fact that they are only modestly correlated with one another - see Appendix Table \ref{tab:corr}.

We investigate whether our finding of increased value for companies with greater labor-based Generative AI exposure is confounded by our measure's relation with firms' product exposure to Generative AI. Specifically, we run an event study regression of firms' cumulative abnormal returns during the ChatGPT event period on their labor-based Generative AI exposure and also various proxies for firms' product exposure to Generative AI: 
\begin{equation} \label{eq:CAR_Product}
\text{CAR}_{i}  = \beta\times\text{GenAI Exp}_i + \gamma\times\text{Product Exp}_{i}  + FEs  +\varepsilon_{i}, 
\end{equation}
where $\textit{CAR}_{i}$ is firm $i$'s cumulative abnormal return during the ChatGPT event period, $\textit{GenAI Exp}_i$  is the firm's labor-based Generative AI exposure, and $\textit{Product Exp}_{i}$ is the proxy for the firm's product exposure to Generative AI.  We are interested in $\beta$, which measures the impact of the release of ChatGPT  on the value of firms with a higher labor-based Generative AI exposure relative to other firms, while allowing for a differential impact on firms with a particular product exposure to Generative AI. Similar to our estimation in equation \eqref{eq:characteristics}, we weigh each stock by its market capitalization as of November 29, 2022. Finally, we include NAICS 3-digit industry fixed effects so that the horseraces are run within industries, further controlling for any remaining product market effects. Moreover, all product exposure measures are standardized, except \textit{GS Product Exposure} and \textit{GPT10K Product Exposure}, which are binary variables. 

Table \ref{tab:product_panel} reports the results of the cross-sectional regression in equation \eqref{eq:CAR_Product}.  Column (1) restates the within-industry importance of our effects documented in Section \ref{subsubsec:ind}, showing that the coefficients of our labor-based Generative AI exposure are similar when controlling for NAICS 3-digit industry fixed effects. Columns (2)-(6) show the horse race results by controlling for firms' product exposure to Generative AI and industry fixed effects.  Two observations stand out: First, three out of four proxies for firms' product exposure positively boost firm value during the ChatGPT event period. This result supports findings in the prior literature that AI technologies improve firms' product functionality and innovations (\cite{babina2024artificial}).

Second, Table \ref{tab:product_panel} shows that firms' labor exposure to Generative AI is robustly related to increases in firm value during the ChatGPT event period, even after controlling for the proxies for firms' product exposure to Generative AI individually in Columns (3)-(5) or jointly in Column (6). The economic magnitude of the CAR associated with the labor exposure to Generative AI is only modestly attenuated, suggesting a 1.4 pp higher event period CAR for firms with a 1 SD higher Generative AI exposure, even when controlling for all product market exposure proxies jointly. 
 
\begin{center}
--- Insert Table \ref{tab:product_panel} about here --- 
\end{center}



\subsection{The role of firms' data assets} \label{subsec:datavalue}
A salient feature of Generative AI is its superior capability to learn from and work with firms' data to upgrade their operations and save labor costs, such as by training customer service chatbots,  automating workflows,  improving predictions and analytics, and performing many other applications (\cite{caserta2023}). For instance, to adopt Generative AI tools and improve the chatbots for internal customer service knowledge management, firms need internal data from past interactions and the technology to upgrade existing labor-intensive customer service systems. 

In this section, we test whether our stock return results are more pronounced among firms relying more heavily on data assets, which can better incorporate Generative AI technologies. Measuring firms' data assets is challenging (\cite{veldkamp2023valuing}).\footnote{See seminal works on the measurement of firms' data assets from \cite{begenau2018big}, \cite{farboodi2019big}, \cite{eeckhout2022data}, \cite{farboodi2023}, \cite{abis2023}, among others.} We construct two proxies for firms' reliance on data assets that capture different aspects of firms' ability to use Generative AI capabilities. Our first measure uses the text of the business description in a firm's 10-K annual report. We again apply the GPT model to assign a score of 0 to 3 to indicate whether the firms' business descriptions provide no, little,  moderate,  or high evidence of data that would be valuable for Generative AI-based analysis. The model is instructed to base its assessment on mentions of six data-related topics such as data collection,  data utilization,  data infrastructure \& management, and data regulation and privacy (see more details in the Internet Appendices \ref{sec:datameasure} and \ref{sec:dataprompt}).  The overall score assigned by the model is our first measure of the firm's reliance on data assets.  We label this proxy \textit{10K Data Assets}. We think of this measure as capturing the degree to which the nature of a firm's business practices and operational choices expose it to large volumes of customer data and require data management capabilities.

Our second measure follows \cite{abis2023} and calculates firms' share of labor skills in data management. In particular, we first measure the likelihood that an occupation is a  ``data management'' position by analyzing whether the requirements listed in each occupation's job postings in recent years correspond to data management skills classified by \cite{abis2023}.  Job postings are classified as suggesting a data management-intensive role if at least three of these skills are mentioned.  For each occupation,  we compute the share of data management-intensive job postings as a proxy for the propensity of that occupation to be a data management  position.\footnote{Occupations' data management intensity is 9\% correlated with their Generative AI exposure.} Then, we aggregate the data management intensity from the occupation level to the firm level using the firm's occupational employment shares from the Revelio Labs database, similar to our calculation of firms' Generative AI exposure (see more details in the Appendix \ref{sec:datameasure}).  The intuition for this measure is that whether a firm has many workers responsible for managing data is a good proxy for whether it has a lot of valuable data to be managed--and for the firm's ability to handle data-based technologies in general.  We label this proxy \textit{AV Data Assets}.\footnote{See Appendix Table \ref{tab:corr} for the raw correlation of the data asset measures with the firm-level Generative AI exposure, and the product market exposure measures.} We think of this measure as capturing the degree to which a firm's labor force is likely to have the skills to handle the data management needs of Generative AI models deployed in the firm at scale. That is, where the \textit{10K Data Assets} capture the firm's access to data, \textit{AV Data Assets} capture its workforce's data handling capabilities.

Equipped with the two proxies for firms' reliance on data assets, we test whether our stock return results are more pronounced among firms with a greater reliance on their data assets.  In particular, we regress firms' cumulative abnormal returns on the interaction between their Generative AI exposure and the proxies, one at a time. Table \ref{tab:datavalue} shows the results. The positive coefficients of the interaction terms suggest that firms with greater access to data assets have significantly higher returns to Generative AI exposure during the ChatGPT event period. This finding supports our conjecture that firm value disproportionately accrues to firms with labor exposure to Generative AI \textit{and} significant data assets, allowing them to better adopt Generative AI technologies and upgrade their labor operations. An alternative explanation for these data asset effects could be that larger firms are better able to pay the fixed costs of adopting Generative AI technologies and also tend to have greater data assets. In Appendix Table \ref{tab:datasize}, we show that this does not seem to be the case: first, column (1) shows that the exposure effects do not vary significantly across firm sizes; second, in a horserace that allows the exposure effects to vary with firm employment size and data assets (see columns (2) and (3)), there is no significant variation of the effects with firm size, and the data asset interaction coefficients are basically unchanged relative to Table \ref{tab:datavalue}. On the other hand, if firms with greater data assets face lower fixed costs when adopting new technologies, then fixed costs may still partially account for the observed heterogeneity.

 We also note that data assets can be firm-specific, making existing incumbent firms' potential gains from adopting Generative AI larger, and less likely to be competed away by new entrants. Our finding that the stock returns to Generative AI exposure during the ChatGPT event period are greater among firms with greater reliance on data assets is consistent with this view. 

  
\begin{center}
--- Insert Table \ref{tab:datavalue} about here --- 
\end{center}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Mechanism --- CashFlow Channel
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Inspecting the Mechanism: Future Cash Flows} \label{sec:cashflow_mechanism}

%: Generative AI Exposure and Future Cash Flows}
%\section{Inspecting the Cash Flow Channel}

% 

The divergence in values between firms with high and low workforce exposure to Generative AI upon the release of ChatGPT reflects investors' expectations of a differential effect on firms' discounted future cash flows. Prior studies suggest that new technologies like AI can potentially help firms organize more efficiently and generate more future cash flows (e.g., \cite{babina2022firm}, \cite{babina2024artificial}, \cite{hampole_artificial_2025}, and \cite{mishra_artificial_2022}). In this section, we inspect this future cash flow channel for our firm value results. In particular, we provide evidence that both analyst forecasts of firms' earnings and actual firm profitability increase more after the release of ChatGPT for firms with greater Generative AI exposures.
 
The release of ChatGPT may also differentially affect firms' risk premia and thus their discount rates, which could potentially contribute to our firm value results.\footnote{A large body of literature shows that new technologies can cause significant employment and income risk for employees in exposed jobs through job displacement (e.g., \cite{autor2003}, \cite{acemoglu2022}, \cite{kogan_technological_2021}, \cite{kogan2023technology}, \cite{garleanu_displacement_2012}, and many others) or empowering the less talented workers to challenge more talented peers (e.g., \cite{dellacqua_navigating_2023} and \cite{brynjolfsson_generative_2025}). Such risk can incentivize employees to hedge their income risks by purchasing the stocks of firms that benefit from new technologies, which reduces those firms' discount rates.} Assessing potential changes in firms' expected returns during the shock period directly is challenging due to the short time series.  However, our evidence from cash flow forecasts suggests that a discount rate channel is unlikely to be the main driver of our firm value results.\footnote{The literature typically proxies for firms' expected returns using average realized returns. Such an approach requires a long time series of data to ensure that the realized return, on average, reflects investors' expected returns. An important study is \cite{babina2023}, who examines changes in the systematic risk of firms with high and low investment potential in AI from 2010-2018. In contrast, our study focuses on firms' realized returns shortly after the release of ChatGPT. \cite{pastor_dissecting_2022} warn that realized returns do not reflect expected returns during the shock periods in the context of explaining green stocks' higher returns over brown stocks.} The magnitude of ChatGPT's cash flow impact we estimate is nearly identical to the impact on firm value across firms with high and low Generative AI exposure, consistent with the cash flow channel having dominant explanatory power.  Additionally, in theory, discount rates for high-exposure firms could increase (due to an increase in systematic risk) or decrease (if high-exposure firms are a hedge for investors exposed through their labor income).  In recent work, \cite{babina2023} find that firms with higher AI investing opportunities see a greater increase in their systematic risk.   An increase in systematic risk for exposed firms would be expected to lead to a corresponding decrease in their value due to increased discount rates, along with higher average returns in the longer run.  Thus, these recent findings also cut against a discount rate channel for our findings regarding the increase in value of highly exposed firms upon the release of ChatGPT.

\subsection{Firms' cash flow forecasts and Generative AI exposure}  
We obtain monthly forecasts of firms' future earnings from the Summary Statistics of the I/B/E/S database. Following the standard approach in the literature (e.g., \cite{bordalo_long-term_2024}), we measure the consensus analyst forecasts for each firm's future earnings based on the median forecasts in the month. We examine forecasts for firms' next year earnings per share (EPS) (i.e., the EPS for firms' fiscal year ending in December 2023) as well as the long-term forecast of the growth rate in EPS (LTG).\footnote{We choose only firms where the fiscal year ends in December to ensure the forecast horizons are unaffected by different fiscal year ending months across firms. Over 80\% of firms in our sample have fiscal years that end in December.} 

With this firm-month level data, we examine changes in forecasts for firms' future earnings after the release of ChatGPT on November 30th, 2022. We regard the consensus forecasts reported in October 2022 as the pre-period forecasts. We use the consensus forecasts reported in January 2023 as the post-period forecasts to allow all updates to be fully reflected in the data.\footnote{We inspect the forecasts only one month after ChatGPT's release (i.e., January 2023) to ensure the changes in earnings forecasts are not affected by news about ChatGPT's future updates. The results are robust if we choose a wider pre- and post-period window though.} Next, we estimate a difference-in-differences model that regresses the forecasts for either short-term EPS or long-term earnings growth on an interaction between a post-ChatGPT dummy and a continuous measure of Generative AI exposure at the firm level. We control for firm fixed effects to ensure our estimate reflects the within-firm \textit{update} on forecasts and month fixed effects to control for aggregate economic conditions. We cluster all standard errors by firm. 

%such that the estimates show whether the post-ChatGPT period was associated with different earnings forecast as a function of Generative AI exposure, controlling for average differences in predicted earnings between firms, and common time trends.

The results are shown in Table \ref{tab:ibes}: Column (1) shows that the consensus forecasts for firms' short-term future EPS update more positively after the release of ChatGPT  for firms with higher Generative AI exposure. Firms with a one-standard-deviation higher Generative AI exposure experience a \$0.076 $(=0.066\times1.14)$ higher update in the forecast of their 2023 year-end cash flows after the release of ChatGPT. Relative to the sample mean of the respective forecasts prior to the release of ChatGPT, this effect corresponds to a $1.8\%$ higher increase in the first year-end EPS forecasts. This magnitude is nearly identical to our firm value results that firms with a one-standard-deviation higher Generative AI exposure experienced a $1.7\%$ greater stock returns, as shown in Section \ref{subsec:mainreturn}. 

We can interpret this finding in a simple discounted future cash flow framework: if we assume that the release of ChatGPT does not affect the low-GenAI exposure firms, and that it permanently raises each future year's cash flows for the high exposure firms by the same percentage, then the above estimate suggests that the cash flow channel fully explains our firm value results. On the other hand, if the large impact on the first year's cash flow is transitory, there can still be room for the discount rate channel. While 65\% of our final sample does not have the long-term earnings growth forecast data, we inspect the impact on LTG across firms with high and low Generative AI exposure using the remaining 35\% of the sample. Column (2) of Table \ref{tab:ibes} shows that the forecast update on long-term earnings growth is also more positive for firms with higher Generative AI exposure. Hence, it is unlikely that analysts expect the impact of ChatGPT on firms' future cash flows to be transitory. 

In summary, these findings suggest that the heterogeneous impact of the release of ChatGPT for firms with high and low Generative AI exposures is consistently observed in both firms' values and their forecast future cash flow. 

 

\subsection{Firms' realized cash flows and Generative AI exposure} 
We next provide additional support by examining the impact of the  release of ChatGPT  on realized cash flows for firms with high and low Generative AI exposure. We compute firms' quarterly profitability using Compustat quarterly data, where profitability is the firm's revenue minus the cost of goods sold normalized by its total assets (\cite{novy2013}).\footnote{\cite{novy2013} highlights that this gross profitability is ``the cleanest accounting measure of true economic profitability. The farther down the income statement one goes, the more polluted profitability measures become.''} Our sample includes 22,403 firm-quarter observations of firms in our stock return analyses from 2022Q1 to 2024Q3. 

Consistent with our findings on cash flow forecasts and firm values, Column (3) in Table \ref{tab:ibes} shows that the firms with higher Generative AI exposure show higher  gross profitability after the release of ChatGPT. A one-standard-deviation increase in Generative AI exposure is associated with a 0.13\% ($=0.078 \times 1.71\%$) increase in the gross profitability rate. While many factors can lead expected and realized profitability to differ, our consistent findings on realized profitability, forecast earnings, and stock market valuation support the cash flow channel for our stock return results. 

Finally, the Appendix Table \ref{tab:ibesrev} further shows that these profitability results are unlikely to be driven by a revenue channel, as we do not observe significant responses of firms' forecast and actual revenues to the release of ChatGPT associated with their Generative AI exposure. This finding supports a cost-saving mechanism, which we examine in the next section. 
 
\begin{center}
--- Insert Table \ref{tab:ibes} about here --- 
\end{center}


\section{Generative AI: Labor Complement or Substitute?}\label{sec:mech}
A firm's workforce exposure to Generative AI could mean that their workers can be substituted by the technology or complemented by it.\footnote{A large body of literature has studied the complementarity and substitution effects of technologies on workers in the context of automation (\cite{autor2003}, \cite{autor2006}, \cite{frey2017future}, and \cite{acemoglu2011}), robots (\cite{acemoglu2020robots}), artificial intelligence (\cite{webb2019impact}, \cite{agrawal2019artificial}, and \cite{babina2022firm}), and disruptive technologies in general (\cite{krusell2000capital}, \cite{kogan2019technology} and \cite{bloom2021diffusion}).}   Both substitution and complementarity channels can potentially improve future cash flows and market values for firms with higher Generative AI exposure.  We find that, at the firm-level, the labor substitution channel is dominant and tends to be most consistent with our findings on cash flows and stock returns.  Dissecting the labor complementarity versus substitution channels shortly after the arrival of the new technology is challenging.  We develop a conceptual framework offering a novel approach for interpreting Generative AI exposure as labor-complementing or substituting.   We combine recent job posting data and individual wage data to validate our approach, and show, using our refined measures of core versus supplementary exposures, that core task exposure leads to lower wages and fewer jobs posted while supplementary task exposures is associated with higher wages and better employment outcomes.        

\subsection{Challenges for timely assessing new technologies' impact on workers}

Detecting whether a new technology will substitute for or complement labor shortly after the arrival of new technologies is challenging for at least two reasons. First, a large body of literature shows that the diffusion of major technologies in history is usually remarkably slow due to adoption frictions, such as limited attention of businesses to the new technologies (\cite{greenwood_third_1999}).\footnote{The diffusion of new technologies is particularly slow in the initial periods after the technologies are available, constituting an S-curve for technology diffusion (see many examples in \cite{greenwood_third_1999} and \cite{manuelli_frictionless_2014}). As a result, many seminal studies on the impact of major technology shocks were highly retrospective rather than conducted soon after the arrival of the technologies.} This lack of attention problem appears less relevant for the diffusion of ChatGPT. Previously, we showed that the release of ChatGPT garnered massive immediate public attention on social media. Here, we further document that the release of ChatGPT also attracted the attention of \textit{firms}. In Figure \ref{fig:calltrends}, we measure firms' mentions of Generative AI in their quarterly earnings calls. Panel A shows that the share of firms mentioning Generative AI rose substantially from less than 5\% before ChatGPT's release to 27\% in the first quarter after the release.\footnote{In contrast, the share of firms mentioning other related topics, such as engineering, does not increase. See the Appendix Figure \ref{fig:calltrends_apx} for this result.} More importantly, Panel B shows that firms with a \textit{higher} Generative AI exposure see a \textit{stronger} increase in the likelihood of mentioning Generative AI after ChatGPT's release. These findings suggest that the release of ChatGPT likely garnered the attention of firms to evaluate how Generative AI can be applied to affect their labor, operations, and profits.\footnote{In fact, \cite{schubert2025} shows that firm exposure strongly predicts firm-level hiring for generative AI skills after the release of ChatGPT.}

Second, the fact that a worker's \textit{tasks} are substituted by Generative AI does not necessarily mean the worker's \textit{occupation} can or will be substituted by Generative AI.  Even if many tasks in a given occupation are highly exposed to being executed by Generative AI, an occupation overall may be less exposed to these substitution effects because the exposed tasks are not core tasks, but are rather supplementary tasks through which Generative AI can increase a worker's productivity.  For instance, while proofreaders and product managers both have some tasks that can be completed more efficiently by ChatGPT, ChatGPT may substantially reduce the demand for proofreaders but may make product managers who use it to complete their supplementary tasks more productive. The distinction between task exposure and occupation exposure represents an under-appreciated challenge in the study of the effects of automation.  Our utilization of the core versus supplementary task distinction offers a novel way to uncover differences between occupational exposures and the raw share of exposed tasks within occupations that has been studied previously (eg. \cite{eloundou2023}).  Prior studies on automation also compute an occupation's susceptibility to computer substitution based on an occupation's routine task share  (e.g., \cite{autor2003}, \cite{acemoglu2011}, and \cite{zhang2019labor}). In what follows, we propose that an occupation's substitutability by Generative AI depends not only on the share of its tasks that are substitutable by Generative AI, but also on whether the exposed tasks are \textit{core} or \textit{supplemental} to the occupation. 


\begin{center}
--- Insert Figure \ref{fig:calltrends} about here --- 
\end{center}

\subsection{Conceptual framework: Task-exposure vs.  job-exposure to Generative AI} \label{subsec:eos}

\paragraph{Conceptualizing core versus  supplemental tasks} An occupation is a bundle of tasks.  As such, some tasks being automated are not necessarily equivalent to the full job being automated. Our key point is that whether automation substitutes for or complements an occupation depends on how essential the automatable tasks are to the occupation's expected functionality. In particular, \textit{core tasks} represent the most fundamental duties an employee in the occupation is expected to perform. For instance, ``correct or record omissions, errors, or inconsistencies found'' is a core task for proofreaders. If firms can adopt ChatGPT to complete this task at a lower cost, proofreaders may face a potential decline in demand and future wages as they lose their competitive advantage in performing their most expected fundamental duties to ChatGPT.\footnote{From the firm's perspective, this labor-technology substitution could happen either through a reduction in the number of workers in that occupation or by ``unbundling.'' \cite{agrawal2023} note that if AI replaces some tasks that were previously bundled into jobs requiring scarce skilled workers, firms may unbundle the rest of the tasks into new jobs for workers without those specialized skills, enabling the firm to employ fewer skilled workers.} 

In contrast, \textit{supplemental tasks} are additional tasks or duties associated with the core tasks but are not considered critical or central to the occupation. For instance, ``prepare operating and maintenance manuals, studies, or reports'' is a supplemental task for architects. If firms can adopt ChatGPT to complete this type of task more efficiently, architects may have a greater bandwidth to work on their core tasks such as ``represent clients in obtaining bids or awarding construction contracts.'' As long as the demand for architects' services is not fully satiated, architects may produce more output per unit of effort with ChatGPT helping with the supplemental tasks.\footnote{If the overall demand for architects' services is fully satiated, then ChatGPT will result in an oversupply of architects' services and may still reduce the demand for the occupation.} In this case, architects may see increased demand in the labor market and higher future wages. 

This distinction between core and supplemental tasks' exposure to Generative AI suggests that the impact of Generative AI on jobs has two layers---it is ``\textit{not just how many tasks but which tasks}'' as it was put by David Autor in his 2024 \href{https://economics.mit.edu/sites/default/files/2024-09/Autor-Schumpeter-Expertise-20240829-handout.pdf}{Joseph Schumpeter lecture}. Specifically, while an occupation's Generative AI exposure in Equation \eqref{eq:exp} characterizes the intensity of the technology's impact on the occupation, the share of the exposure deriving from the occupation's core versus  supplemental tasks can help to capture the substitution versus  complementarity of the technology's impact on the job. 


\medskip 

\noindent \textsc{Prediction:} \textit{Occupations with a higher Generative AI exposure and also a higher share of the exposure deriving from core (supplemental) tasks experience lower (higher) labor demand and wages after the release of ChatGPT.} 
 
\paragraph{Implications for firm valuation} 

In principle, both the labor-complementing and labor-substituting mechanisms could contribute to the greater increase in market value for firms with a higher Generative AI exposure after the release of ChatGPT. If the firm's Generative AI exposure is primarily due to its high fraction of occupations with core tasks substitutable by Generative AI, the firm can potentially save labor costs by substituting the new technology. The cost-saving can potentially increase their future profits and thus positively impact their current firm value. If the firm's Generative AI exposure is primarily due to its high fraction of occupations with supplemental tasks substitutable by Generative AI, the firm can expect a boost from the productivity of its labor, allowing the firm to expand and potentially increase its market value. Which channel drives the post-GPT labor market and our firm value results is an empirical question. We thus rely on data to shed light on the mechanism. 

Before we head to further empirical analyses, we emphasize an important note that the above arguments rely on the assumption that increases in future cash flows cannot be fully appropriated by workers or competed away in the product market. Literature suggests that labor markets and product markets may not be perfectly competitive. For instance, many prior studies document that firms possess certain monopsony power in the labor market (e.g., \cite{schubert2020}, \cite{berger2022labor}, \cite{yeh2022monopsony}, and \cite{seegmiller2021valuing}) and that measures of product market competition in the U.S. have been low and declining (e.g., \cite{gutierrez2017declining} and \cite{akcigit2021ten}). 

 
\subsection{Measuring core and supplemental task exposure to Generative AI}

\paragraph{Task definition} We obtain the classification of each task as core or supplemental for each occupation directly from the O*Net database. According to the \href{https://www.onetonline.org/help/online/scales#score}{O*Net description}, core tasks are \textit{critical to the occupation}, while  supplemental tasks are \textit{less relevant and/or important to the occupation}.\footnote{O*Net defines a task as \textit{core} for an occupation if the task has a relevance score above $67\%$ and an importance rating above 3.0 for the occupation and as \textit{supplemental} if otherwise. See details at \url{https://www.onetonline.org/help/online/scales\#score}. For an average occupation in the O*Net V27.2 database, 76\% of tasks are core and 24\% of tasks are supplemental.} 

\paragraph{Occupation-level measure} To test the prediction from our conceptual framework above, we distinguish whether an occupation's Generative AI exposure derives from its core or supplemental tasks. Specifically, we measure the share of an occupation's Generative AI exposure deriving from its supplemental tasks as 
\begin{equation}\label{eq:suppdefine}
ShareSupp_o=\frac{\sum_{T \in (o|Supplemental)} X^T }{\sum_{T \in o} X^T}, 
\end{equation}
where the numerator is the sum of task exposures to Generative AI for occupation $O$'s supplemental tasks, and the denominator is the sum of task exposures to Generative AI from all of the occupation's tasks. Correspondingly, the share of exposure from core tasks is $ShareCore_o = 1 - ShareSupp_o$. For occupations with a positive Generative AI exposure, on average, 23\% of the exposure derives from supplemental tasks and 77\% comes from core tasks (see Panel A of Table \ref{tab:summary}). Many occupations have exposure to Generative AI through both core and supplemental tasks (see Appendix Figure \ref{fig:task_magnitude}). We thus focus on variations in occupations' continuous $ShareSupp_o$ instead of creating binary labels for occupations.  Intuitively, occupations in which core tasks involve textual or quantitative analysis (or coding) are more likely to see stronger substitution effects.  Occupations in which core tasks involve manual or interpersonal activities, but in which supplemental tasks involve textual or quantitative analysis, are more amenable to complementarity. 


%\textcolor{red}{ Appendix Table \ref{tab:highlowocc_bycore} provides a glance at the GenAI-substitutable and GenAI-complementary occupations by listing the occupations with the highest core-task exposure to Generative AI (GenAI Exp$_o \times$ ShareCore$_o$) in Panel A and occupations with the highest supplemental-task exposure to Generative AI in Panel B. We observe that text-related occupations such as proofreaders, typists, writers, and information-processing occupations such as statisticians, programmers, and mathematicians can be substituted  by Generative AI, while occupations that involve both text-related buy also human interactions and manual tasks such as administrative occupations, inspectors, engineers, measurers, and health  service workers can be complemented by Generative AI. XXX} 

 
\paragraph{Firm-level measure} Finally, we measure the share of a \textit{firm}'s Generative AI exposure deriving from its workers' supplemental tasks  as 
\begin{equation}\label{eq:suppdefine_firm}
ShareSupp_f=\frac{\sum_{o \in f} EmpShare_{f,o} \times X^o \times ShareSupp_o}{\sum_{o \in f} EmpShare_{f,o} \times X^o},
\end{equation}
where $X^O$ is occupation $O$'s Generative AI exposure defined in equation \eqref{eq:exp}, and $ShareSupp_O$ is the occupation's share of Generative AI exposure derived from its supplemental tasks' exposure to Generative AI defined in equation \eqref{eq:suppdefine}. The firm's share of Generative AI exposure from core tasks is $ShareCore_f = 1 - ShareSupp_f$.


 
\subsection{Validation: Evidence on occupational substitution vs.~complementarity} \label{subsec:occsubcomp}
We test our prediction about the impact of Generative AI on occupations in our conceptual framework by running several variants of the following regression specification: 
\begin{align}  
y_{j,o,t} =  \  &  \theta \cdot \text{Post}_t\times\text{GenAI Exp}_{o} + \eta \cdot  \text{Post}_t\times\text{ShareSupp}_{o}  \nonumber \\
& + \lambda \cdot \text{Post}_t\times\text{GenAI Exp}_{o}\times\text{ShareSupp}_{o} + \text{FEs} + \varepsilon_{j,o,t}. \label{eq:h2}
\end{align}
Here, $y_{j,o,t}$ is the labor demand or wage variables to be detailed later, $Post_t$ is an indicator of the time period after the release of ChatGPT in November 2022, \textit{GenAI Exp}$_{o}$ is the occupation's Generative AI exposure defined in equation \eqref{eq:exp}, and  \textit{ShareSupp}$_o$ is the share of exposure to Generative AI that comes from supplemental tasks in equation \eqref{eq:suppdefine}, and \textit{FEs} include occupation and time fixed effects which capture other terms that vary only by occupation or time. 

\paragraph{Evidence on occupational labor demand} To test Generative AI's heterogeneous impact on occupational labor demand, we use data from Lightcast (formerly Burning Glass Technologies) and construct firms' number of job postings for each SOC 6-digit occupation in each month from January 2022 to August 2023. We aggregate the number of job postings to the occupation-month level, resulting in a final sample with a balanced panel of 43,512 observations for occupations that ever posted jobs in our time period, where occupation-months without any job postings are coded as zeros. We run three variants of the specification \eqref{eq:h2} above to test our prediction. 

First, we inspect the overall effect of ChatGPT on labor demand for occupations with high and low Generative AI exposure by estimating the regression without the \textit{ShareSupp}$_{o}$ term, i.e.,  
\begin{align}  
y_{j,o,t}= & \chi \cdot \text{Post}_t \times  \text{GenAI Exp}_{o}     + \text{FEs} + \varepsilon_{j,o,t}.  \label{eq:h1}
\end{align}
This specification does not distinguish occupations' Generative AI exposure deriving from their core versus supplemental tasks. Instead, it provides a benchmark estimate for us to highlight the labor-substitution and labor-complementarity effects later. To present the estimates as a percentage change in job postings but without dropping observations when log-transforming the dependent variable, we follow \cite{cohn2022} and estimate the above specification using a Poisson model with fixed effects.\footnote{A commonly adopted approach is to take the natural logarithm of the variable before estimating a linear model. However, the natural logarithm of zero is undefined.  Prior studies therefore often transform the dependent variable into the logarithm of a constant plus the original variable. However, \cite{cohn2022} show that estimates using this approach do not generate the correct interpretation and can even produce the wrong signs, while the Poisson model with fixed effects generates the correct interpretation of the estimated coefficient as representing percentage changes in the dependent variable. In particular, we used the PPML Stata model developed by \cite{santos2015}.} 

Column (1) of Table \ref{tab:empocc} reports the results. Occupations with a one-standard-deviation higher Generative AI exposure experience about an 8\% ($=0.209\times0.387$) decline in job postings after the release of ChatGPT, relative to less exposed occupations. This result  suggests the substitution effect tends to dominate the impact on occupations with high Generative AI exposure. 

One potential concern is that more exposed occupations may happen to be more prevalent in firms that are not performing well during this time period (e.g., some tech firms experienced downsizing in 2023). In that case, our occupation-level finding might be unrelated to firms choosing to shift hiring away from more exposed occupations, but rather might be due to firms that typically hired more exposed occupations reducing their overall job postings. To address this concern, we re-aggregate the detailed job posting data to the occupation-firm-month level for the publicly traded firms for which Lightcast provides a crosswalk of job postings to Compustat firm identifiers. We then estimate the heterogeneous labor demand across occupations within a firm by running the regression in equation \eqref{eq:h1} while controlling for firm-month fixed effects. Column (4) shows similar results, suggesting that firms, on average, shift their labor demand away from more exposed occupations after the release of ChatGPT. 

Second, we run the specification in equation \eqref{eq:h2} which includes \textit{ShareSupp}$_{o}$. We focus on the coefficient $\theta$, which measures the labor-substitution mechanism in our prediction. In particular, $\theta$ estimates the impact of ChatGPT on the spectrum of occupations with Generative AI derived solely from core tasks, i.e.,  \textit{ShareSupp}$_{o} = 0$. Supporting our prediction, we observe in Column (2) that the point estimate of $\theta$ is  74\% ($=0.672/0.387-1$) greater than the estimate of $\chi$ in the benchmark case in Column (1). Hence, if we restrict the exposure to be solely from core tasks, an increase in occupations' Generative AI exposure corresponds to a much stronger  substitution effect from ChatGPT. Similarly, Column (5) shows that this inference holds within a firm-month.  In addition, in both columns, the point estimate of $\lambda$ for the triple interaction is positive and statistically significant, confirming that the labor-substitution effect is mitigated as occupations' Generative AI exposure derives less from core tasks and more from supplemental tasks.

Third, we run the specification in equation \eqref{eq:h2} but substitute \textit{ShareSupp}$_{o}$ with \textit{ShareCore}$_{o}$. In this case, the coefficient $\theta$ measures the labor-complementarity mechanism in our prediction. That is, $\theta$ estimates the impact of ChatGPT on the spectrum of occupations with Generative AI exposure derived solely from supplemental tasks, i.e.,  \textit{ShareCore}$_{o} = 0$. Supporting our prediction, we observe in Columns (3) and (6) that the point estimate of $\theta$ is positive and statistically significant. Hence, if we restrict the exposure to be solely from supplemental tasks, an increase in occupations' Generative AI exposure corresponds to a positive impact of ChatGPT on the occupations' demand, consistent with the complementarity mechanism. 

\paragraph{Evidence on the occupational wage rate.} We corroborate our labor demand findings by further analyzing the impact of Generative AI on workers' wage rates. We use the monthly individual-level data from the Census Current Population Survey (CPS) from January 2022 to October 2023.\footnote{From the CPS data, we extract each individual's hourly wage rate, occupation code, gender, age, race, education level, and sampling weight in the survey. We require the individuals to be between 18 and 65 years old,  employed in the month of the survey, and to have a non-missing hourly wage rate and a non-missing occupation code. The data can be downloaded at \url{https://cps.ipums.org/cps/}.} We compute the more aggregated Census occupations' Generative AI exposure by applying a crosswalk and then averaging over the exposure of related SOC 6-digit occupations.  Our final sample includes the natural logarithm of hourly wage rates of about 271,000 individual-by-month observations, along with their occupation and other demographic characteristics, including gender, age, age squared, work experience, work experience squared, race (white versus non-white), and years of education.

To test our prediction on occupational wages in the conceptual framework, we run three variants similar to specification \eqref{eq:h2}, where the dependent variable is the hourly wage rate of the individual. We further control for the above individual demographics, and we weight the observations using each individual's CPS sampling weight following the literature. We still run Poisson regressions for the above specifications, and hence the coefficients should be interpreted as percentage changes in hourly wages. 

Column (7) of Table \ref{tab:empocc} shows the benchmark results consistent with our labor demand findings: overall, occupations with higher Generative AI exposure experience a greater relative decline in wage rates after the release of ChatGPT, although the point estimate is not statistically significant. As we have seen in our labor demand results, examining occupations across their Generative AI exposure alone may conceal substantial heterogeneity in the effect. %A one-standard-deviation increase in Generative AI exposure is associated with a 0.5\% ($=0.209 \times 0.023$) decline in the wage rate, but the average effect is not statistically significant (see the significant wage effects in Section \ref{sec:mech} for comparison). The smaller magnitude of the wage effect compared to that of the job posting effect is expected in that wages are known to be sticky (\cite{barattieri2014some}).

Columns (8)-(9) show the heterogeneous wage effects when occupations' exposure derives from core or supplemental tasks. For occupations with exposure derived solely from core tasks, a one-standard-deviation higher Generative AI exposure corresponds to a significantly greater decline in relative wage rates by 1.4\% $=0.209\times 0.065$ after the release of ChatGPT. This result supports the labor-substitution effect. In contrast, the wage effect is estimated to be positive and significant for occupations with exposure coming only from supplemental tasks (first row of Column (9)), consistent with the labor-complementarity effect. 

In summary, our findings on occupational job postings and wages validate that our approach based on core versus supplemental tasks can capture Generative AI's labor-substitution and labor-complementarity effects. The overall impact of ChatGPT on occupations with varying Generative AI exposure is dominated by the substitution effect, but the average effect estimates fail to capture substantial heterogeneity in these effects based on which of an occupation's tasks are exposed. 
%We next show the implications of these occupation-level findings for firms' labor responses to ChatGPT, which sheds further light on the underlying mechanism for our firm value results.  

\begin{center}
--- Insert Table \ref{tab:empocc} about here --- 
\end{center}

\subsection{Firms' labor reaction and Generative AI exposure} \label{subsec:firm_fund}  
We next demonstrate the implications of the labor market findings above for firms with high and low labor exposure to Generative AI. In particular, if occupations with higher exposure to Generative AI are, on average, more substitutable by ChatGPT, we would expect firms with a higher workforce exposure to Generative AI to have a greater labor-saving opportunity when ChatGPT becomes available. We present two sets of results suggesting that this is the case. First, we show that firms with a higher Generative AI exposure substantially reduce their exposed labor after the release of ChatGPT. This labor-substitution effect, as discussed in the conceptual framework, can reduce costs, increase future cash flows, and enhance firm value. Second, we provide additional evidence of the labor-substitution mechanism by showing that the labor reduction results are even stronger if firms' workforce Generative AI exposure derives solely from their core tasks. 

\paragraph{Firms' labor demand and Generative AI exposure}  The labor-substitution mechanism suggests that firms with a higher Generative AI exposure can save more costs by reducing their reliance on labor to do the tasks in highly exposed occupations after the introduction of ChatGPT. We thus define an occupation as highly exposed to Generative AI if the occupation's Generative AI exposure is within the top tercile of the distribution across all occupations, labeled as \textit{High-GenAI Exposure} occupations. From the Lightcast job posting data, we calculate the number of firms ' job postings for High-GenAI Exposure occupations in each month. We further require the firms to be in our stock return test sample, resulting in a final sample of 36,900 firm-month observations from January 2022 to August 2023. 
 
Our first test uses the following difference-in-differences regression specification:
\begin{align} \label{eq:h1_firm}
\text{High-Exp Job Posting}_{i,t} = &\kappa\cdot \text{Post}_t \times  \text{GenAI Exp}_i  + \text{FEs} + \varepsilon_{i,t},
\end{align}
where \textit{High-Exp Job Posting}$_{i,t}$ is firm $i$'s job posting count for the highly exposed occupations defined above, \textit{GenAI Exp}$_i$ is firm $i$'s Generative AI exposure,  and \textit{FEs} includes year-month fixed effects and firm fixed effects which subsume the standalone variables $\textit{Post}_t$, and  $\textit{GenAI Exposure}_i$. 


Column (1) of Table \ref{tab:empfirm} confirms that firms with a higher Generative AI exposure reduce their demand for high-GenAI exposure occupations after the release of ChatGPT. The magnitude of the coefficient suggests that the effect is sizable, with a one-standard-deviation increase in firm exposure resulting in a 11\% ($=0.078 \times 1.378$) decline in job postings for the highly exposed occupations.\footnote{In Appendix Figure \ref{fig:jobposting_pretrend}, we plot the effect of firms' GenAI Exp on their job postings for high-exposure occupations in each quarter from 2021q1 to 2023q3. We observe a strong trend break after the release of ChatGPT, consistent with the above regression results. In Panel A, we observe relatively higher job postings from firms with higher GenAI exposure during the pre-period. Our pre-period in this test coincides with the COVID period, during which tech firms had substantially higher labor demand. Panel B shows that the pre-trend is absorbed by industry heterogeneity when including industry $\times$ quarter fixed effects, while Panel C shows that the results are very similar if we exclude firms from the tech sector. While these findings suggest that our results are unlikely to be fully driven by the rise and fall of tech hiring during and after Covid, we cannot fully rule out that the impact of Covid forms part of the explanation, to the degree that it also impacted non-tech firm hiring of high-exposure occupations. We confirm in Appendix Table \ref{tab:empfirm_indFE} that our labor demand effect estimates are very similar with and without controlling for industry $\times$ month fixed effects.} 

We further test the labor-substitution mechanism by including the firm-level \textit{ShareSupp}$_i$ in specification \eqref{eq:h1_firm} above: 
\begin{align} \label{eq:h2_firm}
 \text{High-Exp Job Posting}_{i,t} = & \phi \cdot \text{Post}_t \times  \text{GenAI Exp}_i + \zeta \cdot \text{Post}_t \times \text{ShareSupp}_i \nonumber \\
&   + \psi \cdot \text{Post}_t \times  \text{GenAI Exp}_i \times \text{ShareSupp}_i + \text{FEs} + \varepsilon_{i,t},
\end{align}
where \textit{ShareSupp}$_i$  is the share of firm $i$'s  Generative AI exposure deriving from its workers' supplemental tasks' exposure. Similar to our inference at the occupation level, the coefficient $\phi$ informs the labor-substitution mechanism, as it captures the labor reactions when a firm's labor exposure to Generative AI derives solely from their core tasks (i.e., \textit{ShareSupp}$_i = 0$). Column (2) confirms that the reduction in labor demand is more than twice as great (i.e., comparing the coefficients $-3.038$ and $-1.378$) for firms where the Generative AI exposure derives solely from their workers' core task exposure.\footnote{In the Internet Appendix \ref{tab:empfirm_expanded}, we examine the demand for mid-exposure and low-exposure which can potentially serve as a placebo test. The table shows that firms' GenAI Exposure predicts a less negative response of job postings for mid-exposure occupations to the release of ChatGPT and an insignificant response of job postings for low-exposure occupations. These results highlight that the job posting effects derive primarily from high-exposure occupations, consistent with our mechanism.} 

\paragraph{Firms' employment and Generative AI exposure.} We reinforce our labor demand findings by further showing results on firms' actual employment changes in the highly exposed occupations. While the effect on hiring suggests a shift in firms' labor demand away from highly exposed occupations, a consistent finding in firms' employment changes strengthens the evidence for the labor-substitution effect. We use LinkedIn data from Revelio Labs on employees in the highly exposed occupations, aggregated at the firm-by-month level for public firms from January 2022 to December 2023. We estimate the same two specifications in equations \eqref{eq:h1_firm} and \eqref{eq:h2_firm} above, and replace the dependent variable with the firm's employment of highly-exposed occupations in the month, \textit{High-Exp Employment}$_{i,t}$. 

Our findings support our occupation-level and job posting results: Column (3) of Table \ref{tab:empfirm} shows that a one-standard-deviation increase in firm Generative AI exposure corresponds to a 0.6\% ($=0.078 \times 0.083$) decline in employment of highly-exposed occupations after the release of ChatGPT. Column (4) shows that the effect is much stronger when firms' Generative AI exposure derives solely from their workforce's core tasks (comparing the coefficients $-0.414$ and $-0.083$). 

In summary, the consistent results across the board of our tests regarding firms' labor demand and employment changes collectively provide strong support for the cost-saving mechanism: firms with a higher labor exposure to Generative AI can reduce their reliance on the exposed workforce. This labor-substitution mechanism provides an explanation for the predicted and realized changes in future cash flows and changes in firm value following the arrival of Generative AI technology, as documented in the previous sections. 


\begin{center}
--- Insert Table \ref{tab:empfirm} about here --- 
\end{center}

 
 
\subsection{Labor-substitution mechanism for firm value and cash flow effects} \label{subsec:het_cf}
Here, we present our last set of results to further solidify the labor-substitution mechanism for firm cash flow and value results. We have shown in the section above that the labor-substitution effect is strongest when a firm's employeesâ€™ exposure to Generative AI derives solely from their core tasks. Below, we show  that the effects on firm value and future cash flows are also strongest when a firm's employeesâ€™  exposure derives solely from their core tasks.  

For our test on firm value, we estimate the event study regression on cumulative abnormal returns in equation \eqref{eq:characteristics} while interacting  $\textit{GenAI Exp}_i$ with $\textit{ShareSupp}_i$:
\begin{equation} \label{eq:car_interaction}
\text{CAR}_{i}  =  \mu \cdot \text{GenAI Exp}_i +\nu \cdot \text{ShareSupp}_i  + \omega\cdot \text{GenAI Exp}_i\times \text{ShareSupp}_i  +\varepsilon_{i}. 
\end{equation} 
We again focus on the coefficient $\mu$, which informs the market value reaction to the release of ChatGPT for firms where Generative AI exposure derives solely from their workforce's core tasks, $\textit{ShareSupp}_i = 0$. Column (1) of Table \ref{tab:firm_core} reports that their firm value effects are significantly positive with a magnitude larger than the benchmark case shown in Column (1) of Table \ref{tab:het_panel} (i.e, comparing the coefficients $0.380$ and $0.216$ from the two tables). 

For our tests regarding future cash flows, we similarly add $\textit{ShareSupp}_i$ to our analyses of firms' forecast earnings and realized profitability in Section \ref{sec:cashflow_mechanism}. Columns (2) and (3) of Table \ref{tab:firm_core} show consistent results that if we focus on firms with their Generative AI exposure derived solely from their workers' core tasks' exposure, the effects on forecasts for short-term earnings and long-term growth are both at least  60\% larger than the average effects shown in Columns (1) and (2) of Table \ref{tab:ibes}. Column (4) shows a similar result for firms' realized gross profitability. %\footnote{While these findings support the labor-substitution mechanism, they also indicate that the labor-complementarity effect seems silent in immediately boosting firm value. There can be many reasons for this. For instance, occupations complemented by Generative AI may engage in long-term innovation (\cite{toner2024}) that generates uncertain cash flows in the far future that investors or analysts could not immediately incorporate into firm value. On the other hand, when aggregated to the firm-level, few firms have their Generative AI exposure derived solely or even mainly from supplemental tasks, as $\textit{ShareSupp}_i$ has a narrow standard deviation of only $0.07$ around its mean at $0.20$, unlike the wider spread of  occupations' $\textit{ShareSupp}_o$. Therefore, we do have data to inspect variations among firms in the spectrum featuring high workforce complementarity, which may limit our ability to detect the labor-complementarity effect on firm value. Future research into this mechanism remains fruitful.} 

In summary, the earlier results on the labor side have already suggested that firms' exposure to Generative AI primarily captures their workers' substitutability by the technology, supporting a labor-substitution mechanism for our main results on firm value. Our findings in this section further strengthen this mechanism by showing that all effects are stronger if we restrict firms' Generative AI exposure to capture solely their workers' substitutability by the technology. 

\begin{center}
--- Insert Table \ref{tab:firm_core} about here --- 
\end{center}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Conclusion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}\label{sec:concl}
Market equity prices indicate that the arrival and diffusion of large language models and Generative AI represent a major technology shock with important effects on the overall value of firms,  leading to winners and losers.  This paper uses occupational exposures to Generative AI, along with firm-level measures of occupational composition, to assess the exposure to Generative AI innovations at the firm level for publicly traded U.S. corporations.  We find that the release of ChatGPT had a substantial impact  on firm value, leading to a difference in firm returns of 0.45\% daily. Moreover, we show that this change in valuations can be explained by a mechanism where market participants expect higher cash flows for exposed firms in the future: analysts' long-run earnings forecasts increase more for exposed firms after the release of ChatGPT, and there are also effects on actual gross profitability that are realized within a year after the release.

To show that firms change their actions in response to their technology exposure,  we provide evidence that firms with higher exposure to Generative AI-driven productivity increases are more likely to communicate with their investors about these technologies in their earnings calls, and differ in their hiring behavior in subsequent months,  reducing their job postings for highly exposed occupations and also seeing a decline in employment levels for these roles.  We also document a relative decline in wages and hiring for highly exposed occupations at the national level in the months that followed the initial technology shock.  

We find that there is substantial heterogeneity in these effects that aligns with a mechanism where it matters \textit{which} tasks within a given occupation are exposed: we argue that if more of a worker's core tasks---as opposed to supplemental tasks---can be automated by a technology, this has more negative consequences for labor demand for those roles, but more positive consequences for firm profitability. All our key outcomes show heterogeneity of the effects of Generative AI exposure that aligns with the mechanism.

These findings raise important issues for policymakers: to the extent that shareholders benefit from increases in firm value while affected workers lose out, the new technology redistributes income in the economy, which may or may not be desirable from a welfare perspective.  At the same time,  our quantification of the productivity potential of Generative AI for different firms permits policymakers and entrepreneurs to better identify areas of opportunity and targets for disruption as this new technology reshapes the economic landscape.   The degree to which this new technology will bring pain or plenty will depend on how firms and regulators can align in realizing the value that is promised by the financial market reaction to its release.  The early labor market effects that we document highlight that there are significant impacts on employment and wages of worker in occupations with substantial core-task exposures to Generative AI.

 


\clearpage
% Bibliography.
%\begin{doublespacing}   % Double-space the bibliography
\bibliographystyle{jf}
\bibliography{bibliohoco}
%\end{doublespacing}

\newpage			


%\section{Figures}

\begin{figure}\centering
\captionsetup{singlelinecheck=off}
\includegraphics[width=0.75\textwidth]{../figures/skill_exposure_coefs.png} 
\caption[.]{\textbf{Occupational Generative AI Exposure and Skill Measures.}\label{fig:autor} This figure plots the coefficients of regressing occupations' Generative AI exposure (see equation \eqref{eq:exp}) on six measures of occupations' skills constructed by \cite{acemoglu2011}.  Equation \eqref{eq:regskill} shows the regression specification. Occupation is classified at the SOC 6-digit level.  The six skill measures are each  standardized to have a mean of zero and a standard deviation of one.  See Appendix \ref{sec:skill_apx} for details on the construction of these skill measures. The bar around each coefficient shows the 95\% confidence interval based on heteroskedasticity-robust standard errors.}
\end{figure}



\begin{figure} 
\centering 
\includegraphics[width=0.8\linewidth]{../figures/gpt_w_occ2d}   
\caption{\textbf{Generative AI Exposure and Wages by Major Occupation Group.} The figure plots the relationship between Generative AI exposure and annual wages by SOC 2-digit occupation group. We aggregate the Generative AI exposure from SOC 6-digit to SOC 2-digit using the May 2022 occupational employment distribution from the Bureau of Labor Statistics Occupational Employment and Wage Statistics (OEWS) downloaded at \url{https://www.bls.gov/oes/current/oes_stru.htm}. We obtain the average annual wages of the SOC 2-digit occupations from the 2022 OEWS. The dashed red line indicates the employment-weighted linear best fit.   \label{fig:wage_exp_occ}}
\end{figure}





\begin{figure}[p]
\begin{center}
    \includegraphics[width=1.05\linewidth]{../figures/s12wt_by_ind3d_withsd} 
\end{center}
\caption{ \textbf{Generative AI Exposure Within and Across Industries.} \label{fig:gpt_naics2} This figure plots the average and the standard deviation of Compustat firms' Generative AI exposure within each NAICS 3-digit industry in 2022. For ease of exposition, we require the industry to have at least 20 firms to be added to this figure.  See Appendix Figure \ref{fig:gpt_naics2_full} for the full set of subsectors.}
\end{figure} 


\begin{figure}
\centering
\includegraphics[width=.7\linewidth]{../figures/twitter_mentions_4wk} 

\caption[.]{\textbf{Social Media Attention to the Release of ChatGPT.} The figure plots the total count of Twitter mentions of ``ChatGPT'' or ``GPT'', in thousands, on each day from November 14, 2022, to December 29, 2022. The data are from Media Cloud. The red dashed vertical lines indicate the ``ChatGPT event period'' for our stock market reaction analyses, which includes the two weeks following the release of ChatGPT on November 30, 2022.    
\label{fig:vol} }
\end{figure}




 
\begin{figure}
\centering 
\textit{Panel A: Share of Firms Mentioning Generative AI}
\bigskip 

\includegraphics[width=0.55\linewidth]{../figures/calltrends_callshare_m_llm} 
\bigskip \bigskip 


\textit{Panel B: Firms' Generative AI Exposure and Their Mentions of Generative AI}
\bigskip 

\includegraphics[width=0.55\linewidth]{../figures/calls_llm_s12wt_qrt} 

\caption[.]{\textbf{Firm Mentions of Generative AI in Earnings Conference Calls.} Panel A plots the percentage of S\&P 500 firms mentioning keywords of Generative AI in their quarterly earnings conference call transcripts in each quarter, where the data are manually collected from the \textit{Seeking Alpha} website.  We convert each call transcript into a list of lower-case unigrams and bigrams and examine whether it mentions the Generative AI keywords: ``llm'',  ``chatgpt'',  ``gpt'', ``gpt3'', ``gpt4'', ``generative'', and ``language model''.  Panel B reports the cross-sectional relationship between firms' indicator of mentioning Generative AI, \textit{GenAI Mention}$_{i,t}$, and the labor-based Generative AI exposure, \textit{GenAI Exp}$_i$, constructed in Section \ref{sec:data}. We estimate the following regression specification in each fiscal quarter from 2019Q1 to 2023Q1 and plot the point estimates of $\beta_t$ and the 95\% confidence intervals based on heteroskedasticity-robust standard errors: $\mathbbm{1}[\text{GenAI Mention}]_{i,t} = \alpha_t + \beta_t \text{GenAI Exp}_i + \gamma \mathbbm{1}[\text{GenAI Mention}]_{i,2019}  + \varepsilon_{i,t}.$
The Appendix Figure \ref{fig:calltrends_apx} plots firms' mentions of generic ``engineering'' keywords as a placebo test.  }
\label{fig:calltrends}
\end{figure}


 
\FloatBarrier
\newpage


%\section{Tables}

 
   
\begin{landscape}  
\begin{table}[h]
\caption{\\ \textbf{Examples of GPT Scores for Tasks}} 

\vspace{-.1cm}  \small  This table presents examples of the scoring of labor tasks' exposure to Generative AI by comparing the tasks' statement to a rubric using the GPT 3.5 Turbo Model. We obtain from the O*Net V27.2 database task statements for each occupation and also an indicator of whether each task is ``core'' or ``supplemental'' to the occupation.  An occupation has, on average, 22 tasks. We use the GPT model together with a rubric detailing the capabilities of ChatGPT-like tools to classify each task into three categories: if the task can be more efficiently completed with ChatGPT, it receives an exposure score of 1; if the task can be more efficiently completed with ChatGPT only if ChatGPT is further integrated with additional software or applications, it receives a score of 0.5 (\cite{eloundou2023}); and if the task cannot be completed by ChatGPT, it receives a score of 0. The GPT model also provides an explanation for the classification of each task. Section \ref{sec:data} details the procedure.  \vspace{.3cm}



\label{table:gpt_output} 
\centering
\scriptsize 
 \begin{tabular}{>{\raggedright\arraybackslash}p{6.5cm} >{\raggedright\arraybackslash}p{3cm}>{\raggedright\arraybackslash}p{1.2cm} >{\raggedright\arraybackslash}p{1.2cm} >{\raggedright\arraybackslash}p{8.8cm}}
\toprule
 \textbf{Task} &  \textbf{Occupation}  &      \textbf{Type}   & \textbf{Score} & \textbf{GPT Explanation for the Score} \\\midrule 
\input{../tables/gptoutputexamples_new}
\bottomrule
\end{tabular}
\end{table}
\end{landscape} 





\begin{table}[htbp]
 
  \caption{\\ \textbf{Summary Statistics}}  

  \vspace{-.1cm}  \small  This table reports summary statistics of key variations at the occupation level in Panel A and at the firm level in Panel B. \textit{Generative AI Exposure}$_o$ is the SOC 6-digit occupation's Generative AI exposure aggregated from its tasks' Generative AI exposure (see equation \eqref{eq:exp}). \textit{ShareSupp$_{o}$} is the share of the occupation's Generative AI exposure that derives from the occupation's supplemental tasks' exposure to Generative AI as compared to its core tasks' exposure (see equation \eqref{eq:suppdefine}). For firm-level measures, \textit{Generative AI Exposure} is the firm's Generative AI exposure which is the average of its occupations' Generative AI exposure weighted by the firm's 2022 occupational employment shares from the Revelio Labs database. \textit{Log Size} is the natural logarithm of total assets.  \textit{Tobin's Q} is the market value of the firm divided by book assets following \cite{gutierrez2017investmentless}. \textit{ROA} is return on assets measured as EBITDA divided by total assets. \textit{Labor Intensity} is the logarithm of the ratio of employment to the net value of property, plant, \& equipment following \cite{donangelo2014}. \textit{Tangibility} is asset tangibility measured as the ratio of PP\&E to total assets. \textit{Mkt. Leverage} is the ratio of the firm's total value of debt to the sum of total debt and the market value of equity. See table notes for Tables \ref{tab:product_panel}, \ref{tab:ibes}, \ref{tab:datavalue}, and \ref{tab:empfirm} for additional variable definitions. \vspace{.2cm}

\centering
 
\label{tab:summary}  
    \begin{tabular}{lccccccc} 
        \toprule
     \ \ \  \ \ \  \ \ \  \ \ \  \ \ \  \ \ \  \ \ \  \ \ \  \ \ \  \ \ \  \ \ \  \ \ \ \    \ \ \ \  &            \multicolumn{1}{c}{  \ \ \  Mean\ \ \   }  &    \multicolumn{1}{c}{Std. Dev.} &  \multicolumn{1}{c}{\ \   \ p10\  \ \ } &   \multicolumn{1}{c}{\ \ \ \  p50\ \ \ \ } &    \multicolumn{1}{c}{\   \ \   p90  \ \ \  } &   \multicolumn{1}{c}{\ \     Obs.\ \     } \\   

    \midrule
                \multicolumn{7}{c}{\textit{Panel A: Occupation-level measures}} \\
    \midrule
 \input{../tables/sumstat_occ_new.tex} 
 \midrule
    \multicolumn{7}{c}{\textit{Panel B: Firm-level measures}} \\
     \midrule
    \input{../tables/sumstat_new.tex} 
    \input{../tables/sumstat_eps_BenNewSample.tex} 
\input{../tables/sumstat_firmmonth.tex}   
     \bottomrule
    \end{tabular}
\end{table}%
 






\begin{table}[p]  
\caption{ \\\textbf{Firms with Highest and Lowest Generative AI Exposure}}    \label{tab:firm_gpt}

\vspace{-.1cm}  \small  This table lists the 15 firms with the highest Generative AI exposure in Panel A and the 15 firms with the lowest exposure in Panel B among the 100 largest US-headquartered publicly traded firms based on their market capitalization as of November 29, 2022. \textit{GenAI Exp} is the firm's labor-based Generative AI exposure defined in Section \ref{sec:data}. \textit{MktCap} is the firm's market capitalization in \$ billions.  \textit{Industry} is classified at the NAICS 3-digit level. \vspace{.2cm}

\footnotesize 
\scalebox{0.945}{
\begin{tabular}{lcrl}
\toprule
    \multicolumn{4}{c}{\textit{Panel A: Top 15 large firms with the highest Generative AI exposure}} \\
    \midrule
    Firm Name &  GenAI Exp  &  MktCap     & Industry \\
    \midrule
\input{../tables/Top_15.tex}
    \midrule
    \multicolumn{4}{c}{\textit{Panel B: Bottom 15 large  firms with the lowest Generative AI exposure}} \\
    \midrule
    Firm Name &  GenAI Exp  &  MktCap  & Industry \\
    \midrule
\input{../tables/Bottom_15.tex}
    \bottomrule
    \end{tabular}}
\end{table}




\begin{table}[h] 
\caption[]{\\ \textbf{Reaction of Portfolios Sorted by Generative AI Exposure}}

\vspace{-.1cm} \small This table reports daily percentage stock returns, as a measure of changes in firm value, during the ChatGPT event period for five value-weighted portfolios sorted on firms' Generative AI exposure. To form the portfolios, we sort NYSE stocks on November 29, 2022, into five quintiles by their Generative AI exposure, and we assign all stocks into the portfolios using the NYSE breakpoints. We aggregate stock returns within each portfolio using the stocks' market capitalization on the prior trading day as the weight. \textit{AMH} is the ``Artificial Minus Human'' zero net investment portfolio long the portfolio with high exposure and short the portfolio with low exposure. We define the ChatGPT event period as from November 30, 2022, to December 14, 2022, i.e., the two weeks after the release of ChatGPT (see Section \ref{sec:returns} for more details). Panel A reports each portfolio's raw daily return in excess of the risk-free rate. Panels B and C report the CAPM market-adjusted alphas and the Fama-French 5-factor-adjusted alphas, where the factor loadings of each portfolio are estimated using data from the previous six months. Panel D reports the Fama-French 5-factor-adjusted alphas for a sample that excludes firms in the tech sectors, NAICS 51 (information) and NAICS 54 (business services), following \cite{acemoglu2022}.  $t$-statistics are shown in parentheses.  See Section \ref{subsec:mainreturn} for more details.  \vspace{.2cm} 
\footnotesize 

\centering 

\label{tab:robust_quintiles}
\begin{tabular}{cccccccc} 
\toprule
\addlinespace
\ \ \ & \ \ \ \ \ \  {Q1 (H)} \ \ \ \ \ \   & \ \ \ \ \   \    {Q2} \ \ \ \ \   \ & \ \  \ \  \  \ {Q3}    \ \ \ \  \  \ &     \  \ \ \ \ \ {Q4} \   \  \ \  \ \  &  \ \ \ \  \ \ {Q5 (A)} \ \ \  \ \ \    & \ \ \ \ \  \     {AMH} \ \ \ \ \  \ &   \\
\midrule 
\csname @@input\endcsname {../tables/pf_news_w2d180.tex}
\midrule \addlinespace
\csname @@input\endcsname {../tables/pf_news_w2d180_B.tex}
\bottomrule
\end{tabular}
\end{table} 





   
%\begin{landscape}
\begin{table}[h] 
\caption[]{\\ \textbf{Cumulative Abnormal Returns and Generative AI Exposure}}

\vspace{-.1cm}  \small This table reports the relation between firms' cumulative abnormal returns during the ChatGPT event period,  [$-1, 10$] trading days around the release of ChatGPT on November 30, 2022, (CAR [$-1, 10$]) and firms' Generative AI exposure, defined in Section \ref{sec:data}. To compute the cumulative abnormal return of each stock, we first subtract the daily market return from Kenneth French's website from the daily stock return from Yahoo Finance,  and then we cumulate the daily abnormal returns over [$-1, 10$]. See Table \ref{tab:summary} for the definitions of firm characteristic variables. All firm characteristics other than generative AI exposure have been standardized to have a mean of zero and a standard deviation of one. Equation \eqref{eq:characteristics} describes the regression specification and the weighting of firms.  $t$-statistics are computed using heteroskedasticity-robust standard errors and reported in parentheses.  ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 
\vspace{.2cm} 

\centering 
\footnotesize 

\label{tab:het_panel}
\begin{tabular*}{\textwidth}{l @{\extracolsep{\fill}} cccccccc}
\toprule
 Dep.  var.: &   \multicolumn{8}{c}{CAR[-1,10]}   \\
\cmidrule{2-9} \addlinespace
\input{../tables/car_compustat.tex}
\end{tabular*}
\end{table} 

%\end{landscape} 






\begin{table}[h] 
\caption[]{\\ \textbf{ Reaction of Within-Industry Sorted Portfolios}} 

\vspace{-.1cm} \small This table reports daily percentage stock returns, as a measure of changes in firm value, during the ChatGPT event period for three value-weighted portfolios sorted on firms' Generative AI exposure within the industry. To form the portfolios, we sort NYSE stocks on November 29, 2022 into three terciles by their Generative AI exposure across all stocks in Panels A1 and B1, within the NAICS 3-digit industry in Panels A2 and B2, and within the \cite{hoberg2016} FIC 50-industry in Panels A3 and B3, and we assign all stocks into the portfolios using the NYSE breakpoints. We aggregate stock returns within each portfolio using the stocks' market capitalization on the prior trading day as the weight. \textit{AMH} is the ``Artificial Minus Human'' zero net investment portfolio long the portfolio with high exposure and short the portfolio with low exposure. We define the ChatGPT event period as from November 30, 2022, to December 14, 2022, i.e., the two weeks after the release of ChatGPT (see Section \ref{sec:returns} for more details). Panels A1-A3 report the CAPM market-adjusted alphas, and Panels B1-B3 report the Fama-French 5-factor-adjusted alphas.  $t$-statistics are shown in parentheses. See Section \ref{subsec:withinindustry} for more details. \vspace{.2cm} 
 
\centering 
\footnotesize 

 \label{tab:terciles_withinindustry}
 
\begin{tabular}{lcccccc} 
\toprule
\addlinespace
 \ \ \ & \ \ \ \ \ \ \ \ \ \ \    {Q1 (H)} \ \ \ \ \ \ \ \ \ \ \   & \ \ \ \ \ \ \ \ \ \ \   {Q2}\ \ \ \ \ \ \ \ \ \ \    & \ \ \ \ \ \ \ \ \ \ \    {Q3 (A)} \ \ \ \ \ \ \ \ \ \ \  & \ \ \ \ \ \ \ \ \ \ \    {AMH}  \ \ \ \ \ \ \ \ \ \ \   &  \  \\
\midrule 
\csname @@input\endcsname {../tables/pf_terc_news_w2d180.tex}
\bottomrule
\end{tabular}

\end{table} 




  
   
\begin{table}[h] 
\caption[]{\\ \textbf{Product Exposure  versus   Labor Exposure to Generative AI}} 

\vspace{-.1cm}  \small This table reports the relation between firms' cumulative abnormal returns during the ChatGPT event period, [$-1, 10$] trading days around the release of ChatGPT on November 30, 2022, (CAR [$-1, 10$]) and firms' labor-based Generative AI exposure (our main measure defined in Section \ref{sec:data}) while controlling for various proxies for firms' product exposure to AI.  To compute the cumulative abnormal return of each stock, we first subtract the daily market return from Kenneth French's website from the daily stock return from Yahoo Finance,  and then we cumulate the daily abnormal returns over [$-1, 10$].  The definitions of the four proxies of firms' product exposure to AI are described in detail in Section \ref{sec:product}. \textit{GPT10 Product Exp} is based on GPT 3.5 Turbo assessment of firms' annual reports' description of their products. \textit{Count10K Product Exp} is based on counting AI-related keywords in firms' annual reports. \textit{GS Product Exp} is based on Goldman Sachs' classification of firms as ``near-term beneficiaries of AI''.  \textit{BFHH Product Exp} is based on firms' share of AI-skilled workers constructed by \cite{babina2024artificial}. All product exposure measures are standardized to have a mean of zero and a standard deviation of one, except \textit{GS Product Exp}  and \textit{GPT10K Product Exposure}, which are binary variables.  All regressions include NAICS 3-digit fixed effects.  Equation \eqref{eq:CAR_Product} describes the regression specification and the weighting of firms. $t$-statistics are computed using heteroskedasticity-robust standard errors and reported in parentheses.  ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 
\vspace{.2cm}

\centering 

\label{tab:product_panel}
 
\begin{tabular*}{\textwidth}{l @{\extracolsep{\fill}} cccccc}
\toprule
 Dep.  var.: &    \multicolumn{6}{c}{CAR[-1,10]}    \\
\cmidrule(lr){2-7}  \addlinespace
\input{../tables/product_car.tex}
\end{tabular*}
\end{table} 


    
\begin{table}[h] 
\caption[]{\\\textbf{Generative AI Exposure and Firm Data Assets}}

\vspace{-.1cm} This table reports coefficients from regressions of cumulative abnormal returns of firms during the ChatGPT event period, [$-1, 10$] trading days around the release of ChatGPT on November 30, 2022, on firms' Generative AI exposure interacted with proxies for their data assets. To compute the cumulative abnormal return of each stock, we first subtract the daily market return from Kenneth French's website from the daily stock return from Yahoo Finance,  and then we cumulate the daily abnormal returns over the [$-1, 10$] period. Section \ref{subsec:datavalue} details the construction of the two proxies for firms' data assets.  \textit{10K Data Assets} is a score of 0, 1, 2, or 3, indicating the firm is not likely, slightly likely, moderately likely, or highly likely to have data that can be used as an input into large language model analytics based on the assessment of firms' annual reports using the GPT 3.5 Turbo Model. \textit{AV Data Assets} is constructed following \cite{abis2023} and measures the intensity of data management skills in the firm's workforce. All regressions include NAICS 3-digit fixed effects and weight firms by their market capitalization as of November 29, 2022. $t$-statistics are computed using heteroskedasticity-robust standard errors and reported in parentheses.  ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 

\vspace{.2cm}

\centering
\footnotesize 

\label{tab:datavalue}
\begin{tabular*}{\textwidth}{l @{\extracolsep{\fill}} cc}
\toprule
 Dep.  var.: & \multicolumn{2}{c}{CAR[-1,10] } \\
\cline{2-3}   \addlinespace           &\multicolumn{1}{c}{ \ \ \ \ \ \ \ \ \ \ (1) \ \ \ \ \ \ \  \ \ \  }   &\multicolumn{1}{c}{ \ \ \ \ \ \ \ \ \ \   (2)  \ \ \ \ \ \ \ \ \ \  }   \\ \midrule 
\input{../tables/data_car_smallA.tex}
\end{tabular*}
\end{table} 


    
\begin{table}[h] 
\caption[]{\\\textbf{Mechanism: Future Cash Flow Impact and Generative AI Exposure}}

\vspace{-.1cm} \small This table reports the impact of the release of ChatGPT on analyst forecasts of firms' future earnings per share (EPS) and on firms' reported quarterly profitability. Analyst forecasts are updated monthly for each firm in the I/B/E/S data. For each firm in each month, we obtain the median analyst forecasts of the firm's EPS in the fiscal year ending in December 2023 and the firm's long-term annual percentage growth rate in earnings (LTG). The dependent variables in Columns (1) and (2) are the firm's median forecasts of the corresponding measures made in October 2022 and January 2023. The dependent variable in Column (3) is the firm's quarterly gross profitability defined as (\textit{Revenue} - \textit{COGS})/\textit{Assets} following \cite{novy2013} in percentage using the Compustat quarterly data from 2022Q1 to 2024Q3. The independent variable \textit{Post} is an indicator for whether the time period is after the release of ChatGPT (i.e., after November 2022).  \textit{GenAI Exp} is a continuous measure of GenAI exposure at the firm level. See Section \ref{sec:cashflow_mechanism} for more details. All regressions include both firm-level and time-period fixed effects. $t$-statistics in parentheses are computed using standard errors clustered at the firm level. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 
\vspace{.2cm}

\centering 
\small

\label{tab:ibes}
\begin{tabular*}{1\textwidth}{l @{\extracolsep{\fill}} ccc}  
\toprule
% \textit{Panel:} & \multicolumn{4}{c}{Firm $\times$ Month} &  \multicolumn{1}{c}{Firm $\times$ Qtr} \\
%  \cmidrule(lr){2-5}   \cmidrule(lr){6-6}  
\textit{Data:} & \multicolumn{2}{c}{\ \ \ \ \  \ \ \ \ \    I/B/E/S Analyst Forecasts \ \ \ \ \  \ \ \ \ \   } &  \multicolumn{1}{c}{ \  \  \ Compustat \  \  \  } \\
 \cmidrule(lr){2-3}   \cmidrule(lr){4-4}  
 \textit{Measure:  \ \ \ \ \  \ \ \ \ \  \ \ \ \ \ }  &  \ \ \ \ \ \ \ \ \ \ \ \  EPS \ \ \ \ \ \ \ \ \ \ \ \   &  \ \ \ \ \ \ \ \ \ \     LTG    \ \ \ \ \   \ \ \ \ \    &  \ \  \  \  \  \   Gross Profit \  \    \  \  \  \  \\ 
  \cmidrule(lr){2-2}  \cmidrule(lr){3-3}  \cmidrule(lr){4-4}  
 %\textit{Units:} & \$ & \$ & \$ & \% & \%  \\ 
   & (1)  & (2)  & (3)            \\ 
\midrule             
\addlinespace
 \input{../tables/Ben_IBES_EPS.tex} 
\end{tabular*}
\end{table}  



\begin{landscape}



\begin{table}[h] 
\caption[]{\\ \textbf{Validation: Occupational Hiring and Wage Impact and Generative AI Exposure}}

\vspace{-.1cm} \footnotesize This table reports the impact of the release of ChatGPT on job postings and wages of occupations. In Columns (1)-(3), the sample includes the total number of job postings at the occupation-month level, and in Columns (4)-(6) at the firm-occupation-month level in the U.S. from January 2022 to August 2023, aggregated from the Lightcast (formerly Burning Glass) job posting database.  In Columns (7)-(9), the sample consists of the worker-level hourly wage rate from the Census Current Population Survey (CPS) in monthly panels from January 2022 to October 2023. \textit{GenAI Exp} is the occupation-level Generative AI exposure. \textit{ShareSupp} and \textit{ShareCore} are the occupation's share of Generative AI exposure deriving from the occupation's supplemental and core tasks' exposure to Generative AI. Worker demographic controls in Columns (7)-(9) include the worker's gender,  age, age squared, work experience, experience squared,  race (white versus  not), and years of education. Individual observations in Column, (7)-(9) are weighted by the CPS sampling weight. The job posting panels include many zeros,  which makes it impractical to log-transform the dependent variable.  Instead,  we estimate all regressions using the Poisson model with fixed effects following \cite{cohn2022}, which means that coefficients can be interpreted as semi-elasticities,  i.e.,  in terms of percentage changes in the dependent variable. $t$-statistics in parentheses are computed using standard errors double clustered at the month level and the occupation level in Columns (1)-(3) and (7)-(9), and triple clustered at the month, occupation, and firm levels in Columns (4)-(6). ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively.  See Section \ref{subsec:occsubcomp} for more details. 

\vspace{.2cm}

\centering 

\label{tab:empocc}
\footnotesize 
\scalebox{0.99}{
\begin{tabular}{lccccccccccc} 
\toprule
\textit{Dep var.:} & \multicolumn{6}{c}{Job Postings} & \multicolumn{3}{c}{Hourly Wage} \\
 \cmidrule(lr){2-7} \cmidrule(lr){8-10}   \addlinespace
 \textit{Panel Unit:} &\multicolumn{3}{c}{Occ.$\times$Month}&\multicolumn{3}{c}{Occ.$\times$Firm$\times$Month}  &\multicolumn{3}{c}{Worker$\times$Month}   \\
 \cmidrule(lr){2-4}  \cmidrule(lr){5-7}  \cmidrule(lr){8-10}   \addlinespace
   & (1)  & (2)  & (3)  & (4)   & (5)  & (6)  & (7)  & (8)     & (9)        \\ 
\midrule             
\addlinespace
 \input{../tables/tab_emp_occ.tex}
\end{tabular}}
\end{table}   

\end{landscape}






\begin{table}[h] 

\caption[]{\\ \textbf{ Labor-Substitution Channel: Firm Hiring and Employment}}

\vspace{-.1cm} \footnotesize This table reports the impact of the release of ChatGPT on job postings and employment in high-exposure occupations by firms. In Columns (1)-(2) the sample includes the high-exposure (top tercile) job postings at the firm-month level from January 2022 to August 2023 aggregated from the Lightcast (formerly Burning Glass) job posting database. In Columns (3)-(4), the sample consists of total employment in high-exposure (top tercile) occupations at publicly traded firms for each month, computed from LinkedIn data for publicly traded U.S. firms from January 2022 to December 2023.  \textit{GenAI Exp} is the \textit{firm}-level Generative AI exposure, which is an employment-weighted average across occupations within the firm. \textit{ShareSupp} is the firm's share of Generative AI exposure deriving from the supplemental tasks' exposure to Generative AI. The job posting panels include many zeros,  which makes it impractical to log-transform the dependent variable.  Instead,  we estimate all regressions using the Poisson model with fixed effects following \cite{cohn2022}, which means that coefficients can be interpreted as semi-elasticities,  i.e.,  in terms of percentage changes in the dependent variable. $t$-statistics in parentheses are computed using standard errors double-clustered at the month level and the firm level. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 

\vspace{.2cm}

\centering 

\label{tab:empfirm}
\footnotesize 
\begin{tabular*}{1\textwidth}{l @{\extracolsep{\fill}} cccc}  
\toprule
\textit{Dep var.:} & \multicolumn{2}{c}{High-Exposure Job Postings} & \multicolumn{2}{c}{High-Exposure Employment} \\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5}  
%  \addlinespace \textit{Panel Unit:} &\multicolumn{2}{c}{Firm$\times$Month} &\multicolumn{2}{c}{Firm$\times$Month}     \\
 %\cmidrule(lr){2-3} \cmidrule(lr){4-5}   \addlinespace
   & (1)  & (2)  & (3)  & (4)        \\ 
\midrule             
\addlinespace
 \input{../tables/tab_emp_firm_short.tex}
\end{tabular*}
\end{table}   


\begin{table}[h] 
 
\caption[]{\\ \textbf{ Labor-Substitution Channel: Firm Value and Future Cash Flows}} 
 
\vspace{-.1cm} \small 
This table reports the heterogeneous impact of the release of ChatGPT on firm value and future cash flows based on the firmâ€™s workforce's supplemental versus  core task exposure to Generative AI. The heterogeneous exposure is captured by an interaction between firms' generative AI exposure (\textit{GenAI Exp}) and firms' share of Generative
AI exposure deriving from their workers' supplemental tasks' exposure to Generative AI (\textit{ShareSupp}). Column (1) shows the results on firms' cumulative abnormal returns (CARs) during the release period. See details about the specification in Table \ref{tab:het_panel}. Columns (2) and (3) show the results on monthly analyst forecasts of firms' 2023 year-end earnings per share (EPS) and the long-term annual percentage growth rate of EPS (over the next business cycle) made from May 2022 to May 2023 using the I/B/E/S data. Column (4) shows the results on firms' quarterly gross profitability. In Columns (2)-(4), \textit{Post} is an indicator for whether the time period is after the release of ChatGPT (i.e., after November 2022). See details about the specification and sample in Table  \ref{tab:ibes}.  $t$-statistics, reported in parentheses, are computed using heteroskedasticity-robust standard errors in Column (1) and using standard errors clustered by firm in Columns (2)-(4).   ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 
 
\vspace{.2cm}

\centering 
\footnotesize 

\label{tab:firm_core}
\small
\begin{tabular*}{1\textwidth}{l @{\extracolsep{\fill}} cccc}   
\toprule
%\textit{Panel:} & Firm & \multicolumn{4}{c}{Firm $\times$ Month} &  \multicolumn{1}{c}{Firm $\times$ Qtr} \\
 %\cmidrule(lr){2-2}  \cmidrule(lr){3-6}   \cmidrule(lr){7-7}  

 \textit{Measure:} & \ \ \  CAR[-1,10] \ \ \ & \ \ \ \ \ \   EPS \ \ \ \ \ \         & \ \ \ \ \ \ LTG \ \ \ \ \ \   & \   Gross Profit \    \\
  \cmidrule(lr){2-2}  \cmidrule(lr){3-3}  \cmidrule(lr){4-4}  \cmidrule(lr){5-5}    
 %\textit{Units:} & & \$ & \$ & \$ & \% & \%  \\ 
   & (1)  & (2)  & (3)  & (4)            \\ 
\midrule             
\addlinespace
 \input{../tables/firmvalue_core_short.tex} 
\end{tabular*}
\end{table}  




 


\begin{comment}

\begin{table}[h] 
\caption[]{\\\textbf{Effect Heterogeneity: Firm Value and Future Cashflows}} 

\vspace{-.1cm} \small 

This table reports the heterogeneous impact of the ChatGPT release on firm value and future cashflows based on firm workforce's supplemental vs. core task exposure to Generative AI. The heterogeneous exposure is captured by an interaction between firms' generative AI exposure (\textit{GenAI Exp}) and firms' share of Generative
AI exposure deriving from their workers' supplemental tasks' exposure to Generative AI (\textit{ShareSupp}). Column (1) shows the results on firms' cumulative abnormal returns (CARs) during the release period. See details about the specification in Table \ref{tab:het_panel}. Columns (2)-(6) show the results on monthly analyst forecasts of firms' future earnings per share (EPS) and long-term annual percentage growth rate of EPS (converting the long-term forecast assuming a 5-year horizon)   made during May 2022--June 2023 (6 months before and after the event period Nov.-Dec. 2023) using the I/B/E/S data. Column (7) shows the results on firms' quarterly gross profitability. In Columns (2)-(7), \textit{Post} is an indicator for whether the time period is after the release of ChatGPT (i.e., after November 2022). See details about the variables and the specifications in Table \ref{tab:ibes}.   ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 

%This table reports the impact of the release of ChatGPT on cumulative returns during the release period (adjusted for market returns), firm-by-month level measures of analyst forecasts of earnings per share, and accounting measures of reported profitability. Forecasts are made at a monthly frequency for each firm, and we retain the median analyst forecast for each firm for the fiscal years ending December 2024, December 2025, and December 2026, and the long-term (3-5 year horizon) forecast  of the annual growth rate in earnings per share. The regression in columns (2)-(5) uses a panel of firm-by-month median forecasts made during January 2022--June 2023, constructed from I/B/E/S data. The dependent variable in column (6) of is the firm's gross profitability defined as (\textit{Revenue} - \textit{COGS})/\textit{Assets} following \cite{novy2013} in percent.
% The independent variable is an interaction between an indicator for whether the time period is after the release of ChatGPT (i.e., after November 2022), and a continuous measure of GenAI exposure at the firm level. All regressions include both firm-level and time period fixed effects. $t$-statistics in parentheses are computed using standard errors clustered at the time period level (column 2-6) or firm level (column 2). ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 
\vspace{.2cm}

\centering 
\footnotesize

\label{tab:firm_core}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular*}{1.24\textwidth}{l @{\extracolsep{\fill}} cccccccc} 
\toprule
%\textit{Panel:} & Firm & \multicolumn{4}{c}{Firm $\times$ Month} &  \multicolumn{1}{c}{Firm $\times$ Qtr} \\
 %\cmidrule(lr){2-2}  \cmidrule(lr){3-6}   \cmidrule(lr){7-7}  

 \textit{Measure:} & CAR[-1,10] &   EPS 2023   &   EPS 2024    &    EPS 2025      &     EPS 2026      & LTG   & Gross Profit  \\
  \cmidrule(lr){2-2}  \cmidrule(lr){3-3}  \cmidrule(lr){4-4}  \cmidrule(lr){5-5}   \cmidrule(lr){6-6}   \cmidrule(lr){7-7} \cmidrule(lr){8-8}  
 %\textit{Units:} & & \$ & \$ & \$ & \% & \%  \\ 
   & (1)  & (2)  & (3)  & (4)   & (5)     & (6)   & (7)          \\ 
\midrule             
\addlinespace
 \input{../tables/firmvalue_core_short.tex} 
\end{tabular*}
\end{adjustbox}
\end{table}		

	\end{comment}		


	\begin{comment}


\begin{table}[h] 
\caption[]{\\\textbf{Hiring Effects of Gen. AI Exposure: Heterogeneity by Skill}}

\vspace{-.1cm} \small This table reports the impact of the release of ChatGPT on the total number of job postings at the occupation-month level in the U.S. from January 2022 to August 2023 aggregated from the Lightcast (formerly Burning Glass) job posting database. Each column includes a triple interaction between the post-release Gen. AI exposure term and each occupation's skill intensity score for different skills. The skill intensities are computed following \cite{acemoglu2011}, and capture the following skill categories in the respective columns: (1) Non-routine cognitive analytical; (2) Routine cognitive; (3) Non-routine manual interpersonal; (4) Non-routine cognitive interpersonal; (5) Routine manual; (6) Non-routine manual physical.  We estimate all regressions using the Poisson model with fixed effects following \cite{cohn2022} which means that coefficients can be interpreted as semi-elasticities,  i.e.,  in terms of percentage changes in the dependent variable. $t$-statistics in parentheses are computed using standard errors double clustered at the month level and the occupation level. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively.  See Section \ref{subsec:occsubcomp} for more details. 

\vspace{.2cm}

\centering 

\label{tab:occ_skill}
\footnotesize 
\scalebox{0.94}{
\begin{tabular}{lcccccc} 
\toprule
\textit{Dep var.:} & \multicolumn{6}{c}{Job Postings}  \\
 \cmidrule(lr){2-7}  \addlinespace
 \textit{Skill category:} & $\substack{\text{Non-rout. cogn.} \\ \text{analytical} }$ & $\substack{\text{Routine} \\ \text{cognitive} }$ & $\substack{\text{Non-rout. man.} \\ \text{interpersonal} }$ & $\substack{\text{Non-rout. cogn.} \\ \text{interpersonal} }$ & $\substack{\text{Routine} \\ \text{manual} }$ & $\substack{\text{Non-rout. man.} \\ \text{physical} }$ \\
  \cmidrule(lr){2-2}   \cmidrule(lr){3-3}  \cmidrule(lr){4-4}  \cmidrule(lr){5-5}  \cmidrule(lr){6-6}  \cmidrule(lr){7-7}
   & (1)  & (2)  & (3)  & (4)   & (5)  & (6)           \\ 
\midrule             
\addlinespace
 \input{../tables/tab_skill_heterogeneity.tex}
\end{tabular}}
\end{table}		 

			
		
\end{comment}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\FloatBarrier
\newpage

\appendix

\renewcommand{\appendixname}{}

\begin{appendices}
\counterwithin{figure}{section}
\counterwithin{table}{section}
\renewcommand\thefigure{\thesection\arabic{figure}}
\renewcommand\thetable{\thesection\arabic{table}}
\clearpage
\newpage  

\begin{center}
\Large{\it Internet Appendix for}

\Large{\bf {`` Generative AI and Firm Values''}}
\end{center}
\centerline{\large  }
\centerline{\large  {Andrea L. Eisfeldt}   \ \ \ \ \ \ \  {Gregor Schubert} \ \ \ \ \ \ \  {Bledi Taska} \ \ \ \ \ \ \   {Miao Ben Zhang}}
\setcounter{table}{0}
\setcounter{figure}{0}
\setcounter{section}{0}
\renewcommand{\thetable}{IA.\arabic{table}}
\renewcommand{\thefigure}{IA.\arabic{figure}}
%
%%\setcounter{page}{1}
\renewcommand{\thesection}{IA.\arabic{section}}


\clearpage
\newpage
 



 
			
\section{Appendix Figures}
\FloatBarrier




\begin{figure}
\centering 
\includegraphics[width=0.95\linewidth]{../figures/ts_m3d120_mkt}  

\caption[.]{\textbf{Cumulative abnormal returns by Generative AI exposure: Extended pre-period} The figure plots the cumulative abnormal returns (CARs) of value-weighted quintile portfolios sorted by firms' labor-based Generative AI exposure. The graph shows the CARs of the lowest-exposure quintile portfolio, ``Human'' (H), the highest-exposure quintile portfolio, ``Artificial'' (A), and the zero investment portfolio that goes long A and shorts H, ``Artificial-minus-Human'' (AMH). Market-adjusted daily abnormal returns are cumulated from November 29, 2022, the day before the release of ChatGPT, and are based on factor exposures computed over the 4-month period preceding the period shown in the graph.  Daily stock returns are from Yahoo Finance. The dashed vertical lines indicate the ``ChatGPT event period'' from November 30, 2022, to December 14, 2022. See details of the definition of firms' Generative AI exposure in Section \ref{sec:data} and the construction of the portfolios, the calculation of portfolios' CARs, and the determination of the ChatGPT event period in Section \ref{sec:returns}.}
\label{fig:apx_ts_mkt} 
\end{figure}



\begin{figure}[p]
\caption{ \textbf{ Generative AI exposure across and within subsectors: complete list.} \label{fig:gpt_naics2_full} \small This figure plots the average and the standard deviation of Compustat firms' Generative AI exposure within each NAICS 3-digit subsector.  }

\begin{center}
\bf
    \includegraphics[width=1.0\linewidth]{../figures/s12wt_by_ind3d_withsd_all} 
    \vspace{.5cm}
\end{center}
\end{figure} 




	
	
\begin{figure}
\captionsetup{singlelinecheck=off}
\caption[.]{\textbf{ Firm-level Generative AI exposure  and ``engineering'' topic mentions in company earnings conference calls.} \small These graphs use data on the share of S\&P 500 firms' earnings calls that mention a particular topic. The quarterly earnings conference call transcripts for S\&P 500 firms are manually collected from the \textit{Seeking Alpha} website.  Each call transcript is converted into a list of lower-case unigrams and bigrams.   Panel A shows the share of earnings calls mentioning keywords about engineering: ``engineer'' and ``engineering''. 
Panel B then shows the result of estimating regression specifications of the form
\begin{align*}
\mathbbm{1}[\text{Engineering Topic}]_{i,t} = \alpha_t + \beta^X_t \text{GenAI Exp}_i + \gamma \mathbbm{1}[\text{Engineering Topic}]_{i,2019}  + \varepsilon_{i,t} 
\end{align*}
 for cross-sections in each fiscal quarter from 2019 Q1 to 2023 Q1.  The graph shows the estimates $\hat{\beta}^X_t $ that represent the effect of higher Generative AI exposure on the likelihood that a firm mentions ``engineering'' as a topic in that quarter's earnings call,  controlling for whether the firm already mentioned the topic in any 2019 earnings call.  Dotted lines show 95\% confidence intervals based on heteroskedasticity-robust standard errors.   \label{fig:calltrends_apx} }
     \captionsetup[subfigure]{justification=centering}
 		\centering 
         \includegraphics[width=0.55\linewidth]{../figures/calltrends_callshare_m_eng} 
        \subcaption{Share of earnings calls mentioning Engineering}
 
        \includegraphics[width=0.55\linewidth]{../figures/calls_eng_s12wt_qrt} 
        \subcaption{Effect of Gen.  AI exposure on firm mentioning Engineering}
			
	\end{figure}
	
	
\begin{figure}
\captionsetup{singlelinecheck=off}
\caption[.]{\textbf{Price reaction of IT producers versus~the AMH portfolio:} \small This plot shows the release event period cumulative abnormal returns adjusted for FF5 factor exposure the AMH portfolio and a long-short portfolio of IT producers versus~Non-IT producers, where IT producers are defined based on \cite{saunders2016valuing} as all firms with primary industry codes in computer and electronic product manufacturing (NAICS 334), software publishing (NAICS 5112), data processing, hosting, and related services (NAICS 518), and computer system design and related services (NAICS 5415). The figure shows that the impact of the release of ChatGPT on IT producers occurred in one day, consistent with the industry effect being simpler than, and distinct to, the labor effects.  Daily abnormal returns are cumulated from November 29, 2022, the day before the release of ChatGPT, and are based on factor exposures computed over the 6-month period preceding the period shown in the graph. Daily stock returns are from Yahoo Finance. The dashed vertical lines indicate the â€œChatGPT event periodâ€ from November 30, 2022, to December 14, 2022.  
  \label{fig:prduct_vs_labor}}
     \captionsetup[subfigure]{justification=centering}
 		\centering 
         \includegraphics[width=0.9\linewidth]{../figures/ts_w2d180_ff5_tech_crop.png} 
       \end{figure}	





\begin{figure} 
    \centering
\caption{\textbf{Firms' Generative AI exposure and the hiring effects:} This figure plots the dynamic effects of firm-level Generative AI exposure on firm-level job posting for high-GenAI-exposure occupations before and after the release of ChatGPT.  In Panel A, the regression specification is the following:  $y_{i,q} =   \sum_{q\in[2021q1, 2023q3]} \beta_{q} \cdot  1_q \times \text{GenAI Exp}_i+\alpha_i +\alpha_q + \epsilon_{i,q},$ where $\alpha_i$ indicates firm fixed effects and $\alpha_q$ indicates quarter fixed effects. The figure plots the coefficients $\beta_{q}$, which capture the relative size of the effect of firm-level Generative AI exposure on the outcome variable in each quarter \textit{relative} to 2022Q3. Panel B replaces the quarter fixed effects with industry-quarter fixed effects, where industry is defined at the NAICS 3-digit level. Panel C further excludes firms from the tech sectors (see Table \ref{tab:robust_quintiles}).    \label{fig:jobposting_pretrend} }
    \bigskip \bigskip 

    \bf 
    Panel A: With Quarter Fixed Effects 
    
    \includegraphics[width=0.5\textwidth, trim=0 0 0 27pt, clip]{../figures/diffindiff_NoindFE.png} % replace with your filename
    \bigskip 
 \bigskip 
 
    Panel B: With Industry-Quarter Fixed Effects 
    
    \includegraphics[width=0.5\textwidth, trim=0 0 0 27pt, clip]{../figures/diffindiff_indFE.png} % replace with your filename
    \bigskip \bigskip 
    
    Panel C: With Industry-Quarter Fixed Effects (Exclude Tech Sectors) 
    
    \includegraphics[width=0.5\textwidth, trim=0 0 0 27pt, clip]{../figures/diffindiff_indFENoTech.png} % replace with your filename



\end{figure}



\begin{figure} 
\centering 
\caption{\textbf{Occupations' core-task and supplemental-task exposures to Generative AI:} The plot shows the distribution of  occupations' core-task exposure to Generative AI in $x$-axis and supplemental-task exposure in $y$-axis. Each dot represents a SOC 6-digit occupation. An occupation's supplemental-task exposure to Generative AI is computed as the occupation's GenAI Exposure (equation \eqref{eq:exp}) multiplied by its' ShareSupp (equation \eqref{eq:suppdefine}). The red line is the 45 degree line.   \label{fig:task_magnitude} }

\bigskip \bigskip 

\includegraphics[width=0.9\linewidth]{../figures/task_magnitude}   

\end{figure}


\begin{comment}
\begin{figure} 
\centering 
\includegraphics[width=0.8\linewidth]{../figures/gpt_occ2d_supp}   
\caption{\textbf{Generative AI Exposure and Supplemental Exposure Share by Major Occupation Group.} The figure plots the relationship between Generative AI exposure and the supplemental task share of exposure by SOC 2-digit occupation group. We aggregate the Generative AI exposure and supplemental task exposure shares from SOC 6-digit to SOC 2-digit using the May 2022 occupational employment distribution from the Bureau of Labor Statistics Occupational Employment and Wage Statistics (OEWS) downloaded at \url{https://www.bls.gov/oes/current/oes_stru.htm}.  \label{fig:supp_exp_occ} }
\end{figure}

\end{comment}
		
\clearpage 


		\FloatBarrier
			\newpage

		
\section{Appendix Tables}




\begin{table}[h]
\caption{ \\ \textbf{ Highest and Lowest Generative AI Exposure Score Occupations}} 

\small  See Section \ref{subsec:occexposure} for details. Note that 15\% (102 of 678) of the occupations that exist in our Revelio Labs data have zero exposure, so only a subset of the lowest exposure occupations is shown.
\smallskip

\label{tab:highlowocc}
\
\centering \footnotesize \renewcommand{\arraystretch}{0.7}
\begin{tabular}{>{\raggedright\arraybackslash}p{1.5cm} >{\raggedright\arraybackslash}p{10cm}>{\centering \arraybackslash}p{1.4cm} >{\centering \arraybackslash}p{1.9cm}}
\toprule
\textbf{SOC Code} & \textbf{Occupation Title} & \textbf{GenAI Exp} & \textbf{ShareSupp}  \\
\midrule
\input{../tables/score_s12wt_high}
\vdots & \vdots&\multicolumn{1}{c}{\vdots} \\
\input{../tables/score_s12wt_low}
\bottomrule
\end{tabular}
\end{table}



% \begin{table}[h]
% \caption{ \\ \textbf{Occupations with Highest Core- vs. Supplemental-Task Exposure.}} 

% \small  See Section \ref{subsec:eos} for details. Panel A lists occupations with the highest core-task exposure to Generative AI among those with their $ShareSupp_o$ below the top quartile. Panel B lists occupations with the highest supplemental-task exposure to Generative AI among those with their $ShareSupp_o$ above the top quartile. \textit{Core-Task Exposure} is the occupation's GenAI Exposure multiplied by ShareCore. \textit{Supplemental-Task Exposure} is the occupation's GenAI Exposure multiplied by ShareSupp. 
% \medskip

% \label{tab:highlowocc_bycore}


% \centering \scriptsize  
% \renewcommand{\arraystretch}{1}
% \begin{tabular*}{\textwidth}{l @{\extracolsep{\fill}} lcc}
%     \toprule
%     % \multicolumn{3}{c}{\textbf{Panel A: Occupations with High Substitutable Skills to GenAI}} \\
%     % \midrule
%     % \textbf{SOC}   & \textbf{Occupation Title}  & \multicolumn{1}{l}{\bf Core-Task } \\
%     % \textbf{Code}  &       & \multicolumn{1}{l}{\bf Exposure Score} \\
%     % \midrule
%     % \toprule
%     % \midrule
%     SOC   & Occupation Title  & \multicolumn{1}{l}{Core-Task } & \multicolumn{1}{l}{Supp-Task } \\
%     Code  &       & \multicolumn{1}{l}{Exposure} & \multicolumn{1}{l}{Exposure} \\ \midrule 

%     \multicolumn{4}{c}{\textbf{Panel A: Occupations with High Core-Task Exposure to GenAI}} \\
%     \midrule
%     43-9081 \ \ \ & Proofreaders and Copy Markers & 0.82  & 0.14 \\
%     15-2021 & Mathematicians & 0.82  & 0.05 \\
%     15-1122 & Information Security Analysts & 0.75  & 0.00 \\
%     41-3099 & Sales Representatives, Services, All Other & 0.73  & 0.00 \\
%     43-9022 & Word Processors and Typists & 0.70  & 0.15 \\
%     43-3011 & Bill and Account Collectors & 0.70  & 0.13 \\
%     15-1152 & Computer Network Support Specialists & 0.67  & 0.00 \\
%     15-2031 & Operations Research Analysts & 0.66  & 0.03 \\
%     15-1131 & Computer Programmers & 0.65  & 0.21 \\
%     15-1134 & Web Developers & 0.64  & 0.03 \\
%     43-9111 & Statistical Assistants & 0.64  & 0.18 \\
%     15-2041 & Statisticians & 0.64  & 0.00 \\
%     27-3042 & Technical Writers & 0.63  & 0.00 \\
%     41-3041 & Travel Agents & 0.63  & 0.00 \\
%     27-3043 & Writers and Authors & 0.62  & 0.13 \\
%     27-3031 & Public Relations Specialists & 0.61  & 0.08 \\
%     15-1111 & Computer and Information Research Scientists & 0.60  & 0.00 \\
%     31-9094 & Medical Transcriptionists & 0.60  & 0.00 \\
%     15-1132 & Software Developers, Applications & 0.59  & 0.00 \\
%     15-1133 & Software Developers, Systems Software & 0.59  & 0.00 \\
%     43-6011 & Executive Secretaries and Executive Administrative Assistants & 0.59  & 0.18 \\
%     27-3021 & Broadcast News Analysts & 0.58  & 0.00 \\
%     13-2082 & Tax Preparers & 0.58  & 0.00 \\
%     27-3022 & Reporters and Correspondents & 0.58  & 0.00 \\
%     15-1199 & Computer Occupations, All Other & 0.58  & 0.00 \\
%     \midrule
%     \multicolumn{4}{c}{\textbf{Panel B: Occupations with High Supplemental-Task Exposure  to GenAI}} \\
%     % \midrule
%     % SOC   & Occupation Title  & \multicolumn{1}{l}{Core-Task } & \multicolumn{1}{l}{Supp-Task } \\
%     % Code  &       & \multicolumn{1}{l}{Exposure} & \multicolumn{1}{l}{Exposure} \\
%     \midrule
%     43-5111 & Weighers, Measurers, Checkers, and Samplers, Recordkeeping & 0.14  & 0.39 \\
%     31-9095 & Pharmacy Aides & 0.12  & 0.38 \\
%     45-2011 & Agricultural Inspectors & 0.05  & 0.30 \\
%     43-9051 & Mail Clerks and Mail Machine Operators, Except Postal Service & 0.00  & 0.28 \\
%     21-1094 & Community Health Workers & 0.03  & 0.21 \\
%     43-5051 & Postal Service Clerks & 0.10  & 0.19 \\
%     41-9011 & Demonstrators and Product Promoters & 0.04  & 0.17 \\
%     39-7011 & Tour Guides and Escorts & 0.03  & 0.16 \\
%     27-4012 & Broadcast Technicians & 0.05  & 0.16 \\
%     27-4011 & Audio and Video Equipment Technicians & 0.05  & 0.14 \\
%     51-5112 & Printing Press Operators & 0.07  & 0.13 \\
%     29-2053 & Psychiatric Technicians & 0.00  & 0.13 \\
%     49-9091 & Coin, Vending, and Amusement Machine Servicers and Repairers & 0.05  & 0.11 \\
%     51-6063 & Textile Knitting and Weaving Machine Setters, Operators, and Tenders & 0.05  & 0.10 \\
%     27-2042 & Musicians and Singers & 0.02  & 0.10 \\
%     51-2092 & Team Assemblers & 0.00  & 0.09 \\
%     39-9021 & Personal Care Aides & 0.00  & 0.09 \\
%     35-2012 & Cooks, Institution and Cafeteria & 0.00  & 0.09 \\
%     51-3021 & Butchers and Meat Cutters & 0.04  & 0.08 \\
%     53-3031 & Driver/Sales Workers & 0.00  & 0.08 \\
%     29-2031 & Cardiovascular Technologists and Technicians & 0.04  & 0.08 \\
%     19-4051 & Nuclear Technicians & 0.04  & 0.08 \\
%     29-2055 & Surgical Technologists & 0.03  & 0.06 \\
%     39-6011 & Baggage Porters and Bellhops & 0.00  & 0.06 \\
%     31-1013 & Psychiatric Aides & 0.03  & 0.06 \\
    
%     \bottomrule
% \end{tabular*}
% \end{table}



		
\begin{table}[p]  
\caption{  \\ \textbf{ Generative AI Exposure for the Largest 100 U.S. Firms}} \label{apptab:firm_gpt} 

\small This table lists the Generative AI exposure scores for the largest 100 publicly-traded firms with headquarters in the U.S., where size is measured as the market capitalization as of November 1, 2022. \textit{Generative AI exposure} is the firm's labor exposure defined in Section \ref{sec:data}.  \textit{MktCap} is the firm's market capitalization as of November 1, 2022, in \$B.  \textit{Subsector} is defined at the NAICS 3-digit level. 

\vspace{.5cm}
\centering
\footnotesize
\scalebox{.6}{  \renewcommand{\arraystretch}{0.6}
\begin{tabular}{llll}
\toprule
    Company Name &  Gen.  AI exposure \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \ &  MktCap \ \ \ \ \ \  \ \ \ \ \ \ \ \ \ \ \ \ & Subsector \\
    \midrule
  \input{../tables/Top_Bottom_US_Large_Firms_3d}
    \bottomrule
    \end{tabular}
    }
\end{table}



\begin{table}[h]
\caption{ \\  \textbf{ Generative AI Exposure Scores by NAICS 3-digit Industry}}
\smallskip 

\centering \scriptsize
\scalebox{.9}{
\begin{tabular}{>{\raggedright\arraybackslash}p{3cm} >{\raggedright\arraybackslash}p{11cm}>{\raggedright\arraybackslash}p{3cm}}
\toprule
\textbf{NAICS Subsector} & \textbf{Industry Title} & \textbf{Exposure Score}  \\
\midrule
\input{../tables/score_s12wt_naics3d}
\bottomrule
\end{tabular}}
\label{tab:highlowind}
\end{table}



\def\sym#1{\ifmmode^{#1}\else\(^{#1}\)\fi}
\begin{table}[p]  
\caption{ \\  \textbf{ Firm Generative AI Exposure and Firm Characteristics}}  \label{tab:firmgpt_char} 

\small  This table regresses our firms' Generative AI exposure measure on firm characteristics using the cross-section of U.S. publicly traded firms in 2022. See Table \ref{tab:summary} for variable definitions. Panel B controls for fixed effects at the NAICS 3-digit level.  All variables are winsorized at the top and bottom 1\%. Standard errors are clustered at the industry level and reported in parentheses. \sym{*}, \sym{**}, and \sym{***} indicate significance at the 10\%, 5\%, and 1\% level, respectively.
 
\footnotesize  
\begin{center}
\begin{tabular}{lccccccc}
\toprule
\multicolumn{7}{c}{\bf Panel A: Across All Firms}  \\ \midrule
\input{../tables/GPT_Char_new_A.tex}
\midrule
\multicolumn{7}{c}{\bf Panel B: Within-Industry}  \\ \midrule
\input{../tables/GPT_Char_new_B.tex}
\bottomrule
\end{tabular} 
\end{center}
\end{table}






\begin{table}[h] 
\caption[]{\\ \textbf{Reaction of Portfolios Sorted by Generative AI Exposure: Shorter Event Period}}

\vspace{-.1cm} \small This table reports daily percentage stock returns, as a measure of changes in firm value, during the ChatGPT event period for five value-weighted portfolios sorted on firms' Generative AI exposure. To form the portfolios, we sort NYSE stocks on November 29, 2022 into five quintiles by their Generative AI exposure, and we assign all stocks into the portfolios using the NYSE breakpoints. We aggregate stock returns within each portfolio using the stocks' market capitalization on the prior trading day as the weight. \textit{AMH} is the ``Artificial Minus Human'' zero net investment portfolio long the portfolio with high exposure and short the portfolio with low exposure. We define the shorter ChatGPT event period here as from November 29, 2022 to December 7, 2022, i.e., one day before to 1 week after the release of ChatGPT (see Section \ref{sec:returns} for more details). Panel A reports each portfolio's raw daily return in excess of the risk free rate. Panels B and C report the CAPM market-adjusted alphas and the Fama-French 5-factor-adjusted alphas, where the factor loadings of each portfolio are estimated using data from the previous six months. Panel D reports the Fama-French 5-factor-adjusted alphas for a sample that excludes firms in the tech sectors, NAICS 51 (information) and NAICS 54 (business services), following \cite{acemoglu2022}.  $t$-statistics are shown in parentheses.  See Section \ref{subsec:mainreturn} for more details.  \vspace{.2cm} 
\footnotesize 

\centering 

\label{tab:5d_quintiles}
\begin{tabular}{cccccccc} 
\toprule
\addlinespace
\ \ \ & \ \ \ \ \ \  {Q1 (H)} \ \ \ \ \ \   & \ \ \ \ \   \    {Q2} \ \ \ \ \   \ & \ \  \ \  \  \ {Q3}    \ \ \ \  \  \ &     \  \ \ \ \ \ {Q4} \   \  \ \  \ \  &  \ \ \ \  \ \ {Q5 (A)} \ \ \  \ \ \    & \ \ \ \ \  \     {AMH} \ \ \ \ \  \ &   \\
\midrule 
\csname @@input\endcsname {../tables/pf_news_w2d180_5d.tex}
\midrule \addlinespace
\csname @@input\endcsname {../tables/pf_news_w2d180_B_5d.tex}
\bottomrule
\end{tabular}
\end{table}	



\begin{table}[h] 
\caption[]{\\ \textbf{Reaction of Portfolios Sorted by Generative AI Exposure: Longer Event Period}}

\vspace{-.1cm} \small This table reports daily percentage stock returns, as a measure of changes in firm value, during the ChatGPT event period for five value-weighted portfolios sorted on firms' Generative AI exposure. To form the portfolios, we sort NYSE stocks on November 29, 2022 into five quintiles by their Generative AI exposure, and we assign all stocks into the portfolios using the NYSE breakpoints. We aggregate stock returns within each portfolio using the stocks' market capitalization on the prior trading day as the weight. \textit{AMH} is the ``Artificial Minus Human'' zero net investment portfolio long the portfolio with high exposure and short the portfolio with low exposure. We define the \textit{longer} ChatGPT event period here as from November 29, 2022 to December 21, 2022, i.e., one day before to 3 weeks after the release of ChatGPT (see Section \ref{sec:returns} for more details). Panel A reports each portfolio's raw daily return in excess of the risk free rate. Panels B and C report the CAPM market-adjusted alphas and the Fama-French 5-factor-adjusted alphas, where the factor loadings of each portfolio are estimated using data from the previous six months. Panel D reports the Fama-French 5-factor-adjusted alphas for a sample that excludes firms in the tech sectors, NAICS 51 (information) and NAICS 54 (business services), following \cite{acemoglu2022}.  $t$-statistics are shown in parentheses.  See Section \ref{subsec:mainreturn} for more details.  \vspace{.2cm} 
\footnotesize 

\centering 

\label{tab:15d_quintiles}
\begin{tabular}{cccccccc} 
\toprule
\addlinespace
\ \ \ & \ \ \ \ \ \  {Q1 (H)} \ \ \ \ \ \   & \ \ \ \ \   \    {Q2} \ \ \ \ \   \ & \ \  \ \  \  \ {Q3}    \ \ \ \  \  \ &     \  \ \ \ \ \ {Q4} \   \  \ \  \ \  &  \ \ \ \  \ \ {Q5 (A)} \ \ \  \ \ \    & \ \ \ \ \  \     {AMH} \ \ \ \ \  \ &   \\
\midrule 
\csname @@input\endcsname {../tables/pf_news_w2d180_15d.tex}
\midrule \addlinespace
\csname @@input\endcsname {../tables/pf_news_w2d180_B_15d.tex}
\bottomrule
\end{tabular}
\end{table}	

\begin{table}[h]\footnotesize
\caption[]{\\ \textbf{Reaction of Portfolios Sorted by Generative AI Exposure: Non-event Period}}   

\vspace{-.1cm} \small This table reports daily percentage stock returns, as a measure of changes in firm value, in the days surrounding, but outside of,  the ChatGPT event period for five value-weighted portfolios sorted on firms' Generative AI exposure. To form the portfolios, we sort NYSE stocks on November 29, 2022 into five quintiles by their Generative AI exposure, and we assign all stocks into the portfolios using the NYSE breakpoints. We aggregate stock returns within each portfolio using the stocks' market capitalization on the prior trading day as the weight. \textit{AMH} is the ``Artificial Minus Human'' zero net investment portfolio long the portfolio with high exposure and short the portfolio with low exposure. We define the ChatGPT event period as from November 30, 2022 to December 14, 2022, i.e., the two weeks after the release of ChatGPT (see Section \ref{sec:returns} for more details).  The table then shows placebo event study returns for the ten trading days before (Nov.  14- Nov. 29, 2022) and after (Dec 15 - Dec 29,  2022) the ChatGPT-release event period.   Panel A reports each portfolio's raw daily return in excess of the risk free rate. Panels B and C report the CAPM market-adjusted alphas and the Fama-French 5-factor-adjusted alphas, where the factor loadings of each portfolio are estimated using data from the previous six months. Panel D reports the Fama-French 5-factor-adjusted alphas for a sample that excludes firms in the tech sectors, NAICS 51 (information) and NAICS 54 (business services), following \cite{acemoglu2022}.  $t$-statistics are shown in parentheses.  See Section \ref{subsec:mainreturn} for more details.  \vspace{.2cm} 

\centering 

\label{tab:robust_quintiles_nonews}
\begin{tabular}{ccccccc} 
\toprule
\addlinespace
\ \ \ & \ \ \ \ \ \  {Q1 (H)} \ \ \ \ \ \   & \ \ \ \ \   \    {Q2} \ \ \ \ \   \ & \ \  \ \  \  \ {Q3}    \ \ \ \  \  \ &     \  \ \ \ \ \ {Q4} \   \  \ \  \ \  &  \ \ \ \  \ \ {Q5 (A)} \ \ \  \ \ \    & \ \  \      {AMH} \ \ \   \\
\midrule 
\csname @@input\endcsname {../tables/pf_nonews_w2d180.tex}
%\input{../tables/pf_nonews_m3d120.tex}
\midrule \addlinespace
\csname @@input\endcsname {../tables/pf_nonews_w2d180_B.tex}
%\input{../tables/pf_nonews_m3d120_B.tex}
\bottomrule
\end{tabular}
\end{table}	



	
\begin{table}[h]\footnotesize

\captionsetup{singlelinecheck=off}
\caption[]{ \\  \textbf{Within-industry Portfolios Sorted by Generative AI Exposure: Non-event Period}} 

\vspace{-.1cm} \small This table reports daily percentage stock returns, as a measure of changes in firm value, in the days surrounding, but outside of,  the ChatGPT event period for three value-weighted portfolios sorted on firms' Generative AI exposure within the industry. To form the portfolios, we sort NYSE stocks on November 29, 2022 into three terciles by their Generative AI exposure across all stocks in Panels A1 and B1, within the NAICS 3-digit industry in Panels A2 and B2, and within the \cite{hoberg2016} FIC 50-industry in Panels A3 and B3, and we assign all stocks into the portfolios using the NYSE breakpoints. We aggregate stock returns within each portfolio using the stocks' market capitalization on the prior trading day as the weight. \textit{AMH} is the ``Artificial Minus Human'' zero net investment portfolio long the portfolio with high exposure and short the portfolio with low exposure.  We define the ChatGPT event period as from November 30, 2022 to December 14, 2022, i.e., the two weeks after the release of ChatGPT (see Section \ref{sec:returns} for more details).  The table then shows placebo event study returns for the ten trading days before (Nov.  14- Nov. 29, 2022) and after (Dec 15 - Dec 29,  2022) the ChatGPT-release event period.   Panels A1-A3 report the CAPM market-adjusted alphas, and Panels B1-B3 report the Fama-French 5-factor-adjusted alphas.  $t$-statistics are shown in parentheses. See Section \ref{subsec:withinindustry} for more details. \vspace{.2cm}

\centering 
 \label{tab:terciles_withinindustry_nonews}
\begin{tabular}{lcccc} 
\toprule
\addlinespace
 & \ \ \ \ \ \ \ \ \ \ \  {Q1 (H)}   \ \ \ \  \ \ \ \ \ \ &   \ \ \ \ \ \ \ \ \ \ \  {Q2} \ \ \  \ \ \ \ \  \ \ \   &  \ \ \ \ \   \ \ \ {Q3 (A)}    \ \ \  \ \ \ \ \ \ & \ \ \ \ \ \ \ \    \ \ {AMH} \ \  \ \ \ \ \ \ \ \ \  \\
\midrule 
\csname @@input\endcsname {../tables/pf_terc_nonews_w2d180.tex}
\bottomrule
\end{tabular}

\end{table}		




		\begin{table}[h]
\caption[.]{\\\textbf{Product AI Exposure Proxies and Reported AI Use}}
			
\vspace{-0.1cm} \small These regressions show the relationship between different proxies for industries' product exposure to AI and the reported AI use by firms in the industry.  The AI use in production by industry is measured as the average rate of ``yes'' responses to the question \textit{``In the last two weeks, did this business use Artificial Intelligence (AI) in producing goods or services?''} by 3-digit NAICS subsector in the U.S. Census Bureau Business Trends and Outlook Survey from October 23, 2023.  The proxies for product exposure to AI are aggregated from firm-level measures as employment-weighted means by NAICS subsector.  The definitions of the four proxies for firms' product exposure to AI are described in detail in Section \ref{sec:product}. \textit{GPT10 Product Exp} is based on GPT 3.5 Turbo assessment of firms' annual reports' description of their products. \textit{Count10K Product Exp} is based on counting AI-related keywords in firms' annual reports. \textit{GS Product Exp} is based on Goldman Sachs' classification of firms as ``near-term beneficiaries of AI''.  \textit{BFHH Product Exp} is based on firms' share of AI-skilled workers constructed by \cite{babina2024artificial}. All product exposure measures are standardized to have a mean of zero and a standard deviation of one, except \textit{GS Product Exp}  and \textit{GPT10K Product Exposure}, which are binary variables. The last column includes all four  measures at the same time.  t-statistics based on heteroskedasticity-robust standard errors are shown in parentheses.  ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 
\vspace{.2cm}

\centering

 \label{tab:btos}  \label{fig:btos}
 \scalebox{.95}{
\begin{tabular}{lccccc} 
\toprule
 Dep.  var.: & \multicolumn{5}{c}{\ \ \ \ \ \ \ AI Use in Last 2 Wks \%, Oct. 2023 (BTOS Survey)\ \ \ \ \ \ \ }  \\
\cmidrule(lr){2-6} 
\input{../tables/product_adoption_3d.tex}
\bottomrule
\end{tabular}
}
\end{table}	


			
%\begin{landscape}
\begin{table}[h]\footnotesize

\captionsetup{singlelinecheck=off}
\caption[]{ \\  \textbf{ Cumulative Abnormal Returns and Generative AI Exposure: Other Abnormal Return Models}}


\vspace{-.1cm}  \small This table reports the relation between firms' cumulative abnormal returns during the ChatGPT event period, [$-1, 10$] trading days around the release of ChatGPT on November 30, 2022, (CAR [$-1, 10$]) and firms' labor-based Generative AI exposure defined in Section \ref{sec:data}.  To compute the baseline cumulative abnormal return of each stock, we first subtract the daily market return from Kenneth French's website from the daily stock return from Yahoo Finance,  and then we cumulate the daily abnormal returns over [$-1, 10$]. 
Columns (1)-(2) show abnormal returns as defined in the baseline model where returns are adjusted by risk free rates.  Columns (3)-(4) compute abnormal returns relative to the CAPM model,  and columns (5)-(6) relative to the Fama French 5-factor model.  These abnormal returns are computed by first estimating factor loadings for each firm separately either for the market factor or the Fama French 5-Factor model using data for the 6 months from May 18, 2022 - Nov 14, 2022 (ending two weeks before the GPT release), and then computing abnormal returns for later periods as the difference between the raw excess returns and the returns predicted by the factor loadings.  Where indicated, regressions include NAICS 3-digit fixed effects.  Equation \eqref{eq:CAR_Product} describes the regression specification and the weighting of firms. $t$-statistics are computed using heteroskedasticity-robust standard errors and reported in parentheses.  ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. \vspace{.5cm}


\centering
\label{tab:car_apx}
 \scalebox{.99}{
\begin{tabular}{lcccccccc} 
\toprule
 Dep.  var.: & \multicolumn{6}{c}{CAR[-1,10]  }   \\
\cmidrule(lr){2-7}  
Abnormal returns:  &    \multicolumn{2}{c}{Baseline}  
&     \multicolumn{2}{c}{CAPM} 
&    \multicolumn{2}{c}{FF5}   \\
\cmidrule(lr){2-3}  \cmidrule(lr){4-5}  \cmidrule(lr){6-7} 
\input{../tables/car_apx.tex}
\end{tabular}}
\end{table}	

%\end{landscape}	

\begin{table}[h]\footnotesize
\centering
\captionsetup{singlelinecheck=off}
\caption[]{ \\  \textbf{ Correlations between Firm-Level Generative AI exposure, AI Product Market Exposure, and Data Assets}}  


\vspace{-.1cm}  \small This table reports the correlation between the firm-level Generative AI exposure measure defined in Section \ref{subsec:firmgenai} , the different product market exposure (``PE'') measures defined in Section \ref{sec:product}, and the data asset (``DA'') measures defined in Section \ref{subsec:datavalue}.


\label{tab:corr}
 \scalebox{.99}{
%\input{../tables/corrfirm.tex}
\begin{tabular}{l*{9}{c}}
\toprule 
\input{../tables/corrfirm.tex}
\bottomrule 
\end{tabular}
}
\end{table}	



			
\begin{table}[h] 
\caption[]{\\\textbf{Generative AI Exposure and Firm Data Assets and Firm Size}}

\vspace{-.1cm} \small This table reports coefficients from regressions of cumulative abnormal returns of firms during the ChatGPT event period, [$-1, 10$] trading days around the release of ChatGPT on November 30, 2022, on firms' Generative AI exposure interacted with proxies for their data assets and also  interacted with proxies for firm size in the form of quintiles of total firm employment in Compustat as of October 2022. The largest firm size quintile is omitted as the reference category. To compute the cumulative abnormal return of each stock, we first subtract the daily market return from Kenneth French's website from the daily stock return from Yahoo Finance,  and then we cumulate the daily abnormal returns over the [$-1, 10$] period. Section \ref{subsec:datavalue} details the construction of the two proxies for firms' data assets.  \textit{10K Data Assets} is a score of 0, 1, 2, or 3, indicating the firm is not likely, slightly likely, moderate likely, or highly likely to have data that can be used as an input into large language model analytics based on the assessment of firms' annual reports using the GPT 3.5 Turbo Model. \textit{AV Data Assets} is constructed following \cite{abis2023} and measures the intensity of data management skills in the firm's workforce. All regressions include NAICS 3-digit fixed effects and employment quintile fixed effects,  and weight firms by their market capitalization as of November 29, 2022. $t$-statistics are computed using heteroskedasticity-robust standard errors and reported in parentheses.  ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 

\vspace{.2cm}

\centering
\footnotesize 

\label{tab:datasize}
% \begin{tabular*}{\textwidth}{l @{\extracolsep{\fill}} cc}
% \toprule
%  Dep.  var.: & \multicolumn{2}{c}{CAR[-1,10] } \\
% \cline{2-3}   \addlinespace           &\multicolumn{1}{c}{ \ \ \ \ \ \ \ \ \ \ (1) \ \ \ \ \ \ \  \ \ \  }   &\multicolumn{1}{c}{ \ \ \ \ \ \ \ \ \ \   (2)  \ \ \ \ \ \ \ \ \ \  }   \\ \midrule 
% \input{../tables/data_car_size.tex}
% \end{tabular*}
\begin{tabular*}{\textwidth}{l @{\extracolsep{\fill}} ccc}
\toprule
 Dep.  var.: & \multicolumn{3}{c}{CAR[-1,10] } \\
\cline{2-4}   \addlinespace           &\multicolumn{1}{c}{  (1)  }  &\multicolumn{1}{c}{  (2)  }  &\multicolumn{1}{c}{  (3)  }    \\ \midrule 
\input{../tables/data_car_size.tex}
\end{tabular*}
\end{table}	
	 



			
\begin{table}[h] 

\caption[]{\\\textbf{Future Revenue Impact and Generative AI Exposure}}

\vspace{-.1cm} \small This table reports the impact of the release of ChatGPT on analyst forecasts of firms' future revenues and on firms' reported quarterly revenues. Analyst forecasts are updated at a monthly frequency for each firm in the I/B/E/S data. For each firm in each month, we obtain the median analyst forecasts of the firm's revenues in the fiscal year ending in December 2023 in billions and the firm's long-term annual percentage growth rate in revenues (LTG (Revenues)). The dependent variables in Columns (1) and (2) are the firm's median forecasts of the corresponding measures made in October 2022 and January 2023. The dependent variable in Column (3) is the firm's quarterly revenues in billions in the Compustat quarterly data from 2022Q1 to 2024Q3. The independent variable \textit{Post} is an indicator for whether the time period is after the release of ChatGPT (i.e., after November 2022).  \textit{GenAI Exp} is a continuous measure of GenAI exposure at the firm level. See Section \ref{sec:cashflow_mechanism} for more details. All regressions include both firm-level and time-period fixed effects. $t$-statistics in parentheses are computed using standard errors clustered at the firm level. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively.   
\vspace{.2cm}

\centering 
\label{tab:ibesrev}
\footnotesize
%\scalebox{0.955}{
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lccc} 
\toprule
\textit{Data:} & \multicolumn{2}{c}{ I/B/E/S Analyst Forecasts} &  \multicolumn{1}{c}{Compustat} \\
 \cmidrule(lr){2-3}   \cmidrule(lr){4-4}  
 % \textit{Measure:  \ \ \ \ \  \ \ \ \ \  \ \ \ \ \ }  & \ \  EPS 2024 \ \  &  \ \ EPS  2025 \  \   &  \  \ EPS  2026 \  \   & \ \ \ \ \     LTG      \ \ \ \ \    &  \   Gross Profit  \  \\
 %  \cmidrule(lr){2-2}  \cmidrule(lr){3-3}  \cmidrule(lr){4-4}  \cmidrule(lr){5-5}   \cmidrule(lr){6-6}  


 \textit{Measure:}  &  \ \ \ \ \    \ \ \ \ \ Revenues 2023  \ \ \ \ \ \ \ \ \ \   &  \ \ \ \ \  \ \ \  LTG (Revenues) \ \ \  \ \ \ \ \  &  \ \ \ \ \   \ \ \  Revenues  \ \ \ \ \ \ \ \  \\
  \cmidrule(lr){2-2}  \cmidrule(lr){3-3}  \cmidrule(lr){4-4}  
 %\textit{Units:} & \$M & \$M & \$M & \%  \\ 
   & (1)  & (2)  & (3)          \\ 
\midrule             
\addlinespace
 \input{../tables/ibes_rev_short_BenNewSample.tex} 
\end{tabular}
\end{adjustbox}
\end{table}		 


\begin{table}[h] 

\caption[]{\\ \textbf{ Firm Hiring of Occupations by Exposure}}

% \vspace{-.1cm} \footnotesize    This table reports the impact of the release of ChatGPT on firms' job postings and employment in occupations with high/medium/low-exposure to Generative AI. In Panel A, the sample includes the high/medium/low-exposure (top/medium/bottom tercile) job postings at the firm-month level from January 2022 to August 2023 aggregated from the Lightcast (formerly Burning Glass) job posting database. In Panel B, the sample consists of total employment in high/medium/low-exposure (top/medium/bottom tercile) occupations at publicly traded firms for each month, computed from LinkedIn data for publicly traded U.S. firms from January 2022 to December 2023.  \textit{GenAI Exp} is the \textit{firm}-level Generative AI exposure, which is an employment-weighted average across occupations within the firm. \textit{ShareSupp} is the firm's share of Generative AI exposure deriving from the supplemental tasks' exposure to Generative AI. The job posting panels include many zeros,  which makes it impractical to log-transform the dependent variable.  Instead,  we estimate all regressions using the Poisson model with fixed effects following \cite{cohn2022} which means that coefficients can be interpreted as semi-elasticities,  i.e.,  in terms of percentage changes in the dependent variable. $t$-statistics in parentheses are computed using standard errors double clustered at the month level and the firm level. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 

\vspace{-.1cm} \footnotesize    This table reports the impact of the release of ChatGPT on firms' job postings for occupations with different exposures to Generative AI. The sample includes the high/medium/low-exposure (top/medium/bottom tercile) job postings at the firm-month level from January 2022 to August 2023 aggregated from the Lightcast (formerly Burning Glass) job posting database.  \textit{ShareSupp} is the firm's share of Generative AI exposure deriving from the supplemental tasks' exposure to Generative AI. The job posting panels include many zeros,  which makes it impractical to log-transform the dependent variable.  Instead,  we estimate all regressions using the Poisson model with fixed effects following \cite{cohn2022} which means that coefficients can be interpreted as semi-elasticities,  i.e.,  in terms of percentage changes in the dependent variable. $t$-statistics in parentheses are computed using standard errors double clustered at the month level and the firm level. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 

\vspace{.2cm}

\centering 

\label{tab:empfirm_expanded}
\footnotesize 
\begin{tabular*}{1\textwidth}{l @{\extracolsep{\fill}} cccccc}  
\toprule
%\multicolumn{7}{c}{\bf Panel A: Effects on Firms' Job Posting} \\ \midrule 
 \textit{Dep var.:} & \multicolumn{2}{c}{Job Postings for} & \multicolumn{2}{c}{Job Postings for}& \multicolumn{2}{c}{Job Postings for} \\
  & \multicolumn{2}{c}{High-Exposure Occ} & \multicolumn{2}{c}{Medium-Exposure Occ} & \multicolumn{2}{c}{Low-Exposure Occ} \\
 \cmidrule(lr){2-3} \cmidrule(lr){4-5}  \cmidrule(lr){6-7}  
%  \addlinespace \textit{Panel Unit:} &\multicolumn{2}{c}{Firm$\times$Month} &\multicolumn{2}{c}{Firm$\times$Month}     \\
 %\cmidrule(lr){2-3} \cmidrule(lr){4-5}   \addlinespace
   & (1)  & (2)  & (3)  & (4)   & (5)  & (6)       \\ 
\midrule             
\addlinespace
Post $\times$ GenAI Exp&      -1.378\sym{***}&      -3.038\sym{***}&      -1.007\sym{***}&      -0.611         &      -0.534         &      -0.745         \\
                    &    (-3.747)         &    (-2.991)         &    (-2.783)         &    (-0.596)         &    (-1.427)         &    (-0.791)         \\
\addlinespace
Post $\times$ ShareSupp&                     &      -2.302\sym{**} &                     &       0.463         &                     &      -0.149         \\
                    &                     &    (-2.029)         &                     &     (0.399)         &                     &    (-0.159)         \\
\addlinespace
Post $\times$ GenAI Exp $\times$ ShareSupp&                     &       8.100\sym{**} &                     &      -0.694         &                     &       1.926         \\
                    &                     &     (2.037)         &                     &    (-0.160)         &                     &     (0.635)         \\
% \addlinespace
% (rawsum) countalljob&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}&       0.000\sym{***}\\
%                     &     (7.654)         &     (7.691)         &     (5.475)         &     (5.471)         &     (4.732)         &     (4.789)         \\
% \addlinespace
% Constant            &       6.581\sym{***}&       6.758\sym{***}&       6.602\sym{***}&       6.522\sym{***}&       6.207\sym{***}&       6.195\sym{***}\\
%                     &    (95.978)         &    (57.413)         &    (77.911)         &    (45.240)         &    (67.168)         &    (39.995)         \\
\midrule
Observations                   &      36,900         &      36,880         &      34,720         &      34,700         &      30,100         &      30,080         \\
Month FE  & X & X & X & X & X & X \\
Firm FE   & X & X & X & X & X & X \\
% \toprule
% \multicolumn{7}{c}{\bf Panel B: Effects on Firms' Employment} \\ \midrule 
%  \textit{Dep var.:} & \multicolumn{2}{c}{Employment of} & \multicolumn{2}{c}{Employment of}& \multicolumn{2}{c}{Employment of} \\
%   & \multicolumn{2}{c}{High-Exposure Occ} & \multicolumn{2}{c}{Medium-Exposure Occ} & \multicolumn{2}{c}{Low-Exposure Occ} \\
%  \cmidrule(lr){2-3} \cmidrule(lr){4-5}  \cmidrule(lr){6-7}  
% %  \addlinespace \textit{Panel Unit:} &\multicolumn{2}{c}{Firm$\times$Month} &\multicolumn{2}{c}{Firm$\times$Month}     \\
%  %\cmidrule(lr){2-3} \cmidrule(lr){4-5}   \addlinespace
%    & (1)  & (2)  & (3)  & (4)   & (5)  & (6)       \\ 
% \midrule             
% \addlinespace
% Post $\times$ GenAI Exp&      -0.083\sym{*}  &      -0.414\sym{***}&       0.143\sym{**} &      -0.197         &       0.255\sym{***}&       0.049         \\
%                     &    (-1.810)         &    (-3.169)         &     (2.495)         &    (-1.643)         &     (3.239)         &     (0.361)         \\
% \addlinespace
% Post $\times$ ShareSupp&                     &      -0.665\sym{***}&                     &      -0.538\sym{***}&                     &      -0.355\sym{**} \\
%                     &                     &    (-3.074)         &                     &    (-3.112)         &                     &    (-2.094)         \\
% \addlinespace
% Post $\times$ GenAI Exp $\times$ ShareSupp&                     &       1.500\sym{**} &                     &       0.752         &                     &       0.156         \\
%                     &                     &     (2.356)         &                     &     (1.283)         &                     &     (0.270)         \\
% % \addlinespace
% % Constant            &       9.767\sym{***}&       9.846\sym{***}&       8.495\sym{***}&       8.592\sym{***}&       7.648\sym{***}&       7.722\sym{***}\\
% %                     &  (1030.588)         &   (373.897)         &   (798.262)         &   (374.398)         &   (524.939)         &   (302.829)         \\
% \midrule
% Observations                   &      31,644         &      31,644         &      31,182         &      31,182         &      30,230         &      30,230         \\
% Month FE  & X & X & X & X & X & X \\
% Firm FE   & X & X & X & X & X & X \\
\bottomrule 
\end{tabular*}
\end{table}		
				



\begin{table}[h] 

\caption[]{\\ \textbf{Firm Hiring Effects Controlling for Industry Heterogeneity}}

\vspace{-.1cm} \footnotesize This table reports the impact of the release of ChatGPT on firms' job postings for high-exposure occupations with and without controlling for industry heterogeneity. The sample includes the high-exposure (top tercile) job postings at the firm-month level from January 2022 to August 2023 aggregated from the Lightcast (formerly Burning Glass) job posting database.  \textit{GenAI Exp} is the \textit{firm}-level Generative AI exposure, which is an employment-weighted average across occupations within the firm. \textit{ShareSupp} is the firm's share of Generative AI exposure deriving from the supplemental tasks' exposure to Generative AI. The job posting panels include many zeros,  which makes it impractical to log-transform the dependent variable.  Instead,  we estimate all regressions using the Poisson model with fixed effects following \cite{cohn2022} which means that coefficients can be interpreted as semi-elasticities,  i.e.,  in terms of percentage changes in the dependent variable. $t$-statistics in parentheses are computed using standard errors double clustered at the month level and the firm level. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 

\vspace{.2cm}

\centering 

\label{tab:empfirm_indFE}
\footnotesize 
\begin{tabular*}{1\textwidth}{l @{\extracolsep{\fill}} cccc}  
\toprule
   & (1)  & (2)  & (3)   & (4) \\ 
\midrule             
\addlinespace
Post $\times$ GenAI Exp&      -1.378\sym{***}&      -1.337\sym{***}&      -3.038\sym{***}&      -2.641\sym{***}\\
                    &    (-3.747)         &    (-2.836)         &    (-2.991)         &    (-3.019)         \\
\addlinespace
Post $\times$ GenAI Exp $\times$ ShareSupp&                     &                     &       8.100\sym{**} &       7.315\sym{**} \\
                    &                     &                     &     (2.037)         &     (2.079)         \\
\addlinespace
Post $\times$ ShareSupp&                     &                     &      -2.302\sym{**} &      -2.108\sym{**} \\
                    &                     &                     &    (-2.029)         &    (-2.021)         \\
\midrule
Firm FE & X & X& X & X\\
Month FE  & X & & X & \\
Industry-Month FE  &  & X&  & X\\
Observations                   &      36,900         &      36,600         &      36,880         &      36,580         \\
\bottomrule 
\end{tabular*}

\end{table}		
				



% \begin{table}[h] 
% \caption[]{\\ \textbf{ Occupational Hiring and Wage Impact By Exposures}}

% \vspace{-.1cm} \footnotesize This table reports the impact of the release of ChatGPT on job postings and wages of occupations. The specifications are the same as in Table \ref{tab:empocc}. Distinct from Table \ref{tab:empocc} which interacts GenAI Exp with a continuous ShareCore, we construct a dummy variable indicating an occupation as GenAI-Complement if its ShareSupp is above the top quartile and as GenAI-Substitute if otherwise. In Column (1), the sample consists of the worker-level hourly wage rate from the Census Current Population Survey (CPS) in monthly panels from January 2022 to October 2023.  Worker demographic controls in Column (1)  include the worker's gender,  age, age squared, work experience, experience squared,  race (white vs. not), and years of education. Individual observations in Column (1) are weighted by the CPS sampling weight. In Column (2),  the sample includes the total number of job postings at the occupation-month level in the U.S. from January 2022 to August 2023 aggregated from the Lightcast (formerly Burning Glass) job posting database.   The job posting panels include many zeros,  which makes it impractical to log-transform the dependent variable.  Instead,  we estimate all regressions using the Poisson model with fixed effects following \cite{cohn2022} which means that coefficients can be interpreted as semi-elasticities,  i.e.,  in terms of percentage changes in the dependent variable. $t$-statistics in parentheses are computed using standard errors double clustered at the month level and the occupation level. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively.  See Section \ref{subsec:occsubcomp} for more details. 

% \vspace{.2cm}

% \centering 

% \label{tab:empocc_dummy}
% \footnotesize 
 
% \begin{tabular*}{1\textwidth}{l @{\extracolsep{\fill}} cc }  
% \toprule
% \textit{Dep var.:} & \multicolumn{1}{c}{\ \ \ \ Hourly Wage\ \ \ \ }  & \multicolumn{1}{c}{\ \ \ \ Job Postings \ \ \ \ } \\
%   \addlinespace
%  \textit{Panel Unit:} &\multicolumn{1}{c}{Worker$\times$Month}  &\multicolumn{1}{c}{Occ.$\times$Month}    \\
%     \addlinespace
%    & (1)  & (2)         \\ 
% \midrule             
% \addlinespace
%  \input{../tables/tab_emp_occ_dummy.tex}
% \end{tabular*}
% \end{table}		 


	
%\begin{landscape}
\begin{table}[h] 
\caption[]{\\ \textbf{Cumulative Abnormal Returns and Generative AI Exposure with Interactions}}

\vspace{-.1cm}  \small This table reports the relation between firms' cumulative abnormal returns during the ChatGPT event period,  [$-1, 10$] trading days around the release of ChatGPT on November 30, 2022, (CAR [$-1, 10$]) and firms' Generative AI exposure, defined in Section \ref{sec:data}. To compute the cumulative abnormal return of each stock, we first subtract the daily market return from Kenneth French's website from the daily stock return from Yahoo Finance,  and then we cumulate the daily abnormal returns over [$-1, 10$]. See Table \ref{tab:summary} for the definitions of firm characteristic variables. All firm characteristics other than generative AI exposure have been standardized to have a mean of zero and a standard deviation of one. Equation \eqref{eq:characteristics} describes the regression specification and the weighting of firms.  $t$-statistics are computed using heteroskedasticity-robust standard errors and reported in parentheses.  ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 
\vspace{.2cm} 

\centering 
\footnotesize 

\label{tab:het_panel_inter}
\begin{tabular*}{\textwidth}{l @{\extracolsep{\fill}} ccccccc}
\toprule
 Dep.  var.: &   \multicolumn{7}{c}{CAR[-1,10]}   \\
\cmidrule{2-8} \addlinespace
            &\multicolumn{1}{c}{(1)}   &\multicolumn{1}{c}{(2)}   &\multicolumn{1}{c}{(3)}   &\multicolumn{1}{c}{(4)}   &\multicolumn{1}{c}{(5)}   &\multicolumn{1}{c}{(6)}   &\multicolumn{1}{c}{(7)}   \\
\hline
\addlinespace GenAI Exp&       0.216***&       0.252***&       0.158***&       0.208***&       0.269***&       0.205** &       0.187***\\
            &     (2.621)   &     (2.768)   &     (2.937)   &     (2.724)   &     (2.952)   &     (2.219)   &     (2.694)   \\
\addlinespace   GenAI Exp $\times$ Log Size&               &       0.098   &               &               &               &               &               \\
            &               &     (1.549)   &               &               &               &               &               \\
\addlinespace   GenAI Exp $\times$ Tobin's Q&               &               &       0.282***&               &               &               &               \\
            &               &               &     (3.312)   &               &               &               &               \\
\addlinespace   GenAI Exp $\times$ ROA&               &               &               &       0.093*  &               &               &               \\
            &               &               &               &     (1.722)   &               &               &               \\
\addlinespace   GenAI Exp $\times$ Labor Intensity&               &               &               &               &      -0.174** &               &               \\
            &               &               &               &               &    (-2.489)   &               &               \\
\addlinespace   GenAI Exp $\times$ Tangibility&               &               &               &               &               &       0.079   &               \\
            &               &               &               &               &               &     (1.210)   &               \\
\addlinespace   GenAI Exp $\times$ Mkt. Leverage&               &               &               &               &               &               &      -0.228***\\
            &               &               &               &               &               &               &    (-2.814)   \\
\hline
R-squared   &        0.05   &        0.09   &        0.16   &        0.08   &        0.08   &        0.06   &        0.13   \\
Observations&        2085   &        2078   &        2078   &        2073   &        2054   &        2069   &        2073   \\
\bottomrule 
\end{tabular*}
\end{table}	

% \begin{table}[h] 
% \caption[]{\\\textbf{Future Cash Flow Impact and Gen. AI Exposure: Extended Horizon}}

% \vspace{-.1cm} \small This table reports the impact of the release of ChatGPT on analyst forecasts of firms' future earnings per share (EPS) and on firms' reported quarterly profitability. Analyst forecasts are updated at a monthly frequency for each firm in the I/B/E/S data. For each firm in each month, we obtain the median analyst forecasts of the firm's EPS in the fiscal year ending in December 2023, December 2024, and December 2025 and the firm's long-term annual percentage growth rate in EPS. The dependent variables in all are the firm's median forecasts of the corresponding measures made from May 2022 to May 2023. The independent variable \textit{Post} is an indicator for whether the time period is after the release of ChatGPT (i.e., after November 2022).  \textit{GenAI Exp} is a continuous measure of GenAI exposure at the firm level. All regressions include both firm-level and time-period fixed effects. The sample  retains all firm-months with data for both 2023 and 2024 EPS forecasts. $t$-statistics in parentheses are computed using standard errors clustered at the firm level. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 
% \vspace{.2cm}

% \centering 
% \small

% \label{tab:ibes_moreyears}
% \begin{tabular}{lcccccccc} 
% \toprule
% % \textit{Panel:} & \multicolumn{4}{c}{Firm $\times$ Month} &  \multicolumn{1}{c}{Firm $\times$ Qtr} \\
% %  \cmidrule(lr){2-5}   \cmidrule(lr){6-6}  
% \textit{Data:} & \multicolumn{4}{c}{  I/B/E/S Analyst Forecasts   }  \\
%  \cmidrule(lr){2-5}  
%  \textit{Measure:  } & EPS 2023 & EPS 2024 & EPS 2025 & LTG \\	
%   \cmidrule(lr){2-2}  \cmidrule(lr){3-3}  \cmidrule(lr){4-4}   \cmidrule(lr){5-5}  
%  %\textit{Units:} & \$ & \$ & \$ & \% & \%  \\ 
%    & (1)  & (2)  & (3)     & (4)            \\ 
% \midrule             
% \addlinespace
%  \input{../tables/ibes_eps_apx.tex} 
% \end{tabular}
% \end{table}	


			
% \begin{table}[h] 
% \caption[]{\\\textbf{Generative AI Exposure and Analyst Forecasts of Revenues}}

% \vspace{-.1cm} \small This table reports the impact of the release of ChatGPT on firm-by-month level measures of analyst forecasts of revenues. Forecasts are made at a monthly frequency for each firm, and we retain the median analyst forecast for each firm for the fiscal years ending December 2023, December 2024, and December 2025 (all scaled by actual revenues from Compustat for the fiscal year ending in 2022), and the long-term forecast  of the growth in revenues (converted into an annual growth rate assuming a 5-year horizon). The regression uses a panel of firm-by-month median forecasts made during May 2022--May 2023 (6 months before and after the event period Nov. 2022), constructed from I/B/E/S data. The last column shows the estimated effects on actual quarterly revenues for the company from Compustat, using a sample period of Jan. 2022 - Sep. 2024. The independent variable is an interaction between an indicator for whether the month is after the release of ChatGPT (i.e., after November 2022), and a continuous measure of GenAI exposure at the firm level. All regressions include both firm-level and time period fixed effects. The sample retains only firm-months with coverage for both 2023 and 2024 EPS forecasts. $t$-statistics in parentheses are computed using heteroskedasticity-robust standard errors. ***, **, and * denote significance at 1\%, 5\%, and 10\% levels, respectively. 
% \vspace{.2cm}

% \centering 
% \label{tab:ibesapx}
% \footnotesize
% %\scalebox{0.955}{
% \begin{adjustbox}{max width=\textwidth}
% \begin{tabular}{lcccccccc} 
% \toprule
% \textit{Data:} & \multicolumn{4}{c}{ I/B/E/S Analyst Forecasts} &  \multicolumn{1}{c}{Compustat} \\
%  \cmidrule(lr){2-5}   \cmidrule(lr){6-6}  
%  % \textit{Measure:  \ \ \ \ \  \ \ \ \ \  \ \ \ \ \ }  & \ \  EPS 2024 \ \  &  \ \ EPS  2025 \  \   &  \  \ EPS  2026 \  \   & \ \ \ \ \     LTG      \ \ \ \ \    &  \   Gross Profit  \  \\
%  %  \cmidrule(lr){2-2}  \cmidrule(lr){3-3}  \cmidrule(lr){4-4}  \cmidrule(lr){5-5}   \cmidrule(lr){6-6}  


%  \textit{Measure:}  &   Revenue 2023  &   Revenue 2024    &   Revenue 2025     & LTG (Revenue) & Revenue\\
%   \cmidrule(lr){2-2}  \cmidrule(lr){3-3}  \cmidrule(lr){4-4}  \cmidrule(lr){5-5}   \cmidrule(lr){6-6}   
%  %\textit{Units:} & \$M & \$M & \$M & \%  \\ 
%    & (1)  & (2)  & (3)  & (4)    & (5)        \\ 
% \midrule             
% \addlinespace
%  \input{../tables/ibes_rev_short.tex} 
% \end{tabular}
% \end{adjustbox}
% \end{table}	



	
		

	 
		




\FloatBarrier
\newpage


\section{Methodology Notes}\label{sec:apx_meth}




\renewcommand{\thetable}{IA.C.\arabic{table}}
\renewcommand{\thefigure}{IA.C.\arabic{figure}}
\renewcommand{\thesubsection}{C.\arabic{subsection}}

\subsection{GPT prompt for task-based exposure scoring} \label{sec:rubric}

The following prompt structure was based on the rubric language by \cite{eloundou2023}, as well as insights by \cite{willison2023} and  \cite{underwood2023} about how to best structure API calls for GPT classification.   We conducted this categorization on March 29, 2023. To rule out misclassification due to the model's confusion of ChatGPT's known capabilities with ChatGPT's in-development but not well-known capabilities such as image recognition, we follow \cite{eloundou2023} and add a fourth category (E3) in addition to the main categories used in our analysis,  indicating that the task is not exposed to ChatGPT, either directly or by software integration, but can be completed more efficiently if image capabilities of ChatGPT were accessible. Only 0.6\% of the tasks are categorized as E3. We consider tasks that are exposed to image recognition to be not exposed throughout our study.  Here are the instruction  prompts submitted before asking GPT 3.5 Turbo to classify each task statement (using the version as of March 29th, 2023).  Note that the order in which the two user-assistant interactions are provided to the API is randomized for each task, and the GPT ``temperature'' parameter is set to 0:\\
	
systemprompt = "Consider the most powerful OpenAI large language model (LLM). \
 This model can complete many tasks that can be formulated as having text input and text output where the context for the input can be captured in 2000 words.\
 The model also cannot draw up-to-date facts (those from $<$1 year ago) unless they are captured in the input. \
 Assume you are a worker with an average level of expertise in your role trying to complete the given task.\
You have access to the LLM as well as any other existing software or computer hardware tools mentioned in the task.\
You also have access to any commonly available technical tools accessible via a laptop (e.g. a microphone, speakers, etc.).\
 You do not have access to any other physical tools or materials.\
You are a helpful research assistant who wants to label the given tasks according to the rubric below.\
Equivalent quality means someone reviewing the work would not be able to tell whether a human completed it on their own or with assistance from the LLM.\
If you arenâ€™t sure how to judge the amount of time a task takes, consider whether the tools described exposed the majority of subtasks associated with the task. \ \\
\# Exposure rubric:\\ \
\#\# E1 - Direct exposure: Label tasks E1 if direct access to the LLM through an interface like ChatGPT or the OpenAI playground \
alone can reduce the time it takes to complete the task with equivalent quality by at least half.\
 This includes tasks that can be reduced to:\
  - Writing and transforming text and code according to complex instructions,\
  - Providing edits to existing text or code following specifications, \
  - Writing code that can help perform a task that used to be done by hand,\
  - Translating text between languages,\
   - Summarizing medium-length documents,\
- Providing feedback on documents,\
- Answering questions about a document,\
- Generating questions a user might want to ask about a document,\
 - Writing questions for an interview or assessment,\
 - Writing and responding to emails, including ones that involve refuting information or engaging in a negotiation (but only if the negotiation is via written correspondence),\
 - Maintain records of written data,\
  - Prepare training materials based on general knowledge, or - Inform anyone of any information via any written or spoken medium.\\  \
  \#\# E2 - Exposure by LLM-powered applications: Label tasks E2 if having access to the LLM alone may not reduce the time it takes to complete the task by at least half,\
   but it is easy to imagine additional software that could be developed on top of the LLM that would reduce the time it takes to complete the task by half.\
   This software may include capabilities such as: \
    - Summarizing documents longer than 2000 words and answering questions about those documents, \
    - Retrieving up-to-date facts from the Internet and using those facts in combination with the LLM capabilities, \
    - Searching over an organizationâ€™s existing knowledge, data, or documents and retreiving information, \
    - Retrieving highly specialized domain knowledge, \
    - Make recommendations given data or written input, \
    - Analyze written information to inform decisions, \
    - Prepare training materials based on highly specialized knowledge, \
    - Provide counsel on issues, and \
    - Maintain complex databases. \
    \#\# E3 - Exposure given image capabilities: \
 Suppose you had access to both the LLM and a system that could view, caption, and create images as well as any systems powered by the LLM (those in E2 above). \
 This system cannot take video as an input and it cannot produce video as an output. \
 This system cannot accurately retrieve very detailed information from image inputs, such as measurements of dimensions within an image. \
 Label tasks as E3 if there is a significant reduction in the time it takes to complete the task given access to a LLM and these image capabilities: \
 - Reading text from PDFs, \
 - Scanning images, or \
 - Creating or editing digital images according to instructions. \
The images can be realistic but they should not be detailed. The model can identify objects in the image but not relationships between those options \\ \
\#\# E0 - No exposure: Label tasks E0 if none of the above clearly decrease the time it takes for an experienced worker to complete the task with high quality by at least half. \
Some examples: \
- If a task requires a high degree of human interaction (for example, in-person demonstrations) then it should be classified as E0. \
- If a task requires precise measurements then it should be classified as E0. \
- If a task requires reviewing visuals in detail then it should be classified as E0. \
- If a task requires any use of a hand or walking then it should be classified as E0.\
- Tools built on top of the LLM cannot make any decisions that might impact human livelihood (e.g.hiring, grading, etc.).\
  If any part of the task involves collecting inputs to make a final decision (as opposed to analyzing data to inform a decision or make a recommendation) then it should be classified as E0.\
 The LLM can make recommendations. \
- Even if tools built on top of the LLM can do a task, if using those tools would not save an experienced worker significant time completing the task, then it should be classified as E0.\
- The LLM and systems built on top of it cannot do anything that legally requires a human to perform the task. \
- If there is existing technology not powered by an LLM that is commonly used and can complete the task then you should mark the task E0 if using an LLM or LLM-powered tool will not further reduce the time to complete the task.\
When in doubt, you should default to E0."
    
    
user\_prompts = ["", "", "", ""]
user\_prompts[0] = "Read the following occupation title and one of the tasks that belong to that occupation. Then do three things. \
1: Reason step by step to decide which of the labels (E0/E1/E2/E3) from the exposure rubric you were given applies to the task's exposure to LLM. \
Report. Give an explanation for which label applies and report the label that you think fits best. Do not say zero or N/A.\\ \
2: Report only the label that you determined for the task, which should match the label in step 1. Do not reply N/A. \\ \
3: Given the amount of speculation required in step 1, describe your certainty about the estimate--either high, moderate, or low.\\ \
The task to label follows:\\ \
Occupation: Inspectors, Testers, Sorters, Samplers, and Weighers. \
Task: Adjust, clean, or repair products or processing equipment to correct defects found during inspections."


assistant\_prompts = ["", "", "", ""]
assistant\_prompts[0] = "1: Label (E0/E1/E2/E3): E0. Explanation: The model does not have access to any kind of physicality, and more than half of the task (adjusting, cleaning and repairing equipment) described requires hands or other embodiment. \\ \
2: E0. \\  \
3: High confidence."


user\_prompts[1] = "Read the following occupation title and one of the tasks that belong to that occupation. Then do three things. \
1: Reason step by step to decide which of the labels (E0/E1/E2/E3) from the exposure rubric you were given applies to the task's exposure to LLM. \
Report. Give an explanation for which label applies and report the label that you think fits best. Do not say zero or N/A.\\ \
2: Report only the label that you determined for the task, which should match the label in step 1. Do not reply N/A. \\ \
3: Given the amount of speculation required in step 1, describe your certainty about the estimate--either high, moderate, or low.\\  \
The task to label follows:\\  \
Occupation: Computer and Information Research Scientists. \
Task: Apply theoretical expertise and innovation to create or apply new technology, such as adapting principles for applying computers to new uses."


assistant\_prompts[1] = "1: Label (E0/E1/E2/E3): E1. Explanation: The model can learn theoretical expertise during training as part of its general knowledge base, and the principles to adapt can be captured in the text input to the model. \\  \
2: E1. \\  \
3: Medium confidence."



	\subsection{Consistency of Generative AI scoring}  \label{sec:consistent}
	
	To validate the consistency and replicability of our procedure that employs the GPT API for classification,  we compare the scores assigned across 3 different GPT runs (which may vary in results due to the randomized order of example cases provided,  or non-deterministic features of the underlying LLM)  for a randomly selected subsample of 100 task statements.  We compare the different sets of scores as follows: First,  we construct 3 different classifications for each task based on the assigned score: (1) ``Current exposure'': score 1 has been assigned.  (2) ``Expected exposure:'' Either score 1 or 2 has been assigned.  Then,  we compute the agreement between different scoring runs with regard to which tasks belong in these categories.  The comparison between different runs is shown in Appendix Table \ref{tab:valid}. We find that the agreement between different GPT runs is very high - they arrive at the same score for at least 88\% of all cases independent of the exposure classification considered.  This validates that GPT reliably provides classifications that are highly consistent across different runs.
			
		\begin{center}
				\begin{table}[hpbt!]\centering
					\caption{\\ \textbf{Exposure score variation across GPT scoring runs}}\label{tab:valid}
					\begin{tabular}{lcc}
					\hline \hline
					 & \multicolumn{2}{c}{Agreement \%} \\
					 \cline{2-3}
						Score comparison & Current Exposure & Expected exposure  \\
						\midrule
						\addlinespace
						GPT \#1 vs.  GPT \#2 & 95 & 90  \\
						GPT \#1 vs.  GPT \#3 & 93 & 88  \\
						GPT \#2 vs.  GPT \#3 & 96 & 88  \\
						\hline \hline
					\end{tabular}
				\end{table}
			\end{center}




	\subsection{Validation of Generative AI scoring}  \label{sec:validation}
	
How reliable is the approach of classifying task statements using an LLM rather than human research assistants? The benefits of LLM-scoring in terms of costs and speed are clear (the classification task was accomplished in less than two days using an LLM while it would have taken a human research assistant at least 200 hours based on our estimates, and that would be without producing explanations for the assigned score). How does the labeling by an LLM compare in terms of ``quality''? Note that for the tasks in question it is not the correct question whether an LLM  would produce fully correct labels, but whether a human research assistant that could feasibly be hired for the task would have a better ability to produce correct labels.


The ability of human annotators is particularly relevant as the scoring of $>19$K tasks that span the entirety of U.S. occupations requires an exceptionally experienced annotator to fully be able to comprehend and contextualize the description of \textit{any} possible occupation's activities. We consider this as part of the advantages of using a state-of-the-art LLM to do this task: the breadth of occupations represented in the training texts used for LLMs is likely to far exceed the occupational contexts that any human annotator could interpret with confidence. As a result, the LLM could reasonably be considered more of an ``expert'' for this task than the human research assistants who would otherwise be employed in such a task (usually undergraduate or graduate students).

One validation of how an LLM's scoring of tasks as exposed to Generative AI technologies compares to human labeling of the same tasks is already provided by \cite{eloundou2023}, who found that, depending on the exact measure of exposure one is considering, human labels agreed with the GPT-produced labels in 65.6-82.1\% of labels (see Table 2 in that paper). While, the authors of that paper included researchers at OpenAI and therefore had access to ``experienced human annotators who have reviewed GPT-3, GPT-3.5 and GPT-4 outputs as part of OpenAIâ€™s alignment work,'' we do not have access to similarly skilled annotators.

To provide further validation of this method, we recruited two research assistants (one with a graduate degree and one without a college degree) to label a random sample of tasks with the same instructions as were provided to the LLM, and also had one of the authors of this paper label the same set of tasks as an ``experienced'' annotator.  We find agreement between these labelers that looks as shown in Appendix Table \ref{tab:validation} (which is similar to the validation table shown in \cite{eloundou2023}).

\begin{table} 
\caption{\\\textbf{Agreement between different annotators}}
\label{tab:validation}
\small \vspace{-0.1cm} This table shows agreement between annotators of the same random sample of 100 tasks from the full set of task statements on O*NET. Agreement is defined as the \% of tasks that receive the same score for two different score definitions: (1) Column 1 only considers whether there was agreement on whether the  ``direct exposure'' label E1 applied or not.  (2) Column 2 shows agreement on whether any exposure (direct OR indirect) was assigned to the task.\\

\centering \vspace{0.1cm}
\begin{tabular}{lcccc}
\hline
Agreement measure (\%): & E1 only & E1 or E2 \\
\hline
GPT vs. Experienced  & 81  & 86 \\
GPT vs. RA \# 1 & 80  & 72 \\
GPT vs. RA \# 2 &  78  &  81 \\
Experienced vs. RA \# 1 & 79  & 74 \\
Experienced vs. RA \# 2 & 75  & 83 \\
RA \# 1 vs. RA \# 2 & 82  & 73 \\
\hline
\end{tabular}
\end{table}

As the table shows, we find very similar agreements between the LLM and our human annotators as \cite{eloundou2023}, ranging from 72\% to 86\% agreement. If we just focus on whether the annotator determined \textit{direct} Generative AI exposure, we find 78-81\% agreement. 


\textbf{Variation across human labelers.} We can also compare the human annotators to one another. As Table \ref{tab:validation} shows, there is substantial variation in labels \textit{between} human annotators. Our human annotators have similar levels of agreement with one another as they do with the GPT labels, ranging from 73 to 83\% agreement across the different exposure measures, and 79-82\% when determining if there is \textit{any} Generative AI exposure. While this level of idiosyncratic variation across human annotators might be in part due to the fact that we do not have access to highly skilled occupational analysts, it is likely reflective of the annotator skill level that would normally be available for this type of labeling task (albeit at much higher expense of time, money, and research assistant welfare) if LLMs could not be used.
Comparing this agreement across human labelers to the consistency between different LLM runs with random variation in prompting shown in Table \ref{tab:valid},  this suggests that LLMs may be less variable in their output than human annotators would be and might thus enable better replicability of results. 




\subsection{\cite{acemoglu2011} measures of skill requirements of occupations} \label{sec:skill_apx}

For the analysis shown in Figure \ref{fig:autor},  we need measures of the skill requirements of different occupations. We draw on standard measures from the literature that allow for comparability of our results to the characteristics of previous waves of automation.

Acemoglu and Autor (2011) construct six skill measures for each SOC occupation based on O*Net measures in the following steps.  First, they assign detailed skill requirements from the O*Net's database to each of the six aggregated skill measures, using the following O*Net measurements for each occupation:

\noindent \textit{Non-routine cognitive: analytical skill:} 
\begin{itemize}
\item[] 4.A.2.a.4 Analyzing data/information
\item[] 4.A.2.b.2 Thinking creatively
\item[] 4.A.4.a.1 Interpreting information for others
\end{itemize}

\noindent \textit{Non-routine cognitive: interpersonal skill:} 
\begin{itemize}
\item[] 4.A.4.a.4 Establishing and maintaining personal relationships
\item[] 4.A.4.b.4 Guiding, directing and motivating subordinates
\item[] 4.A.4.b.5 Coaching/developing others
\end{itemize}

\noindent \textit{Routine cognitive skill:} 
\begin{itemize}
\item[] 4.C.3.b.7 Importance of repeating the same tasks
\item[] 4.C.3.b.4 Importance of being exact or accurate
\item[] 4.C.3.b.8 Structured v. Unstructured work (taking the reverse value)
\end{itemize}

\noindent \textit{Routine manual skill:}
\begin{itemize}
\item[] 4.C.3.d.3 Pace determined by speed of equipment
\item[] 4.A.3.a.3 Controlling machines and processes
\item[] 4.C.2.d.1.i Spend time making repetitive motions
\end{itemize}



\noindent \textit{Non-routine manual: physical skill} 
\begin{itemize}
\item[] 4.A.3.a.4 Operating vehicles, mechanized devices, or equipment
\item[] 4.C.2.d.1.g Spend time using hands to handle, control or feel objects, tools or controls
\item[] 1.A.2.a.2 Manual dexterity
\item[] 1.A.1.f.1 Spatial orientation
\end{itemize}


\noindent \textit{Non-routine manual: interpersonal skill}
\begin{itemize}
\item[] 2.B.1.a Social perceptiveness
\end{itemize}

Second, they obtain an importance scale of each detailed skill requirement for each SOC8 occupation, and standardize the importance scale of each detailed skill to have a mean of 0 and a standard deviation of 1 across occupations.

Third, they compute an occupation's six skill measures a the average of the standardized importance scales of their corresponding detailed skill measures. 
 



\subsection{Generative AI exposure portfolio construction.} \label{sec:constructpf}

 Portfolios for the main realized return analysis are formed from quintiles of stocks that have Yahoo Finance data for Nov. 15,  2022 - March 31, 2023.  Quintile thresholds that define value-weighted portfolios within industries or for all stocks are solely based on the sample of stocks listed on the NYSE as of the sorting date.  All portfolios are formed based on equal weighted sorts on November 29, 2022,  and weights for computing portfolio returns are adjusted based on daily returns to mimic passive buy-and-hold exposure. 

 Industry-neutral portfolios are computed by first forming within-industry equal-weighted tercile portfolios,  and then averaging portfolio returns for the same terciles across industries.  Returns for within-industry terciles and for all global (not industry-neutral) portfolio quintile sorts are value-weighted,  while across-industry averages are industry market-cap.  weighted.    \textit{AMH} is the "Artificial Minus Human''  zero
net investment portfolio long highest exposure quantile ($A$) stocks and short lowest
exposure quantile ($H$) stocks.   The data set for estimating portfolio returns consists of daily stock returns from Yahoo Finance and the Fama-French factors,  including the market factor and risk free returns are obtained from Ken French's website.   

We define the ChatGPT event period as from November 30, 2022 to December 14, 2022, i.e., the two weeks after the release of ChatGPT (see Section \ref{sec:returns} for more details).  CAPM market-adjusted alphas and the Fama-French 5-factor-adjusted alphas are based on the factor loadings of each portfolio estimated using data from the  six months preceding Nov.  15, 2022.  Abnormal returns are computed as the difference between raw portfolio returns and the product of factor loadings and the factor returns on each day of  the event period.   Alphas for the event period are then computed as the intercept in a regression of abnormal returns over the event period on a constant,  with Newey-West standard errors with five lags.

\subsection{Product Market AI Exposure Measures} \label{sec:productmeasures}

We create a number of new measures to try to capture the degree to which a company has product-market exposure to AI technology innovations. The data sources and construction of these measures are detailed below.

\textbf{Company annual report data.} The 10-K annual reports filed by companies at the SEC's EDGAR system are obtained in pre-cleaned text files from Bill McDonald's ``Software Repository for Accounting and Finance'' website, \footnote{See \url{https://sraf.nd.edu/}} based on the work in \cite{loughran2016}.  We then use regular expressions to break up the text into the different ``items'' contained within the report.\footnote{We built on code provided by Yu Zhu at \url{https://yuzhu.run/how-to-parse-10x/} and coding support from ChatGPT in this analysis.}, focusing only on reports filed in 2022, and on the ``Business'' section of each report.

\textbf{AI-related business description keywords.} For our first product market AI exposure measures  we follow \cite{hoberg2016} and use the ``Business'' description section of a firm's 10-K annual report to infer information about its product markets.  We construct a simple measure of AI relevance for the firm's business by tokenizing the text and counting the number of mentions of ``AI'' or ``artificial intelligence''.  We use the total count of mentions as a proxy for a firm's products either using AI or depending on the use of it by other actors in the value chain. We do this by first lower-casing and tokenizing the text in the ``Business'' section,  constructing lists of all possible unigrams and bigrams contained in the text,  and then counting the occurrences of ``ai'' and ``artificial intelligence'' in the text.  

\textbf{GPT assessment of business product exposure to AI.}  The method of counting keywords potentially discards relevant information contained in the full text and the context and interdependence of the AI-related concepts discussed in it.  Therefore,  we also use  a method that uses a large language model to evaluate the text of the business description in the firm's annual report,  asking it to determine whether there would be direct positive product market impact of a Generative AI boom on the described company.   This allows us to keep the text in its original form and take into account the context within which AI or related topics are discussed.   We develop a rubric that provides guidance to the model in the form of asking it to consider whether the firm's products might be involved in enabling or scaling AI technologies,  or might benefit from a direct incorporation of the new AI capabilities (the full text of the prompt is shown below).  The model is then given two examples of scores applied to company business descriptions and given a new business description and asked to apply a binary label of whether the firm is  ``directly product market exposed to AI'' or not, and also to provide an explanation for the score,  which allows for an  audit of the model's reasoning.  To economize on computing resources and API costs,  we only do this analysis for annual reports in our sample that belong to firms for which we have previously computed a task-based AI exposure score, which have stock price data in our sample, and for which the ``Business'' section contains the word ``and'' at least three times (which removes annual reports that omitted the ``Business'' section  or where our text extraction parsed a snippet that is too small).  We submit the prompt for scoring together with a ``Business'' section to OpenAI's GPT 3.5 Turbo API for evaluation.  We are limited by the context window to evaluating only the first 3000 words of the business description for each firm,  which is rarely binding and allows for ample business description for almost all companies - as the beginning of the section tends to provide the general overview of the company.  The result of this procedure is binary product market AI exposure scores for $\sim2.2$K companies.  Moreover,  in early trial runs we audited the explanations provided by the model to ensure that the prompt leads to scoring that closely corresponds to a human scorer's interpretation of the business impact.

\textbf{Goldman Sachs ``near-term AI beneficiaries''.} This classification is based on the list of firms in the report by Goldman Sachs US Equity Views,  August 21, 2023,   ``The (AI) trade after the trade: Identifying potential long-term EPS beneficiaries of AI adoption'', which identifies 11 large firms ``directly exposed to the development of AI technology.'' While this report is produced ex post, this should, if anything, bias it towards better capturing the (at that point) observed product market exposure that leads to a stock market reaction. We use the report to code a binary variable on whether or not a firm is on the following list:  NVIDIA (NVDA), Meta (META), Amazon (AMZN), Salesforce (CRM), Marvell Technology (MRVL), Adobe(ADBE), Alphabet (GOOGL), ServiceNow (NOW), Microsoft Corporation (MSFT), Intuit (INTU) and Credo Technology (CRDO).

\textbf{Resume AI skill share from \cite{babina2024artificial}:}  we use a measure of the share of workers at a firm that have AI skills on their resumes constructed by \cite{babina2024artificial}, who show that this measure is a good predictor of AI-related product innovations and R\&D spending during the pre-ChatGPT wave of AI advancements.  We use both the last available data point on the stock of AI skills (as a share of firm employment) as proxies for a firm's level  of investment in using AI-related tools pre-ChatGPT.  We use the replication data available from the authors and follow their methodology to construct these regression variables based on the Cognism resume AI skill share data provided.  The last year of available skill share data is 2021 for the majority of firms in the sample, and we only keep skill share level data if the last available data is from no earlier than 2018.


\subsection{Product Market AI Exposure: GPT Prompt for Scoring} \label{sec:productprompt}

General context prompt submitted with the completion task to GPT 3.5 Turbo to score company annual report text from the ``Business'' section for whether it suggests the company has direct product market AI exposure:\\

        \includegraphics[width=0.9\linewidth]{../figures/system.png} 

     %    \vspace{0.2cm}
% \textit{(Example interactions submitted with the prompt are omitted - available from authors upon request)}\\
% \vspace{0.2cm}
 
 Prompt preceding the ``Business'' text submission": \\
        \includegraphics[width=0.9\linewidth]{../figures/prefix.png} 


Overall prompt structure (here,  \textit{fulltext} is the ``Business'' description to be scored):\\
        \includegraphics[width=0.9\linewidth]{../figures/prompt.png} 

		
		
	\subsection{Measuring Firm ``Data Value'' for Generative AI} \label{sec:datameasure}
	
In order to measure the ``data value'' of a company that might contribute to its ability to productively deploy Generative AI tools and their analytics capabilities,  we develop a number or new measures to quantify the amount of data that a company has effective access to.  Similar to the product market Generative AI exposure measurement approach described above,  we again review the business description section in the firm's recent annual report using  both traditional NLP approaches and a large language model.  Again,  we follow \cite{hoberg2016} and use the ``Business'' description section of a firm's 10-K annual report to infer information about its product markets.  We also develop an alternative approach of measuring data value based on the predicted share of ``data management'' roles in a firm's employment structure, which is inspired by the analysis in \cite{abis2023}.

\textbf{Data-related business description keywords.} We construct a simple measure of data value for the firm's business by tokenizing the text of the business description in the firm's annual report filed in 2022 and counting the number of mentions of ``data''.  We use the total count of mentions as a proxy for the importance of data in firm's existing business.   We do this by first lower-casing and tokenizing the text in the ``Business'' section,  constructing lists of all possible unigrams contained in the text,  and then counting the occurrences of ``data'' in the text.  In the regression analysis we use an indicator of a non-zero count of ``data'' mentions as our proxy for a firm having valuable data.


\textbf{GPT assessment of business ``data value'' for LLMs.}  Again, we also use  a method that uses a large language model to evaluate the text of the business description in the firm's annual report.   We develop a rubric that provides guidance to the model in the form of asking it to first consider subcategories of data relevance. In particular,  the LLM is asked to first assess whether a firm's business description suggests access to relevant data based on its coverage of 6 categories: the general nature of the company's business,  the scale and reach of the firm,  data collection mechanisms,  data utilization,  data infrastructure \& management, and data regulation and privacy (full prompt shown below). The model is asked to assign a score of 0, 1, 2, or 3 (no, little, moderate, or high relevance) in each category.  Only then is the model asked to also provide an overall score for the degree to which a firm is likely to have data that can be used as an input into LLM analytics (low, moderate, or high data value). 

We submit the prompt for scoring together with a ``Business'' section to OpenAI's GPT 3.5 Turbo 16k API for evaluation.  We submit only the first 3000 words of the business description for each firm,  which is rarely binding and allows for ample business description for almost all companies - as the beginning of the section tends to provide the general overview of the company.   In our analysis based on this scoring,  we use both  the LLM's 0-3 assessment of the ``overall'' relevance of the company's data for LLM analytics,  as well as a binary indicator for whether any of the subcategory scores was assessed as a 3 (high relevance). 

\textit{Data Management Skill.} As an alternative measure of a company's effective ability to leverage data in combination with LLM analytical capabilities,  we build on the insight  in  \cite{abis2023} that the prevalence of ``data management'' skills in a firm's employment indicates the accumulation of valuable data.  First,  we predict the likelihood that a U.S.  job posting for a 6-digit SOC occupation mentions at least 3 ``data management skills''.  The
se skills are classified based on a list of words indicating relevant skills in job postings from \cite{abis2023}, which we fuzzy match to skill tags in Lightcast job posting data using Stata's \textit{matchit} command.  We retain all matches with a similarity score above 0.7,  and then manually inspect whether the matched Lightcast skill tag actually corresponds to a data management skill or was a spurious match.

Then,  we count the number of such data management skills present in each job posting for 2017-2021---the 5 years preceding the year when ChatGPT was released.  We aggregate the posting-level data  into occupations to compute the probability that a U.S.  job posting for a 6-digit SOC occupation mentions at least 3 data management skills  in this time period---which we define as the likelihood that a job in this occupation has ``high data management skill.''

Last, we again use the LinkedIn occupational employment distribution at each firm in 2022,  together with these occupation-level expected shares of high data management skill jobs,  to predict the probability that a job at a firm is a ``high data management skill'' position. That is,  this measure represents the predicted share of a firm's positions on LinkedIn that are ``data management''-intensive.   In our analysis,  we use both this predicted share and  a binary variable for firms in the top tercile of this predicted data management intensity among its workers---as proxies for the degree to which a company is likely to have valuable data based on its employment structure.

		
\subsection{Data Value Assessment: GPT Prompt for Scoring} \label{sec:dataprompt}

General context prompt submitted with the completion task to GPT 3.5 Turbo 16k to score company annual report text from the ``Business'' section for whether it suggests the company has data that would be valuable as an input for LLM analytics:\\

        \includegraphics[width=0.9\linewidth]{../figures/systemdata.png} 

%         \vspace{0.2cm}
% \textit{(Example interactions submitted with the prompt are omitted - available from authors upon request)}\\
% \vspace{0.2cm}
 
 Prompt preceding the ``Business'' text submission": \\
        \includegraphics[width=0.9\linewidth]{../figures/prefixdata.png} 

			\newpage
			


 \end{appendices}

		
	\end{document}